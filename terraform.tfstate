{
    "version": 3,
    "terraform_version": "0.11.7",
    "serial": 16,
    "lineage": "ed63ba4c-4644-c965-0d0b-bbe715af2c98",
    "modules": [
        {
            "path": [
                "root"
            ],
            "outputs": {
                "api_server_admin_token": {
                    "sensitive": true,
                    "type": "string",
                    "value": "56d89cea5bd825c5dcaedfbf8bd6bf5e"
                },
                "api_server_cert_pem": {
                    "sensitive": true,
                    "type": "string",
                    "value": "-----BEGIN CERTIFICATE-----\nMIIDtzCCAp+gAwIBAgIQakExFRzw73ebhR6ouRgM9jANBgkqhkiG9w0BAQsFADAS\nMRAwDgYDVQQDEwdrdWJlLWNhMB4XDTE5MDIwODAyMjQwNFoXDTIxMTEwNDAyMjQw\nNFowJTEXMBUGA1UEChMOc3lzdGVtOm1hc3RlcnMxCjAIBgNVBAMMASowggEiMA0G\nCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDtb5OCYlLojCYjuGgNQrM+Ips2V/oP\nzzhfVY0eVsWj4DqkOoWmV9PUItVYS2/D42p6TFYtkf8O5qmNhPe8Vq37Djesc5sn\nIP8Sd7a33FY26aKyRaHJFw6Vn22UuSOG21BMozyibxfGpW0UJeuCzk+CqV7CdVwD\npvJDwvqlnl9FB5/EhEva7ytTS3HLfBLG//Pm6eC7vll14SiXV5AFY2SNvxsz8T4E\nak/b7Qf4b8mWdgKQuW55wzbmesriYBb1IA5kwZebPlO0DuvoFxph4vjfb3CpFzGF\neNhPd8hdblBqATwrGo0ZBi+hPoBGYnlmPtsH95KeMiGJfhAlsVGuoCK/AgMBAAGj\ngfUwgfIwDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEF\nBQcDAjAMBgNVHRMBAf8EAjAAMB8GA1UdIwQYMBaAFLr6s2Mj9xrPY2SyhVZXVmlW\n6pnRMIGRBgNVHREEgYkwgYaCCTEwLjIxLjAuMYIJbG9jYWxob3N0ggprdWJlcm5l\ndGVzghJrdWJlcm5ldGVzLmRlZmF1bHSCFmt1YmVybmV0ZXMuZGVmYXVsdC5zdmOC\nJGt1YmVybmV0ZXMuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbIcEgdXGqIcEChUA\nAYcEfwAAATANBgkqhkiG9w0BAQsFAAOCAQEANxcaHsQ+O7/bRi1gMC05G3jdvulg\nQMf6HzJY7tRDDQVoJa4H2kpbS61m7rLKvqf0YTIb9UanxIl6kIyk2JkJaLEccZ19\n/4WyjRIQRf3Hc/YsL1pELUz3htyLd0m2BGhJuc0xI70lQOWOFM4f4cVeAniXmA74\nK8JNuVZrpC5pz3R4OnXbXE5pbHTbPwJa4nJrmA63oEVbNB0XVUiGwtgdpQFPowVA\ns98oq3dgP8tDAf+B6o0v2+foASppkpNXu33pAkDGZC2/OHY+IGIuuPWKv+jA8KzW\nHj3R/4sgDbXkbGO9Sy76F17a+1W0OTUz5dVOFCsEPOQELCu++YDvrjsiqg==\n-----END CERTIFICATE-----\n"
                },
                "api_server_private_key_pem": {
                    "sensitive": true,
                    "type": "string",
                    "value": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEA7W+TgmJS6IwmI7hoDUKzPiKbNlf6D884X1WNHlbFo+A6pDqF\nplfT1CLVWEtvw+NqekxWLZH/DuapjYT3vFat+w43rHObJyD/Ene2t9xWNumiskWh\nyRcOlZ9tlLkjhttQTKM8om8XxqVtFCXrgs5PgqlewnVcA6byQ8L6pZ5fRQefxIRL\n2u8rU0txy3wSxv/z5ungu75ZdeEol1eQBWNkjb8bM/E+BGpP2+0H+G/JlnYCkLlu\necM25nrK4mAW9SAOZMGXmz5TtA7r6BcaYeL4329wqRcxhXjYT3fIXW5QagE8KxqN\nGQYvoT6ARmJ5Zj7bB/eSnjIhiX4QJbFRrqAivwIDAQABAoIBAQDML0KUQsf3seZu\nm3vnw29vRMVjk365L8PTwDeOWqK2TfNAHg+nQCoraRU9TAo+VAjSSWlm4QGNp/Ex\ngaKl9YjCuLRJ+lT37llMYWThcns11++RDW6XBtwE8ciDuD8EDwBcF5jiO1UgAEzw\nobeJkrAvtkWGRvStM1ltynRQDwTwz3iYabMx2XV3z0tcl6vz7sYt8+61ZiBGZJ6T\nZI0Eqh16h+DHlJCi2VVUYo6i+QV39UverH9f0t2QQKbmmt7AYkB7Fl7XSCzw7fPa\ne4mOf3GHNyWCuwgtT1NLme7cBYa88JdfCdRUmHP+nU/weJgKIi5557Jzh7r7w+cR\nv4DY4pgxAoGBAPi31dWUj9JY3xZzLju/Qj0ZFEPfbB/Y5Vo7xZ0KIsOaxV6y6C3v\nYIEEPjF8dOz6OG88C+3T7qMRQi32Lxc1YTRxX/6ZaZs3/cSonn+qPp2HuvR2XKp+\n5J9w1iZkRKBd7ImBw5vedVUo6PLPOGmpF7yn0UYmqQV9epCn3SVoTJv5AoGBAPRj\nLelyetc51usp/rzaziSiPvR4n2/LyudanZt9tiWMwPg+DreOJBWc62xNBelD6W8/\nLo7zNko0wQbjlImds22WfLYHkDHBNeR6gqEKQxeb9roVSGzQpVgKEFvFqQ9GSyil\nJWpztYVR0raiJ6NbJ/FNRoiqRbjZh+zc4hMCNTJ3AoGAPPym/HYvRf7wxQp9Pb1K\nOr0ZkQMJ+k0vAA9EB5vipmAfIXdxI0JdQYWO0oeYDDvW9r+clTawf1/OAIMrTN+T\n9E4QoddwY9U47q4CH3/ZVrtfhm43jr8KxGXgvQ09Hq2pQJaHJoNH9hfP9yoExTPn\nVCU6VZ9JNsVr9miS+4c1sdECgYEAsizhG1OItgQIalmqzLvmEZVsusZ6z4JQQ46w\nW94yf3v4cMSl7DOooU1P4xzg02nc9mulITm2+jEuDjy8XfzpBVvzPq+S9IN+LD8Z\noBmgQsVGA/NiY1tXQTHNLWuVz3obb92/wrXrwPCf5OGibpoWK/qAE0G5JYULcai0\n9tDkQg8CgYEAjePBQTAmeigHdlooeGGIz24LjXxzH8NqAVxxrIDhJ//6tqTsEf9T\nr9TbfmE+UVVidUmE1r88DUOZWhzwJE0s1xFBxxChhCKz6PrWmRe6LNilncMwk4qX\nYapeG4Ayte6pkPGqYiaOcCcFtMAP0lwv6tjRyF2E2xQrNIV/+Bhz3TM=\n-----END RSA PRIVATE KEY-----\n"
                },
                "control_plane_subnet_access": {
                    "sensitive": false,
                    "type": "string",
                    "value": "private"
                },
                "etcd_lb_backendset_2379_name": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "lb-backendset-etcd-2379"
                    ]
                },
                "etcd_lb_backendset_2380_name": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "lb-backendset-etcd-2380"
                    ]
                },
                "etcd_lb_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q"
                    ]
                },
                "etcd_lb_ip": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "129.213.69.178"
                    ]
                },
                "etcd_ssh_ingress_cidr": {
                    "sensitive": false,
                    "type": "string",
                    "value": "0.0.0.0/0"
                },
                "etcd_subnet_ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaaf7xofr4fl6ceqs2wukk4it6amuzljtnj44srqfif5p43oxnemyga",
                        "ocid1.subnet.oc1.iad.aaaaaaaaxiqvp52kdugxhyfv2svsbap34it4dymr2felbnjfi2lxjiwqvwnq",
                        "ocid1.subnet.oc1.iad.aaaaaaaap2rwkhbboizkwub3aialqrv3xnzw6s3vpjw7dfjjydbkzbckljca"
                    ]
                },
                "master_https_ingress_cidr": {
                    "sensitive": false,
                    "type": "string",
                    "value": "0.0.0.0/0"
                },
                "master_lb_backendset_name": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "backendset-https"
                    ]
                },
                "master_lb_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.loadbalancer.oc1.iad.aaaaaaaadynmpm3xzyc7x7zmcwvzbk2zirkl4ve6mzlemdroohmmyk22s3va"
                    ]
                },
                "master_lb_ip": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "129.213.198.168"
                    ]
                },
                "master_ssh_ingress_cidr": {
                    "sensitive": false,
                    "type": "string",
                    "value": "0.0.0.0/0"
                },
                "master_subnet_ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaa3mx26p2ylaqsw5no5qxnihqhxqdpqukkpt4msuevcpfguyat6d7a",
                        "ocid1.subnet.oc1.iad.aaaaaaaagyxrq2uygyhhyltjjc3ghljjrjq5sk5mpmevkfdjl5uuohnkjttq",
                        "ocid1.subnet.oc1.iad.aaaaaaaaumqfgoz6o7s32wqvf5ddowxz5likw5xepxcvi7xcv554w575acpa"
                    ]
                },
                "nat_instance_private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "10.0.13.2"
                    ]
                },
                "nat_instance_public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "129.213.127.98"
                    ]
                },
                "nat_subnet_ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                        "ocid1.subnet.oc1.iad.aaaaaaaamezfmzw4xkoduqzuxrsfreouitkhsxnmo4uukd4btrnrwxht4nyq",
                        "ocid1.subnet.oc1.iad.aaaaaaaak7bxex6ssockzoemup537dntkdllu44ltln224safckvdsnxrz6a",
                        ""
                    ]
                },
                "public_subnet_ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaagzy4dlm25w6gn7z523ss56qvdk3cnpfsrcigk3curx33toaktvja",
                        "ocid1.subnet.oc1.iad.aaaaaaaadcgbuknfac25c6tf5ivuyylpixb7uamdpzjz5u3sc6nq6jklfq7a",
                        "ocid1.subnet.oc1.iad.aaaaaaaanlzfxpjupyuol5g6o6ee3weqsthblapdwcltykn572yaxsrxba3q",
                        ""
                    ]
                },
                "root_ca_key": {
                    "sensitive": true,
                    "type": "string",
                    "value": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEAymZqiWDxK1tTDSfyUsDh5FL/geP8PxbqiU4ROdvG+wJby/na\n3x8+HHseS0+YgWIviIaR6Q71gZCbDwG3t9EHJpkfAAh5LlRiePi+JoPu9wThszXA\nRSOQei/M2Me+faE7fvaE1j/RNPfOuSu5p6bcGaiB/ujM5qwn0r5TTtEuYBEigLpa\nHdxCSMK7X9uWpckSvShB+qvn1xnkzQAbXdlLHkqir6+df4iFIMJytpg+t0cWrwq2\nNAf7y0N9X5UXsMaJyfW7UNHSkiLv4hc2U0XG1xHaxYZd4ErztCCf+nfLh/fHZBWM\n1lB0ZMuF6c+GW62E+Ig3KafYFgz7QR6kMiXBWwIDAQABAoIBAQCRsfeuvKHeW/cE\n2WSOPVpeSYCzt7G0mIJsJE4yIAq0VZZO1qS/SHYlelrsS3e0a0FcPcJ6ydHgWn/D\n5bCiGU3UcxTlqTPSLdxUyHnYr9As8M6nemHVYyx1SENlKSPuu0lgs4Qb1gR65Idi\ntB8ImAyIS8yH+nzE79ga0/aUHfAMJgDwxNS/Qi/fV+fbPXtmBlNol5QuUklkE4Qd\n7cXqWVJ2PF3f703lTRHe4TuN6q1E30yYTpxos7twwKpmLyzTzm/R9oaeOlhyQFfY\n9bbVI5Hq6mYBmgIXxkDH1tfoO9bi/aGhd80OYUiA4gUP3QBdTT2hFMbax/d1B0OS\n7+Ka/SABAoGBAPQ/LmVIY2dnzxgEAUt68r/MVnKxJyYdQCl4eLzdAFTpjdwVCoie\n/fv67K+mZ6AbWyxOdZZ0kuwg4ZQtXdB3ZXQjvV63fdm1/VmOE98s+Qlz1TXI/aQB\nsux8rwkKmdlXi2JqpAIeeAWAiu3eFbdDSt4kivoYtW+JpsjJPKEW0toBAoGBANQj\nvB0ZEfk3ICPBD2/rDkYu+B3UqXwaJ6ezPkk7FrX1cv8lfc44kHzXPhxo2LyQ06Ps\nARBXI0As/JIIAtH+7dmFijvA9TYLuNQ5+qi/nhlMglDKAKcxVcdTGWDDkQZhzTin\n3WKSbvLD5ZIAVzgjupaZ5Bp4JLXsvLa7f/U+JENbAoGBAM+/7fa4W9TYt4312iQZ\nr+D0LZPgmywQNUMQ9aGvWVjgT4mjXBJZKi/qfufo4ruMiUBmfB49ibrPPRCMhf+L\njv/6ZljqOmG0KorCDqUF283ueKwHCbc2urnsU/Wczr/Pdv9/NYGX6P7FF2a8QDxh\nQI0zCAMygSEeNH8UrD1Y7IABAoGBAIyPoPUmx2H5xLHsGe5uMOcP+BbL8gDo052q\nhnq/TC0ElU256cHaeOI/PEhWsEVBMPpMRegt1I2RQUkBRd0erTqT4SP2loNZAP6d\n7Bgj3v2kVDRzpDsj1VJdHVOgQVeZNgF0OJw3qovwgQxcbW4lPlzLWviu4qQoWGI7\nmm1E34JBAoGATte+c89TMfQl5Dc4MnAmdq9DSCWsXrfVRJ4K/MeatDzN5m2+XqOj\npgctDublYDL5c1HmWRcek7giD1IRnF9+m/gVbjoO8dDT+3+rcITcu//g2x2cRjCH\nZiseuXAkzsfPZXiLthtm5VlrBXBoEs++MVNR77eN+NB5VbkWRGtktS8=\n-----END RSA PRIVATE KEY-----\n"
                },
                "root_ca_pem": {
                    "sensitive": true,
                    "type": "string",
                    "value": "-----BEGIN CERTIFICATE-----\nMIIDDzCCAfegAwIBAgIQFEkWp10c+v5ochlZQwhCJzANBgkqhkiG9w0BAQsFADAS\nMRAwDgYDVQQDEwdrdWJlLWNhMB4XDTE5MDIwODAyMjExMVoXDTIxMTEwNDAyMjEx\nMVowEjEQMA4GA1UEAxMHa3ViZS1jYTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCC\nAQoCggEBAMpmaolg8StbUw0n8lLA4eRS/4Hj/D8W6olOETnbxvsCW8v52t8fPhx7\nHktPmIFiL4iGkekO9YGQmw8Bt7fRByaZHwAIeS5UYnj4viaD7vcE4bM1wEUjkHov\nzNjHvn2hO372hNY/0TT3zrkruaem3Bmogf7ozOasJ9K+U07RLmARIoC6Wh3cQkjC\nu1/blqXJEr0oQfqr59cZ5M0AG13ZSx5Koq+vnX+IhSDCcraYPrdHFq8KtjQH+8tD\nfV+VF7DGicn1u1DR0pIi7+IXNlNFxtcR2sWGXeBK87Qgn/p3y4f3x2QVjNZQdGTL\nhenPhluthPiINymn2BYM+0EepDIlwVsCAwEAAaNhMF8wDgYDVR0PAQH/BAQDAgIk\nMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjAPBgNVHRMBAf8EBTADAQH/\nMB0GA1UdDgQWBBS6+rNjI/caz2NksoVWV1ZpVuqZ0TANBgkqhkiG9w0BAQsFAAOC\nAQEAmM9CRYXe1O7mDrp5wRxQ0aLy87gsx6Z/Edb5s2cVA6EZPFDBS0dRJHy/WT9U\nd8u0nepGXHXu0/p4X4nErm8+06NQHgygjK8NGMtW0nxSS39IvlKQpepsYzHMrLV4\nBlYfzEMFyFeRTjHlIVF9p7J4aMBQVEA41J/rvphaNU2nXaThBE6VusaEj/k996L2\nHLvmmyS9zpIFk4hJtUaz2yNQfV8avCjmY3vpWofJ+YaHvWZ1LVYATlakmhwprqAt\nwiGw4skudV0gYHKxz1pazODcovll831MCFu/D0gtYj7E/bBpERs6RkiyRpoNdaan\nacnvk7icSK9cVkMMcKrDKfF3MA==\n-----END CERTIFICATE-----\n"
                },
                "ssh_private_key": {
                    "sensitive": true,
                    "type": "string",
                    "value": "-----BEGIN RSA PRIVATE KEY-----\nMIIEowIBAAKCAQEAt7t/HV5OGVYSIqjDpukZGTg+VF1KBhQeNS3ZSZdocvQkhFwq\nUUy7K6vnFp/l+zEw7TCQ9vwfAiMkbGJ6XmqEUHf7iXPK6z8nJ5VXbakyy9QzRlBd\nIDJL2p6nWDKf1VeRbk03MGZ5DT56cuW/ynyEPBY44DHWreqdTwBxltxPZuBum9su\nbV1kFwxMedyk6cp57aKPTKgO8p1VX2cGm7JDV3zMeof1tzwUkdK/NcPLDEBuW4nF\nFSsthTQB9sC4yL9Yp9tzBRryTk3H1cXTGweeS3NsCw+wSfrgpQ87i2UwQOa0wet9\nrjswGZg2zA5fXtKkO7B7HbihqA552eQiTOWF5wIDAQABAoIBAHI4/0qbwUPhDX88\nmf3fNjpGjAFYyddDlJANA+PLXCTzAOzEe451fHsm8JBRMeHa8AbVRZo2nXRvsoor\nItYltEJuhRMryIA9j7L9FhBXuvua3ZGeDncgraWpMnITbuhr+z6uhFvzqNgB+pAJ\noxVYGcFdM1i1wzf1/nwJ05QtPLPAT3oF1SFNcoVRyNaTHp6RLHk8UZVP5Cl4toFm\n60mnrWBhqVbXSwqIFTB9TDIHnO0zI5L7/x/P2Ya+iGjlCWAXcrwrIGxZA7hhU9pQ\n4HrjM8uOAsZPLXg28+x06rqDJoLy39k/1VqrzZ0Zwe4Qbf8vzbvWYONLtRtSYILd\n5f7j+vECgYEA2an2lnwypesBbELtG4tN6WqEkcYz06N8bW0ARiU3Va3B2NRJVYU4\n9k+9LgLehPRRSEbOlxtNISlGQGtKblwvhY3XHeYWjtBtfmaURwL5Izc2gq02YqfX\nd2RQXTZ37ZE4Woj+wf+xtFIHYJ2b5B5lg+l+sx8MIOUvPezeBvbzH7kCgYEA2Beg\n4KhfFwz1ByGKlowPgVXg99qNiBA/BaDff+xuJ3zcb+krlPSmGIsEgPXy69943gYB\nfsSMLMbyAKhf/VieqRmqek8YF7TcYirokXFJm8dgLXgZyKOJbpjwVezWrzq77PSI\nfFsLMaTF2tamB3c0iho8GzzkvGIWZWgXkAfAYp8CgYEAvc/g0ORnypbAe+d1G+ME\nQ3v3NaRRR8s207oNVh5YPegztmGRvflabjmlMP2hjPH9+/h7afyN61AyCjVGCC1t\n55qEsHcYztvl0CemQLLQDiy05Yoldi0F0gDxsAey18IfEZyMBSN0lVo/QrrO2kTD\npCA3s/5sNjeGVgs8p3gtFkkCgYBdEKgPuVPiuIjavl5SghW3bQYLmMu1mtGZmfRH\nwsqaJRNG+1Pyvf6+uTiCVep+HWuPq2R/dSStsCzPjbRxhvYl+9DJBkFpDFKR0MsC\nwJikB5TrYDsyhwQMZr+zMeIv64q9/X6+l/NVORKhMiqlMnilNbFHRc15OIFOwSrM\ntBnuHwKBgGEtmX8KeyrXCHVo4dfSoYbmrDXR+OutOHsh62XgQwD0RpS5dWCzhwQi\n5YHwJPZ0b5t08BW8IJmnFZbQLCgRUBmsT++OQ5kzZZfr5v7my5Dspkz6T77+syHx\nzHRKYLOZ23HbVOI/6PCfQkiTNMjt88PFhk6PupC7COqSqYOdRcPt\n-----END RSA PRIVATE KEY-----\n"
                },
                "ssh_public_key_openssh": {
                    "sensitive": true,
                    "type": "string",
                    "value": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3u38dXk4ZVhIiqMOm6RkZOD5UXUoGFB41LdlJl2hy9CSEXCpRTLsrq+cWn+X7MTDtMJD2/B8CIyRsYnpeaoRQd/uJc8rrPycnlVdtqTLL1DNGUF0gMkvanqdYMp/VV5FuTTcwZnkNPnpy5b/KfIQ8FjjgMdat6p1PAHGW3E9m4G6b2y5tXWQXDEx53KTpynntoo9MqA7ynVVfZwabskNXfMx6h/W3PBSR0r81w8sMQG5bicUVKy2FNAH2wLjIv1in23MFGvJOTcfVxdMbB55Lc2wLD7BJ+uClDzuLZTBA5rTB632uOzAZmDbMDl9e0qQ7sHsduKGoDnnZ5CJM5YXn\n"
                },
                "vcn_dhcp_options_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq"
                },
                "vcn_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                },
                "vcn_route_for_complete_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda"
                },
                "worker_node_port_ingress_cidr": {
                    "sensitive": false,
                    "type": "string",
                    "value": "0.0.0.0/0"
                },
                "worker_ssh_ingress_cidr": {
                    "sensitive": false,
                    "type": "string",
                    "value": "0.0.0.0/0"
                },
                "worker_subnet_ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaaefqwgcbfss43qxjvcrovz3a6zaqskdfyuif65b7eqpuz3omexuhq",
                        "ocid1.subnet.oc1.iad.aaaaaaaabhkzbvfotkst2mbwxyloesuq6pcvmkext3tjddfjdm3coo2geikq",
                        "ocid1.subnet.oc1.iad.aaaaaaaavop32xhqq7frm4ahwe7mwazf6soe3wtizx7wmvh4jqxfzjv7p6uq"
                    ]
                }
            },
            "resources": {
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.090614797 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "id": "2019-02-08 02:20:52.090614797 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "null_resource.build_source": {
                    "type": "null_resource",
                    "depends_on": [],
                    "primary": {
                        "id": "5883423591269295129",
                        "attributes": {
                            "id": "5883423591269295129"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.null"
                },
                "template_file.etcd_discovery_url": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
                        "attributes": {
                            "id": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855",
                            "rendered": ""
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "etcd-lb"
            ],
            "outputs": {
                "backendset_2379_name": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "lb-backendset-etcd-2379"
                    ]
                },
                "backendset_2380_name": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "lb-backendset-etcd-2380"
                    ]
                },
                "ip_addresses": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "129.213.69.178"
                    ]
                },
                "load_balancer_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q"
                    ]
                }
            },
            "resources": {
                "oci_load_balancer.lb-etcd": {
                    "type": "oci_load_balancer",
                    "depends_on": [],
                    "primary": {
                        "id": "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "lb-etcd",
                            "id": "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q",
                            "ip_addresses.#": "1",
                            "ip_addresses.0": "129.213.69.178",
                            "is_private": "false",
                            "shape": "400Mbps",
                            "state": "ACTIVE",
                            "subnet_ids.#": "2",
                            "subnet_ids.0": "ocid1.subnet.oc1.iad.aaaaaaaagzy4dlm25w6gn7z523ss56qvdk3cnpfsrcigk3curx33toaktvja",
                            "subnet_ids.1": "ocid1.subnet.oc1.iad.aaaaaaaadcgbuknfac25c6tf5ivuyylpixb7uamdpzjz5u3sc6nq6jklfq7a",
                            "time_created": "2019-02-08 02:23:14.802 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_load_balancer_backendset.lb-etcd-backendset-2379": {
                    "type": "oci_load_balancer_backendset",
                    "depends_on": [
                        "oci_load_balancer.lb-etcd"
                    ],
                    "primary": {
                        "id": "lb-backendset-etcd-2379",
                        "attributes": {
                            "backend.#": "0",
                            "health_checker.#": "1",
                            "health_checker.0.interval_ms": "30000",
                            "health_checker.0.port": "2379",
                            "health_checker.0.protocol": "TCP",
                            "health_checker.0.response_body_regex": ".*",
                            "health_checker.0.retries": "3",
                            "health_checker.0.return_code": "200",
                            "health_checker.0.timeout_in_millis": "3000",
                            "health_checker.0.url_path": "",
                            "id": "lb-backendset-etcd-2379",
                            "load_balancer_id": "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q",
                            "name": "lb-backendset-etcd-2379",
                            "policy": "ROUND_ROBIN",
                            "session_persistence_configuration.#": "0",
                            "ssl_configuration.#": "0",
                            "state": "SUCCEEDED"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_load_balancer_backendset.lb-etcd-backendset-2380": {
                    "type": "oci_load_balancer_backendset",
                    "depends_on": [
                        "oci_load_balancer.lb-etcd"
                    ],
                    "primary": {
                        "id": "lb-backendset-etcd-2380",
                        "attributes": {
                            "backend.#": "0",
                            "health_checker.#": "1",
                            "health_checker.0.interval_ms": "30000",
                            "health_checker.0.port": "2380",
                            "health_checker.0.protocol": "TCP",
                            "health_checker.0.response_body_regex": ".*",
                            "health_checker.0.retries": "3",
                            "health_checker.0.return_code": "200",
                            "health_checker.0.timeout_in_millis": "3000",
                            "health_checker.0.url_path": "",
                            "id": "lb-backendset-etcd-2380",
                            "load_balancer_id": "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q",
                            "name": "lb-backendset-etcd-2380",
                            "policy": "ROUND_ROBIN",
                            "session_persistence_configuration.#": "0",
                            "ssl_configuration.#": "0",
                            "state": "SUCCEEDED"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_load_balancer_listener.port-2379": {
                    "type": "oci_load_balancer_listener",
                    "depends_on": [
                        "oci_load_balancer.lb-etcd",
                        "oci_load_balancer_backendset.lb-etcd-backendset-2379"
                    ],
                    "primary": {
                        "id": "port-2379",
                        "attributes": {
                            "connection_configuration.#": "1",
                            "connection_configuration.0.idle_timeout_in_seconds": "300",
                            "default_backend_set_name": "lb-backendset-etcd-2379",
                            "hostname_names.#": "0",
                            "id": "port-2379",
                            "load_balancer_id": "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q",
                            "name": "port-2379",
                            "port": "2379",
                            "protocol": "TCP",
                            "ssl_configuration.#": "0",
                            "state": "SUCCEEDED"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_load_balancer_listener.port-2380": {
                    "type": "oci_load_balancer_listener",
                    "depends_on": [
                        "oci_load_balancer.lb-etcd",
                        "oci_load_balancer_backendset.lb-etcd-backendset-2380"
                    ],
                    "primary": {
                        "id": "port-2380",
                        "attributes": {
                            "connection_configuration.#": "1",
                            "connection_configuration.0.idle_timeout_in_seconds": "300",
                            "default_backend_set_name": "lb-backendset-etcd-2380",
                            "hostname_names.#": "0",
                            "id": "port-2380",
                            "load_balancer_id": "ocid1.loadbalancer.oc1.iad.aaaaaaaaw7nrzjse4gubcouoefyy7epsdsqra4zrz43dibt2wl63tx7pte6q",
                            "name": "port-2380",
                            "port": "2380",
                            "protocol": "TCP",
                            "ssl_configuration.#": "0",
                            "state": "SUCCEEDED"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-etcd-ad1"
            ],
            "outputs": {
                "hostname_label": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "instance_public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.843728271 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:51.843728271 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.982518002 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.982518002 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.etcd-bootstrap": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "34fff0c487629d0de655b508537f7435dc209434656c102d81e85d2a53f75262",
                        "attributes": {
                            "id": "34fff0c487629d0de655b508537f7435dc209434656c102d81e85d2a53f75262",
                            "rendered": "#!/bin/bash -x\n\n# Turn off SELinux\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsetenforce 0\n\n# Set working dir\ncd /home/opc\n\n# enable ol7 addons\nyum-config-manager --disable ol7_UEKR3\nyum-config-manager --enable ol7_addons ol7_latest ol7_UEKR4 ol7_optional ol7_optional_latest\n\n# Install Docker\nuntil yum -y install docker-engine-17.06.2.ol; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=50m --log-opt max-file=5\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\n# Start Docker\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n\ndocker info\n\n###################\n# Drop firewall rules\niptables -F\n\n###################\n# etcd\n\n# Get IP Address of self\nIP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\n\nHOSTNAME=$(hostname)\nFQDN_HOSTNAME=\"$(getent hosts $IP_LOCAL | awk '{print $2}')\"\n\n## Login iSCSI volume mount and create filesystem at /etcd\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"${iqn}\" ]; then\n    echo \"iSCSI Login ${iqn}\"\n    iscsiadm -m node -o new -T ${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T ${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T ${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1) /etcd xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p  /etcd\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\"  /etcd\nfi\n\ndocker run -d \\\n        --restart=always \\\n\t-p 2380:2380 -p 2379:2379 \\\n\t-v /etc/ssl/certs/ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt \\\n\t-v /etcd:/$HOSTNAME.etcd \\\n\t--net=host \\\n\tquay.io/coreos/etcd:v3.2.2 \\\n\t/usr/local/bin/etcd \\\n\t-name $HOSTNAME \\\n\t-advertise-client-urls http://$IP_LOCAL:2379 \\\n\t-listen-client-urls http://$IP_LOCAL:2379,http://127.0.0.1:2379 \\\n\t-listen-peer-urls http://0.0.0.0:2380 \\\n\t-discovery https://discovery.etcd.io/b76bcf381cf9e59b1a3d9518458c47c2\n\n# wait for etcd to become active\nwhile ! curl -sf -o /dev/null http://$FQDN_HOSTNAME:2379/v2/keys/; do\n\tsleep 1\n\techo \"Try again\"\ndone\n\n# Download etcdctl client etcd_ver\nwhile ! curl -L https://github.com/coreos/etcd/releases/download/v3.2.2/etcd-v3.2.2-linux-amd64.tar.gz -o /tmp/etcd-v3.2.2-linux-amd64.tar.gz; do\n\tsleep 1\n\t((secs++)) \u0026\u0026 ((secs==10)) \u0026\u0026 break\n\techo \"Try again\"\ndone\ntar zxf /tmp/etcd-v3.2.2-linux-amd64.tar.gz -C /tmp/ \u0026\u0026 cp /tmp/etcd-v3.2.2-linux-amd64/etcd* /usr/local/bin/\n",
                            "template": "#!/bin/bash -x\n\n# Turn off SELinux\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsetenforce 0\n\n# Set working dir\ncd /home/opc\n\n# enable ol7 addons\nyum-config-manager --disable ol7_UEKR3\nyum-config-manager --enable ol7_addons ol7_latest ol7_UEKR4 ol7_optional ol7_optional_latest\n\n# Install Docker\nuntil yum -y install docker-engine-${docker_ver}; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=${docker_max_log_size} --log-opt max-file=${docker_max_log_files}\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\n# Start Docker\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n\ndocker info\n\n###################\n# Drop firewall rules\niptables -F\n\n###################\n# etcd\n\n# Get IP Address of self\nIP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\n\nHOSTNAME=$(hostname)\nFQDN_HOSTNAME=\"$(getent hosts $IP_LOCAL | awk '{print $2}')\"\n\n## Login iSCSI volume mount and create filesystem at /etcd\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"$${iqn}\" ]; then\n    echo \"iSCSI Login $${iqn}\"\n    iscsiadm -m node -o new -T $${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T $${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T $${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1) /etcd xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p  /etcd\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\"  /etcd\nfi\n\ndocker run -d \\\n        --restart=always \\\n\t-p 2380:2380 -p 2379:2379 \\\n\t-v /etc/ssl/certs/ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt \\\n\t-v /etcd:/$HOSTNAME.etcd \\\n\t--net=host \\\n\tquay.io/coreos/etcd:${etcd_ver} \\\n\t/usr/local/bin/etcd \\\n\t-name $HOSTNAME \\\n\t-advertise-client-urls http://$IP_LOCAL:2379 \\\n\t-listen-client-urls http://$IP_LOCAL:2379,http://127.0.0.1:2379 \\\n\t-listen-peer-urls http://0.0.0.0:2380 \\\n\t-discovery ${etcd_discovery_url}\n\n# wait for etcd to become active\nwhile ! curl -sf -o /dev/null http://$FQDN_HOSTNAME:2379/v2/keys/; do\n\tsleep 1\n\techo \"Try again\"\ndone\n\n# Download etcdctl client etcd_ver\nwhile ! curl -L https://github.com/coreos/etcd/releases/download/${etcd_ver}/etcd-${etcd_ver}-linux-amd64.tar.gz -o /tmp/etcd-${etcd_ver}-linux-amd64.tar.gz; do\n\tsleep 1\n\t((secs++)) \u0026\u0026 ((secs==10)) \u0026\u0026 break\n\techo \"Try again\"\ndone\ntar zxf /tmp/etcd-${etcd_ver}-linux-amd64.tar.gz -C /tmp/ \u0026\u0026 cp /tmp/etcd-${etcd_ver}-linux-amd64/etcd* /usr/local/bin/\n",
                            "vars.%": "6",
                            "vars.docker_max_log_files": "5",
                            "vars.docker_max_log_size": "50m",
                            "vars.docker_ver": "17.06.2.ol",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.etcd_discovery_url": "https://discovery.etcd.io/b76bcf381cf9e59b1a3d9518458c47c2",
                            "vars.etcd_ver": "v3.2.2"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-etcd-ad2"
            ],
            "outputs": {},
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.988786871 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:51.988786871 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.053060612 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:52.053060612 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.etcd-bootstrap": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "34fff0c487629d0de655b508537f7435dc209434656c102d81e85d2a53f75262",
                        "attributes": {
                            "id": "34fff0c487629d0de655b508537f7435dc209434656c102d81e85d2a53f75262",
                            "rendered": "#!/bin/bash -x\n\n# Turn off SELinux\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsetenforce 0\n\n# Set working dir\ncd /home/opc\n\n# enable ol7 addons\nyum-config-manager --disable ol7_UEKR3\nyum-config-manager --enable ol7_addons ol7_latest ol7_UEKR4 ol7_optional ol7_optional_latest\n\n# Install Docker\nuntil yum -y install docker-engine-17.06.2.ol; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=50m --log-opt max-file=5\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\n# Start Docker\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n\ndocker info\n\n###################\n# Drop firewall rules\niptables -F\n\n###################\n# etcd\n\n# Get IP Address of self\nIP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\n\nHOSTNAME=$(hostname)\nFQDN_HOSTNAME=\"$(getent hosts $IP_LOCAL | awk '{print $2}')\"\n\n## Login iSCSI volume mount and create filesystem at /etcd\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"${iqn}\" ]; then\n    echo \"iSCSI Login ${iqn}\"\n    iscsiadm -m node -o new -T ${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T ${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T ${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1) /etcd xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p  /etcd\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\"  /etcd\nfi\n\ndocker run -d \\\n        --restart=always \\\n\t-p 2380:2380 -p 2379:2379 \\\n\t-v /etc/ssl/certs/ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt \\\n\t-v /etcd:/$HOSTNAME.etcd \\\n\t--net=host \\\n\tquay.io/coreos/etcd:v3.2.2 \\\n\t/usr/local/bin/etcd \\\n\t-name $HOSTNAME \\\n\t-advertise-client-urls http://$IP_LOCAL:2379 \\\n\t-listen-client-urls http://$IP_LOCAL:2379,http://127.0.0.1:2379 \\\n\t-listen-peer-urls http://0.0.0.0:2380 \\\n\t-discovery https://discovery.etcd.io/b76bcf381cf9e59b1a3d9518458c47c2\n\n# wait for etcd to become active\nwhile ! curl -sf -o /dev/null http://$FQDN_HOSTNAME:2379/v2/keys/; do\n\tsleep 1\n\techo \"Try again\"\ndone\n\n# Download etcdctl client etcd_ver\nwhile ! curl -L https://github.com/coreos/etcd/releases/download/v3.2.2/etcd-v3.2.2-linux-amd64.tar.gz -o /tmp/etcd-v3.2.2-linux-amd64.tar.gz; do\n\tsleep 1\n\t((secs++)) \u0026\u0026 ((secs==10)) \u0026\u0026 break\n\techo \"Try again\"\ndone\ntar zxf /tmp/etcd-v3.2.2-linux-amd64.tar.gz -C /tmp/ \u0026\u0026 cp /tmp/etcd-v3.2.2-linux-amd64/etcd* /usr/local/bin/\n",
                            "template": "#!/bin/bash -x\n\n# Turn off SELinux\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsetenforce 0\n\n# Set working dir\ncd /home/opc\n\n# enable ol7 addons\nyum-config-manager --disable ol7_UEKR3\nyum-config-manager --enable ol7_addons ol7_latest ol7_UEKR4 ol7_optional ol7_optional_latest\n\n# Install Docker\nuntil yum -y install docker-engine-${docker_ver}; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=${docker_max_log_size} --log-opt max-file=${docker_max_log_files}\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\n# Start Docker\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n\ndocker info\n\n###################\n# Drop firewall rules\niptables -F\n\n###################\n# etcd\n\n# Get IP Address of self\nIP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\n\nHOSTNAME=$(hostname)\nFQDN_HOSTNAME=\"$(getent hosts $IP_LOCAL | awk '{print $2}')\"\n\n## Login iSCSI volume mount and create filesystem at /etcd\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"$${iqn}\" ]; then\n    echo \"iSCSI Login $${iqn}\"\n    iscsiadm -m node -o new -T $${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T $${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T $${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1) /etcd xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p  /etcd\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\"  /etcd\nfi\n\ndocker run -d \\\n        --restart=always \\\n\t-p 2380:2380 -p 2379:2379 \\\n\t-v /etc/ssl/certs/ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt \\\n\t-v /etcd:/$HOSTNAME.etcd \\\n\t--net=host \\\n\tquay.io/coreos/etcd:${etcd_ver} \\\n\t/usr/local/bin/etcd \\\n\t-name $HOSTNAME \\\n\t-advertise-client-urls http://$IP_LOCAL:2379 \\\n\t-listen-client-urls http://$IP_LOCAL:2379,http://127.0.0.1:2379 \\\n\t-listen-peer-urls http://0.0.0.0:2380 \\\n\t-discovery ${etcd_discovery_url}\n\n# wait for etcd to become active\nwhile ! curl -sf -o /dev/null http://$FQDN_HOSTNAME:2379/v2/keys/; do\n\tsleep 1\n\techo \"Try again\"\ndone\n\n# Download etcdctl client etcd_ver\nwhile ! curl -L https://github.com/coreos/etcd/releases/download/${etcd_ver}/etcd-${etcd_ver}-linux-amd64.tar.gz -o /tmp/etcd-${etcd_ver}-linux-amd64.tar.gz; do\n\tsleep 1\n\t((secs++)) \u0026\u0026 ((secs==10)) \u0026\u0026 break\n\techo \"Try again\"\ndone\ntar zxf /tmp/etcd-${etcd_ver}-linux-amd64.tar.gz -C /tmp/ \u0026\u0026 cp /tmp/etcd-${etcd_ver}-linux-amd64/etcd* /usr/local/bin/\n",
                            "vars.%": "6",
                            "vars.docker_max_log_files": "5",
                            "vars.docker_max_log_size": "50m",
                            "vars.docker_ver": "17.06.2.ol",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.etcd_discovery_url": "https://discovery.etcd.io/b76bcf381cf9e59b1a3d9518458c47c2",
                            "vars.etcd_ver": "v3.2.2"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-etcd-ad3"
            ],
            "outputs": {
                "hostname_label": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "instance_public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.164210236 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:52.164210236 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.718644946 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.718644946 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.etcd-bootstrap": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "34fff0c487629d0de655b508537f7435dc209434656c102d81e85d2a53f75262",
                        "attributes": {
                            "id": "34fff0c487629d0de655b508537f7435dc209434656c102d81e85d2a53f75262",
                            "rendered": "#!/bin/bash -x\n\n# Turn off SELinux\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsetenforce 0\n\n# Set working dir\ncd /home/opc\n\n# enable ol7 addons\nyum-config-manager --disable ol7_UEKR3\nyum-config-manager --enable ol7_addons ol7_latest ol7_UEKR4 ol7_optional ol7_optional_latest\n\n# Install Docker\nuntil yum -y install docker-engine-17.06.2.ol; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=50m --log-opt max-file=5\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\n# Start Docker\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n\ndocker info\n\n###################\n# Drop firewall rules\niptables -F\n\n###################\n# etcd\n\n# Get IP Address of self\nIP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\n\nHOSTNAME=$(hostname)\nFQDN_HOSTNAME=\"$(getent hosts $IP_LOCAL | awk '{print $2}')\"\n\n## Login iSCSI volume mount and create filesystem at /etcd\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"${iqn}\" ]; then\n    echo \"iSCSI Login ${iqn}\"\n    iscsiadm -m node -o new -T ${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T ${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T ${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1) /etcd xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p  /etcd\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\"  /etcd\nfi\n\ndocker run -d \\\n        --restart=always \\\n\t-p 2380:2380 -p 2379:2379 \\\n\t-v /etc/ssl/certs/ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt \\\n\t-v /etcd:/$HOSTNAME.etcd \\\n\t--net=host \\\n\tquay.io/coreos/etcd:v3.2.2 \\\n\t/usr/local/bin/etcd \\\n\t-name $HOSTNAME \\\n\t-advertise-client-urls http://$IP_LOCAL:2379 \\\n\t-listen-client-urls http://$IP_LOCAL:2379,http://127.0.0.1:2379 \\\n\t-listen-peer-urls http://0.0.0.0:2380 \\\n\t-discovery https://discovery.etcd.io/b76bcf381cf9e59b1a3d9518458c47c2\n\n# wait for etcd to become active\nwhile ! curl -sf -o /dev/null http://$FQDN_HOSTNAME:2379/v2/keys/; do\n\tsleep 1\n\techo \"Try again\"\ndone\n\n# Download etcdctl client etcd_ver\nwhile ! curl -L https://github.com/coreos/etcd/releases/download/v3.2.2/etcd-v3.2.2-linux-amd64.tar.gz -o /tmp/etcd-v3.2.2-linux-amd64.tar.gz; do\n\tsleep 1\n\t((secs++)) \u0026\u0026 ((secs==10)) \u0026\u0026 break\n\techo \"Try again\"\ndone\ntar zxf /tmp/etcd-v3.2.2-linux-amd64.tar.gz -C /tmp/ \u0026\u0026 cp /tmp/etcd-v3.2.2-linux-amd64/etcd* /usr/local/bin/\n",
                            "template": "#!/bin/bash -x\n\n# Turn off SELinux\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsetenforce 0\n\n# Set working dir\ncd /home/opc\n\n# enable ol7 addons\nyum-config-manager --disable ol7_UEKR3\nyum-config-manager --enable ol7_addons ol7_latest ol7_UEKR4 ol7_optional ol7_optional_latest\n\n# Install Docker\nuntil yum -y install docker-engine-${docker_ver}; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=${docker_max_log_size} --log-opt max-file=${docker_max_log_files}\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\n# Start Docker\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl restart docker\n\ndocker info\n\n###################\n# Drop firewall rules\niptables -F\n\n###################\n# etcd\n\n# Get IP Address of self\nIP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\n\nHOSTNAME=$(hostname)\nFQDN_HOSTNAME=\"$(getent hosts $IP_LOCAL | awk '{print $2}')\"\n\n## Login iSCSI volume mount and create filesystem at /etcd\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"$${iqn}\" ]; then\n    echo \"iSCSI Login $${iqn}\"\n    iscsiadm -m node -o new -T $${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T $${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T $${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1) /etcd xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p  /etcd\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\"  /etcd\nfi\n\ndocker run -d \\\n        --restart=always \\\n\t-p 2380:2380 -p 2379:2379 \\\n\t-v /etc/ssl/certs/ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt \\\n\t-v /etcd:/$HOSTNAME.etcd \\\n\t--net=host \\\n\tquay.io/coreos/etcd:${etcd_ver} \\\n\t/usr/local/bin/etcd \\\n\t-name $HOSTNAME \\\n\t-advertise-client-urls http://$IP_LOCAL:2379 \\\n\t-listen-client-urls http://$IP_LOCAL:2379,http://127.0.0.1:2379 \\\n\t-listen-peer-urls http://0.0.0.0:2380 \\\n\t-discovery ${etcd_discovery_url}\n\n# wait for etcd to become active\nwhile ! curl -sf -o /dev/null http://$FQDN_HOSTNAME:2379/v2/keys/; do\n\tsleep 1\n\techo \"Try again\"\ndone\n\n# Download etcdctl client etcd_ver\nwhile ! curl -L https://github.com/coreos/etcd/releases/download/${etcd_ver}/etcd-${etcd_ver}-linux-amd64.tar.gz -o /tmp/etcd-${etcd_ver}-linux-amd64.tar.gz; do\n\tsleep 1\n\t((secs++)) \u0026\u0026 ((secs==10)) \u0026\u0026 break\n\techo \"Try again\"\ndone\ntar zxf /tmp/etcd-${etcd_ver}-linux-amd64.tar.gz -C /tmp/ \u0026\u0026 cp /tmp/etcd-${etcd_ver}-linux-amd64/etcd* /usr/local/bin/\n",
                            "vars.%": "6",
                            "vars.docker_max_log_files": "5",
                            "vars.docker_max_log_size": "50m",
                            "vars.docker_ver": "17.06.2.ol",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.etcd_discovery_url": "https://discovery.etcd.io/b76bcf381cf9e59b1a3d9518458c47c2",
                            "vars.etcd_ver": "v3.2.2"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-k8smaster-ad1"
            ],
            "outputs": {},
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.240156768 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:52.240156768 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.097136684 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:52.097136684 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.kube-controller-manager": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "f199d0575867308e584ad7956a69c9868630ade13659cf0bb4fc5d299f0de985",
                        "attributes": {
                            "id": "f199d0575867308e584ad7956a69c9868630ade13659cf0bb4fc5d299f0de985",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-controller-manager\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - controller-manager\n    - --master=http://127.0.0.1:8080\n    - --cluster-cidr=10.99.0.0/16\n    - --cluster-name=dev-cluster\n    - --leader-elect=true\n    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n    - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem\n    - --v=2\n    - --allocate-node-cidrs=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    volumeMounts:\n    - mountPath: /etc/kubernetes/ssl\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/kubernetes/ca\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/ssl\n      name: ssl-certs-host\n      readOnly: true\n    - mountPath: /etc/pki\n      name: pki-certs-host\n      readOnly: true\n    - mountPath: /usr/libexec/kubernetes/kubelet-plugins\n      name: plugins\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/ssl\n    name: ssl-certs-kubernetes\n  - hostPath:\n      path: /etc/ssl\n    name: ssl-certs-host\n  - hostPath:\n      path: /etc/pki\n    name: pki-certs-host\n  - hostPath:\n      path: /usr/libexec/kubernetes/kubelet-plugins\n    name: plugins\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-controller-manager\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - controller-manager\n    - --master=http://127.0.0.1:8080\n    - --cluster-cidr=${flannel_network_cidr}\n    - --cluster-name=dev-cluster\n    - --leader-elect=true\n    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n    - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem\n    - --v=2\n    - --allocate-node-cidrs=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    volumeMounts:\n    - mountPath: /etc/kubernetes/ssl\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/kubernetes/ca\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/ssl\n      name: ssl-certs-host\n      readOnly: true\n    - mountPath: /etc/pki\n      name: pki-certs-host\n      readOnly: true\n    - mountPath: /usr/libexec/kubernetes/kubelet-plugins\n      name: plugins\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/ssl\n    name: ssl-certs-kubernetes\n  - hostPath:\n      path: /etc/ssl\n    name: ssl-certs-host\n  - hostPath:\n      path: /etc/pki\n    name: pki-certs-host\n  - hostPath:\n      path: /usr/libexec/kubernetes/kubelet-plugins\n    name: plugins\n",
                            "vars.%": "2",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-dashboard": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "c76017e2cb39f567a2a6fdfcdad567b2e74966217a21910411d1a92815144237",
                        "attributes": {
                            "id": "c76017e2cb39f567a2a6fdfcdad567b2e74966217a21910411d1a92815144237",
                            "rendered": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3\n        ports:\n        - containerPort: 9090\n          protocol: TCP\n        args:\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    k8s-app: kubernetes-dashboard",
                            "template": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v${k8s_dashboard_ver}\n        ports:\n        - containerPort: 9090\n          protocol: TCP\n        args:\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    k8s-app: kubernetes-dashboard",
                            "vars.%": "1",
                            "vars.k8s_dashboard_ver": "1.6.3"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-dns": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "3716feb66bc29b32eaeda859c1b0e3e785f7e86a344398cb5769b708c8290204",
                        "attributes": {
                            "id": "3716feb66bc29b32eaeda859c1b0e3e785f7e86a344398cb5769b708c8290204",
                            "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"KubeDNS\"\nspec:\n  clusterIP: 10.21.21.21\n  selector:\n    k8s-app: kube-dns\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\nspec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator: \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n          name: kube-dns\n          optional: true\n      containers:\n      - name: kubedns\n        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.2\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 3\n          timeoutSeconds: 5\n        args:\n        - --domain=cluster.local.\n        - --dns-port=10053\n        - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        - name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort: 10053\n          name: dns-local\n          protocol: UDP\n        - containerPort: 10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort: 10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /kube-dns-config\n      - name: dnsmasq\n        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.2\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/dnsmasq\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n        - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n        - --log-facility=-\n        - --server=/cluster.local/127.0.0.1#10053\n        - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 150m\n            memory: 20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.2\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A\n        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A\n        ports:\n        - containerPort: 10054\n          name: metrics\n          protocol: TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n      dnsPolicy: Default\n      serviceAccountName: kube-dns\n",
                            "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"KubeDNS\"\nspec:\n  clusterIP: 10.21.21.21\n  selector:\n    k8s-app: kube-dns\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\nspec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator: \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n          name: kube-dns\n          optional: true\n      containers:\n      - name: kubedns\n        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:${k8s_dns_ver}\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 3\n          timeoutSeconds: 5\n        args:\n        - --domain=${pillar_dns_domain}.\n        - --dns-port=10053\n        - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        - name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort: 10053\n          name: dns-local\n          protocol: UDP\n        - containerPort: 10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort: 10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /kube-dns-config\n      - name: dnsmasq\n        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:${k8s_dns_ver}\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/dnsmasq\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n        - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n        - --log-facility=-\n        - --server=/${pillar_dns_domain}/127.0.0.1#10053\n        - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 150m\n            memory: 20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:${k8s_dns_ver}\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.${pillar_dns_domain},5,A\n        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.${pillar_dns_domain},5,A\n        ports:\n        - containerPort: 10054\n          name: metrics\n          protocol: TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n      dnsPolicy: Default\n      serviceAccountName: kube-dns\n",
                            "vars.%": "2",
                            "vars.k8s_dns_ver": "1.14.2",
                            "vars.pillar_dns_domain": "cluster.local"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-proxy": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "4daf8d3641dd92070c9e84b4cf17c71cc19e74bedb4af11fdf6d8d000d06e4b0",
                        "attributes": {
                            "id": "4daf8d3641dd92070c9e84b4cf17c71cc19e74bedb4af11fdf6d8d000d06e4b0",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=http://127.0.0.1:8080\n    - --proxy-mode=iptables\n    - --cluster-cidr=10.99.0.0/16\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /etc/ssl/certs\n      name: ssl-certs-host\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /usr/share/ca-certificates\n    name: ssl-certs-host\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=http://127.0.0.1:8080\n    - --proxy-mode=iptables\n    - --cluster-cidr=${flannel_network_cidr}\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /etc/ssl/certs\n      name: ssl-certs-host\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /usr/share/ca-certificates\n    name: ssl-certs-host\n",
                            "vars.%": "2",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-rbac": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "7ce383c29d9fa93327323556d8e7d61e48480a89a4453c7aa63f7d0d59d0a7df",
                        "attributes": {
                            "id": "7ce383c29d9fa93327323556d8e7d61e48480a89a4453c7aa63f7d0d59d0a7df",
                            "rendered": "apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: system:default-sa\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io",
                            "template": "apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: system:default-sa\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-scheduler": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "30341f281cdb808d4111f7364d1485472f3dee3c308219d134005b782b0dd271",
                        "attributes": {
                            "id": "30341f281cdb808d4111f7364d1485472f3dee3c308219d134005b782b0dd271",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-scheduler\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-scheduler\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - scheduler\n    - --master=http://127.0.0.1:8080\n    - --leader-elect=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10251\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-scheduler\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-scheduler\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - scheduler\n    - --master=http://127.0.0.1:8080\n    - --leader-elect=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10251\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kubelet-service": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "52786bcea2f96bedb2984740aaef12cc54533cb81c5b17c35f9a3080f7063cb3",
                        "attributes": {
                            "id": "52786bcea2f96bedb2984740aaef12cc54533cb81c5b17c35f9a3080f7063cb3",
                            "rendered": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/master-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/master= \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --cloud-provider=external \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "template": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/master-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/master= \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --cloud-provider=external \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.master-kubeconfig": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "53c44372429bc338961ccc28edd15ae9ecfa8384ae1b9a3bef64ed2f84f5ac1c",
                        "attributes": {
                            "id": "53c44372429bc338961ccc28edd15ae9ecfa8384ae1b9a3bef64ed2f84f5ac1c",
                            "rendered": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    server: http://localhost:8080\ncontexts:\n- context:\n    cluster: local\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "template": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    server: http://localhost:8080\ncontexts:\n- context:\n    cluster: local\n  name: kubelet-context\ncurrent-context: kubelet-context\n"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-preflight": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "1cd3c0b842e6bedf246ce3aa2462de01e1595d8057c3b1a91c3ce549b21e4205",
                        "attributes": {
                            "id": "1cd3c0b842e6bedf246ce3aa2462de01e1595d8057c3b1a91c3ce549b21e4205",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/auth /etc/kubernetes/manifests/\n\nbash -x /root/setup.sh | tee -a /root/setup.log\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/auth /etc/kubernetes/manifests/\n\nbash -x /root/setup.sh | tee -a /root/setup.log\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.token_auth_file": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "dbc198ba8d7813184410ab8dd91efdfa30b1b5c04f94c4d65c2c478e0bfa82ea",
                        "attributes": {
                            "id": "dbc198ba8d7813184410ab8dd91efdfa30b1b5c04f94c4d65c2c478e0bfa82ea",
                            "rendered": "56d89cea5bd825c5dcaedfbf8bd6bf5e,admin,admin,\"system:masters\"",
                            "template": "${token_admin},admin,admin,\"system:masters\"",
                            "vars.%": "1",
                            "vars.token_admin": "56d89cea5bd825c5dcaedfbf8bd6bf5e"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-k8smaster-ad2"
            ],
            "outputs": {
                "ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.025029528 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:52.025029528 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.741622617 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.741622617 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.kube-controller-manager": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "f199d0575867308e584ad7956a69c9868630ade13659cf0bb4fc5d299f0de985",
                        "attributes": {
                            "id": "f199d0575867308e584ad7956a69c9868630ade13659cf0bb4fc5d299f0de985",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-controller-manager\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - controller-manager\n    - --master=http://127.0.0.1:8080\n    - --cluster-cidr=10.99.0.0/16\n    - --cluster-name=dev-cluster\n    - --leader-elect=true\n    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n    - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem\n    - --v=2\n    - --allocate-node-cidrs=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    volumeMounts:\n    - mountPath: /etc/kubernetes/ssl\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/kubernetes/ca\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/ssl\n      name: ssl-certs-host\n      readOnly: true\n    - mountPath: /etc/pki\n      name: pki-certs-host\n      readOnly: true\n    - mountPath: /usr/libexec/kubernetes/kubelet-plugins\n      name: plugins\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/ssl\n    name: ssl-certs-kubernetes\n  - hostPath:\n      path: /etc/ssl\n    name: ssl-certs-host\n  - hostPath:\n      path: /etc/pki\n    name: pki-certs-host\n  - hostPath:\n      path: /usr/libexec/kubernetes/kubelet-plugins\n    name: plugins\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-controller-manager\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - controller-manager\n    - --master=http://127.0.0.1:8080\n    - --cluster-cidr=${flannel_network_cidr}\n    - --cluster-name=dev-cluster\n    - --leader-elect=true\n    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n    - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem\n    - --v=2\n    - --allocate-node-cidrs=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    volumeMounts:\n    - mountPath: /etc/kubernetes/ssl\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/kubernetes/ca\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/ssl\n      name: ssl-certs-host\n      readOnly: true\n    - mountPath: /etc/pki\n      name: pki-certs-host\n      readOnly: true\n    - mountPath: /usr/libexec/kubernetes/kubelet-plugins\n      name: plugins\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/ssl\n    name: ssl-certs-kubernetes\n  - hostPath:\n      path: /etc/ssl\n    name: ssl-certs-host\n  - hostPath:\n      path: /etc/pki\n    name: pki-certs-host\n  - hostPath:\n      path: /usr/libexec/kubernetes/kubelet-plugins\n    name: plugins\n",
                            "vars.%": "2",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-dashboard": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "c76017e2cb39f567a2a6fdfcdad567b2e74966217a21910411d1a92815144237",
                        "attributes": {
                            "id": "c76017e2cb39f567a2a6fdfcdad567b2e74966217a21910411d1a92815144237",
                            "rendered": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3\n        ports:\n        - containerPort: 9090\n          protocol: TCP\n        args:\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    k8s-app: kubernetes-dashboard",
                            "template": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v${k8s_dashboard_ver}\n        ports:\n        - containerPort: 9090\n          protocol: TCP\n        args:\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    k8s-app: kubernetes-dashboard",
                            "vars.%": "1",
                            "vars.k8s_dashboard_ver": "1.6.3"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-dns": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "3716feb66bc29b32eaeda859c1b0e3e785f7e86a344398cb5769b708c8290204",
                        "attributes": {
                            "id": "3716feb66bc29b32eaeda859c1b0e3e785f7e86a344398cb5769b708c8290204",
                            "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"KubeDNS\"\nspec:\n  clusterIP: 10.21.21.21\n  selector:\n    k8s-app: kube-dns\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\nspec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator: \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n          name: kube-dns\n          optional: true\n      containers:\n      - name: kubedns\n        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.2\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 3\n          timeoutSeconds: 5\n        args:\n        - --domain=cluster.local.\n        - --dns-port=10053\n        - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        - name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort: 10053\n          name: dns-local\n          protocol: UDP\n        - containerPort: 10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort: 10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /kube-dns-config\n      - name: dnsmasq\n        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.2\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/dnsmasq\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n        - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n        - --log-facility=-\n        - --server=/cluster.local/127.0.0.1#10053\n        - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 150m\n            memory: 20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.2\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A\n        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A\n        ports:\n        - containerPort: 10054\n          name: metrics\n          protocol: TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n      dnsPolicy: Default\n      serviceAccountName: kube-dns\n",
                            "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"KubeDNS\"\nspec:\n  clusterIP: 10.21.21.21\n  selector:\n    k8s-app: kube-dns\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\nspec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator: \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n          name: kube-dns\n          optional: true\n      containers:\n      - name: kubedns\n        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:${k8s_dns_ver}\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 3\n          timeoutSeconds: 5\n        args:\n        - --domain=${pillar_dns_domain}.\n        - --dns-port=10053\n        - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        - name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort: 10053\n          name: dns-local\n          protocol: UDP\n        - containerPort: 10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort: 10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /kube-dns-config\n      - name: dnsmasq\n        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:${k8s_dns_ver}\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/dnsmasq\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n        - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n        - --log-facility=-\n        - --server=/${pillar_dns_domain}/127.0.0.1#10053\n        - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 150m\n            memory: 20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:${k8s_dns_ver}\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.${pillar_dns_domain},5,A\n        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.${pillar_dns_domain},5,A\n        ports:\n        - containerPort: 10054\n          name: metrics\n          protocol: TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n      dnsPolicy: Default\n      serviceAccountName: kube-dns\n",
                            "vars.%": "2",
                            "vars.k8s_dns_ver": "1.14.2",
                            "vars.pillar_dns_domain": "cluster.local"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-proxy": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "4daf8d3641dd92070c9e84b4cf17c71cc19e74bedb4af11fdf6d8d000d06e4b0",
                        "attributes": {
                            "id": "4daf8d3641dd92070c9e84b4cf17c71cc19e74bedb4af11fdf6d8d000d06e4b0",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=http://127.0.0.1:8080\n    - --proxy-mode=iptables\n    - --cluster-cidr=10.99.0.0/16\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /etc/ssl/certs\n      name: ssl-certs-host\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /usr/share/ca-certificates\n    name: ssl-certs-host\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=http://127.0.0.1:8080\n    - --proxy-mode=iptables\n    - --cluster-cidr=${flannel_network_cidr}\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /etc/ssl/certs\n      name: ssl-certs-host\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /usr/share/ca-certificates\n    name: ssl-certs-host\n",
                            "vars.%": "2",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-rbac": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "7ce383c29d9fa93327323556d8e7d61e48480a89a4453c7aa63f7d0d59d0a7df",
                        "attributes": {
                            "id": "7ce383c29d9fa93327323556d8e7d61e48480a89a4453c7aa63f7d0d59d0a7df",
                            "rendered": "apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: system:default-sa\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io",
                            "template": "apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: system:default-sa\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-scheduler": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "30341f281cdb808d4111f7364d1485472f3dee3c308219d134005b782b0dd271",
                        "attributes": {
                            "id": "30341f281cdb808d4111f7364d1485472f3dee3c308219d134005b782b0dd271",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-scheduler\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-scheduler\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - scheduler\n    - --master=http://127.0.0.1:8080\n    - --leader-elect=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10251\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-scheduler\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-scheduler\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - scheduler\n    - --master=http://127.0.0.1:8080\n    - --leader-elect=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10251\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kubelet-service": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "52786bcea2f96bedb2984740aaef12cc54533cb81c5b17c35f9a3080f7063cb3",
                        "attributes": {
                            "id": "52786bcea2f96bedb2984740aaef12cc54533cb81c5b17c35f9a3080f7063cb3",
                            "rendered": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/master-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/master= \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --cloud-provider=external \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "template": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/master-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/master= \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --cloud-provider=external \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.master-kubeconfig": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "53c44372429bc338961ccc28edd15ae9ecfa8384ae1b9a3bef64ed2f84f5ac1c",
                        "attributes": {
                            "id": "53c44372429bc338961ccc28edd15ae9ecfa8384ae1b9a3bef64ed2f84f5ac1c",
                            "rendered": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    server: http://localhost:8080\ncontexts:\n- context:\n    cluster: local\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "template": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    server: http://localhost:8080\ncontexts:\n- context:\n    cluster: local\n  name: kubelet-context\ncurrent-context: kubelet-context\n"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-preflight": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "1cd3c0b842e6bedf246ce3aa2462de01e1595d8057c3b1a91c3ce549b21e4205",
                        "attributes": {
                            "id": "1cd3c0b842e6bedf246ce3aa2462de01e1595d8057c3b1a91c3ce549b21e4205",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/auth /etc/kubernetes/manifests/\n\nbash -x /root/setup.sh | tee -a /root/setup.log\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/auth /etc/kubernetes/manifests/\n\nbash -x /root/setup.sh | tee -a /root/setup.log\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.token_auth_file": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "dbc198ba8d7813184410ab8dd91efdfa30b1b5c04f94c4d65c2c478e0bfa82ea",
                        "attributes": {
                            "id": "dbc198ba8d7813184410ab8dd91efdfa30b1b5c04f94c4d65c2c478e0bfa82ea",
                            "rendered": "56d89cea5bd825c5dcaedfbf8bd6bf5e,admin,admin,\"system:masters\"",
                            "template": "${token_admin},admin,admin,\"system:masters\"",
                            "vars.%": "1",
                            "vars.token_admin": "56d89cea5bd825c5dcaedfbf8bd6bf5e"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-k8smaster-ad3"
            ],
            "outputs": {
                "ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:52.033375083 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:52.033375083 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.960149308 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.960149308 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.kube-controller-manager": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "f199d0575867308e584ad7956a69c9868630ade13659cf0bb4fc5d299f0de985",
                        "attributes": {
                            "id": "f199d0575867308e584ad7956a69c9868630ade13659cf0bb4fc5d299f0de985",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-controller-manager\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - controller-manager\n    - --master=http://127.0.0.1:8080\n    - --cluster-cidr=10.99.0.0/16\n    - --cluster-name=dev-cluster\n    - --leader-elect=true\n    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n    - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem\n    - --v=2\n    - --allocate-node-cidrs=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    volumeMounts:\n    - mountPath: /etc/kubernetes/ssl\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/kubernetes/ca\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/ssl\n      name: ssl-certs-host\n      readOnly: true\n    - mountPath: /etc/pki\n      name: pki-certs-host\n      readOnly: true\n    - mountPath: /usr/libexec/kubernetes/kubelet-plugins\n      name: plugins\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/ssl\n    name: ssl-certs-kubernetes\n  - hostPath:\n      path: /etc/ssl\n    name: ssl-certs-host\n  - hostPath:\n      path: /etc/pki\n    name: pki-certs-host\n  - hostPath:\n      path: /usr/libexec/kubernetes/kubelet-plugins\n    name: plugins\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-controller-manager\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-controller-manager\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - controller-manager\n    - --master=http://127.0.0.1:8080\n    - --cluster-cidr=${flannel_network_cidr}\n    - --cluster-name=dev-cluster\n    - --leader-elect=true\n    - --service-account-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem\n    - --root-ca-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem\n    - --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem\n    - --v=2\n    - --allocate-node-cidrs=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10252\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n    volumeMounts:\n    - mountPath: /etc/kubernetes/ssl\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/kubernetes/ca\n      name: ssl-certs-kubernetes\n      readOnly: true\n    - mountPath: /etc/ssl\n      name: ssl-certs-host\n      readOnly: true\n    - mountPath: /etc/pki\n      name: pki-certs-host\n      readOnly: true\n    - mountPath: /usr/libexec/kubernetes/kubelet-plugins\n      name: plugins\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/ssl\n    name: ssl-certs-kubernetes\n  - hostPath:\n      path: /etc/ssl\n    name: ssl-certs-host\n  - hostPath:\n      path: /etc/pki\n    name: pki-certs-host\n  - hostPath:\n      path: /usr/libexec/kubernetes/kubelet-plugins\n    name: plugins\n",
                            "vars.%": "2",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-dashboard": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "c76017e2cb39f567a2a6fdfcdad567b2e74966217a21910411d1a92815144237",
                        "attributes": {
                            "id": "c76017e2cb39f567a2a6fdfcdad567b2e74966217a21910411d1a92815144237",
                            "rendered": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3\n        ports:\n        - containerPort: 9090\n          protocol: TCP\n        args:\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    k8s-app: kubernetes-dashboard",
                            "template": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      k8s-app: kubernetes-dashboard\n  template:\n    metadata:\n      labels:\n        k8s-app: kubernetes-dashboard\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v${k8s_dashboard_ver}\n        ports:\n        - containerPort: 9090\n          protocol: TCP\n        args:\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 9090\n          initialDelaySeconds: 30\n          timeoutSeconds: 30\n      serviceAccountName: kubernetes-dashboard\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n---\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kube-system\nspec:\n  ports:\n  - port: 80\n    targetPort: 9090\n  selector:\n    k8s-app: kubernetes-dashboard",
                            "vars.%": "1",
                            "vars.k8s_dashboard_ver": "1.6.3"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-dns": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "3716feb66bc29b32eaeda859c1b0e3e785f7e86a344398cb5769b708c8290204",
                        "attributes": {
                            "id": "3716feb66bc29b32eaeda859c1b0e3e785f7e86a344398cb5769b708c8290204",
                            "rendered": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"KubeDNS\"\nspec:\n  clusterIP: 10.21.21.21\n  selector:\n    k8s-app: kube-dns\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\nspec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator: \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n          name: kube-dns\n          optional: true\n      containers:\n      - name: kubedns\n        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.2\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 3\n          timeoutSeconds: 5\n        args:\n        - --domain=cluster.local.\n        - --dns-port=10053\n        - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        - name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort: 10053\n          name: dns-local\n          protocol: UDP\n        - containerPort: 10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort: 10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /kube-dns-config\n      - name: dnsmasq\n        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.2\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/dnsmasq\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n        - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n        - --log-facility=-\n        - --server=/cluster.local/127.0.0.1#10053\n        - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 150m\n            memory: 20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.2\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A\n        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A\n        ports:\n        - containerPort: 10054\n          name: metrics\n          protocol: TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n      dnsPolicy: Default\n      serviceAccountName: kube-dns\n",
                            "template": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\n  labels:\n    addonmanager.kubernetes.io/mode: EnsureExists\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\n    kubernetes.io/name: \"KubeDNS\"\nspec:\n  clusterIP: 10.21.21.21\n  selector:\n    k8s-app: kube-dns\n  ports:\n  - name: dns\n    port: 53\n    protocol: UDP\n  - name: dns-tcp\n    port: 53\n    protocol: TCP\n---\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: kube-dns\n  namespace: kube-system\n  labels:\n    k8s-app: kube-dns\n    kubernetes.io/cluster-service: \"true\"\n    addonmanager.kubernetes.io/mode: Reconcile\nspec:\n  strategy:\n    rollingUpdate:\n      maxSurge: 10%\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n      annotations:\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      tolerations:\n      - key: \"CriticalAddonsOnly\"\n        operator: \"Exists\"\n      volumes:\n      - name: kube-dns-config\n        configMap:\n          name: kube-dns\n          optional: true\n      containers:\n      - name: kubedns\n        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:${k8s_dns_ver}\n        resources:\n          limits:\n            memory: 170Mi\n          requests:\n            cpu: 100m\n            memory: 70Mi\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/kubedns\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        readinessProbe:\n          httpGet:\n            path: /readiness\n            port: 8081\n            scheme: HTTP\n          initialDelaySeconds: 3\n          timeoutSeconds: 5\n        args:\n        - --domain=${pillar_dns_domain}.\n        - --dns-port=10053\n        - --config-dir=/kube-dns-config\n        - --v=2\n        env:\n        - name: PROMETHEUS_PORT\n          value: \"10055\"\n        ports:\n        - containerPort: 10053\n          name: dns-local\n          protocol: UDP\n        - containerPort: 10053\n          name: dns-tcp-local\n          protocol: TCP\n        - containerPort: 10055\n          name: metrics\n          protocol: TCP\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /kube-dns-config\n      - name: dnsmasq\n        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:${k8s_dns_ver}\n        livenessProbe:\n          httpGet:\n            path: /healthcheck/dnsmasq\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - -v=2\n        - -logtostderr\n        - -configDir=/etc/k8s/dns/dnsmasq-nanny\n        - -restartDnsmasq=true\n        - --\n        - -k\n        - --cache-size=1000\n        - --log-facility=-\n        - --server=/${pillar_dns_domain}/127.0.0.1#10053\n        - --server=/in-addr.arpa/127.0.0.1#10053\n        - --server=/ip6.arpa/127.0.0.1#10053\n        ports:\n        - containerPort: 53\n          name: dns\n          protocol: UDP\n        - containerPort: 53\n          name: dns-tcp\n          protocol: TCP\n        resources:\n          requests:\n            cpu: 150m\n            memory: 20Mi\n        volumeMounts:\n        - name: kube-dns-config\n          mountPath: /etc/k8s/dns/dnsmasq-nanny\n      - name: sidecar\n        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:${k8s_dns_ver}\n        livenessProbe:\n          httpGet:\n            path: /metrics\n            port: 10054\n            scheme: HTTP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 5\n        args:\n        - --v=2\n        - --logtostderr\n        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.${pillar_dns_domain},5,A\n        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.${pillar_dns_domain},5,A\n        ports:\n        - containerPort: 10054\n          name: metrics\n          protocol: TCP\n        resources:\n          requests:\n            memory: 20Mi\n            cpu: 10m\n      dnsPolicy: Default\n      serviceAccountName: kube-dns\n",
                            "vars.%": "2",
                            "vars.k8s_dns_ver": "1.14.2",
                            "vars.pillar_dns_domain": "cluster.local"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-proxy": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "4daf8d3641dd92070c9e84b4cf17c71cc19e74bedb4af11fdf6d8d000d06e4b0",
                        "attributes": {
                            "id": "4daf8d3641dd92070c9e84b4cf17c71cc19e74bedb4af11fdf6d8d000d06e4b0",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=http://127.0.0.1:8080\n    - --proxy-mode=iptables\n    - --cluster-cidr=10.99.0.0/16\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /etc/ssl/certs\n      name: ssl-certs-host\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /usr/share/ca-certificates\n    name: ssl-certs-host\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=http://127.0.0.1:8080\n    - --proxy-mode=iptables\n    - --cluster-cidr=${flannel_network_cidr}\n    securityContext:\n      privileged: true\n    volumeMounts:\n    - mountPath: /etc/ssl/certs\n      name: ssl-certs-host\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /usr/share/ca-certificates\n    name: ssl-certs-host\n",
                            "vars.%": "2",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-rbac": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "7ce383c29d9fa93327323556d8e7d61e48480a89a4453c7aa63f7d0d59d0a7df",
                        "attributes": {
                            "id": "7ce383c29d9fa93327323556d8e7d61e48480a89a4453c7aa63f7d0d59d0a7df",
                            "rendered": "apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: system:default-sa\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io",
                            "template": "apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: system:default-sa\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kube-scheduler": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "30341f281cdb808d4111f7364d1485472f3dee3c308219d134005b782b0dd271",
                        "attributes": {
                            "id": "30341f281cdb808d4111f7364d1485472f3dee3c308219d134005b782b0dd271",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-scheduler\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-scheduler\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - scheduler\n    - --master=http://127.0.0.1:8080\n    - --leader-elect=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10251\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-scheduler\n  namespace: kube-system\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-scheduler\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - scheduler\n    - --master=http://127.0.0.1:8080\n    - --leader-elect=true\n    livenessProbe:\n      httpGet:\n        host: 127.0.0.1\n        path: /healthz\n        port: 10251\n      initialDelaySeconds: 15\n      timeoutSeconds: 1\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kubelet-service": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "52786bcea2f96bedb2984740aaef12cc54533cb81c5b17c35f9a3080f7063cb3",
                        "attributes": {
                            "id": "52786bcea2f96bedb2984740aaef12cc54533cb81c5b17c35f9a3080f7063cb3",
                            "rendered": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/master-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/master= \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --cloud-provider=external \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "template": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/master-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/master= \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --cloud-provider=external \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  --register-with-taints=node-role.kubernetes.io/master=:NoSchedule \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.master-kubeconfig": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "53c44372429bc338961ccc28edd15ae9ecfa8384ae1b9a3bef64ed2f84f5ac1c",
                        "attributes": {
                            "id": "53c44372429bc338961ccc28edd15ae9ecfa8384ae1b9a3bef64ed2f84f5ac1c",
                            "rendered": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    server: http://localhost:8080\ncontexts:\n- context:\n    cluster: local\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "template": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    server: http://localhost:8080\ncontexts:\n- context:\n    cluster: local\n  name: kubelet-context\ncurrent-context: kubelet-context\n"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-preflight": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "1cd3c0b842e6bedf246ce3aa2462de01e1595d8057c3b1a91c3ce549b21e4205",
                        "attributes": {
                            "id": "1cd3c0b842e6bedf246ce3aa2462de01e1595d8057c3b1a91c3ce549b21e4205",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/auth /etc/kubernetes/manifests/\n\nbash -x /root/setup.sh | tee -a /root/setup.log\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/auth /etc/kubernetes/manifests/\n\nbash -x /root/setup.sh | tee -a /root/setup.log\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.token_auth_file": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "dbc198ba8d7813184410ab8dd91efdfa30b1b5c04f94c4d65c2c478e0bfa82ea",
                        "attributes": {
                            "id": "dbc198ba8d7813184410ab8dd91efdfa30b1b5c04f94c4d65c2c478e0bfa82ea",
                            "rendered": "56d89cea5bd825c5dcaedfbf8bd6bf5e,admin,admin,\"system:masters\"",
                            "template": "${token_admin},admin,admin,\"system:masters\"",
                            "vars.%": "1",
                            "vars.token_admin": "56d89cea5bd825c5dcaedfbf8bd6bf5e"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-k8sworker-ad1"
            ],
            "outputs": {
                "ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "instance_host_names": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.864114217 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:51.864114217 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.853487402 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.853487402 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.kube-proxy": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "60d085ced18e28432b36e3e82aaa6ca7758ce6100f5709f67bb301c692c56116",
                        "attributes": {
                            "id": "60d085ced18e28432b36e3e82aaa6ca7758ce6100f5709f67bb301c692c56116",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=https://129.213.198.168:443\n    - --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml\n    - --proxy-mode=iptables\n    - --cluster-cidr=10.99.0.0/16\n    - --masquerade-all\n    - --hostname-override=__FQDN_HOSTNAME__\n    - --v=2\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/ssl/certs\n        name: \"ssl-certs\"\n      - mountPath: /etc/kubernetes/manifests/worker-kubeconfig.yaml\n        name: \"kubeconfig\"\n        readOnly: true\n      - mountPath: /etc/kubernetes/ssl\n        name: \"etc-kube-ssl\"\n        readOnly: true\n  volumes:\n    - name: \"ssl-certs\"\n      hostPath:\n        path: \"/usr/share/ca-certificates\"\n    - name: \"kubeconfig\"\n      hostPath:\n        path: \"/etc/kubernetes/manifests/worker-kubeconfig.yaml\"\n    - name: \"etc-kube-ssl\"\n      hostPath:\n        path: \"/etc/kubernetes/ssl\"\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=${master_lb}\n    - --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml\n    - --proxy-mode=iptables\n    - --cluster-cidr=${flannel_network_cidr}\n    - --masquerade-all\n    - --hostname-override=__FQDN_HOSTNAME__\n    - --v=2\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/ssl/certs\n        name: \"ssl-certs\"\n      - mountPath: /etc/kubernetes/manifests/worker-kubeconfig.yaml\n        name: \"kubeconfig\"\n        readOnly: true\n      - mountPath: /etc/kubernetes/ssl\n        name: \"etc-kube-ssl\"\n        readOnly: true\n  volumes:\n    - name: \"ssl-certs\"\n      hostPath:\n        path: \"/usr/share/ca-certificates\"\n    - name: \"kubeconfig\"\n      hostPath:\n        path: \"/etc/kubernetes/manifests/worker-kubeconfig.yaml\"\n    - name: \"etc-kube-ssl\"\n      hostPath:\n        path: \"/etc/kubernetes/ssl\"\n",
                            "vars.%": "4",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kubelet-service": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "1185a7c27b544af4f1656a0b6fd4ff9e2233d624485dad2cd355e26c0a94b438",
                        "attributes": {
                            "id": "1185a7c27b544af4f1656a0b6fd4ff9e2233d624485dad2cd355e26c0a94b438",
                            "rendered": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --docker=unix:///var/run/docker.sock \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/node=,failure-domain.beta.kubernetes.io/region=us-ashburn-1,failure-domain.beta.kubernetes.io/zone=US-ASHBURN-AD-1,node.info/external.ipaddress=__EXT_IP__,node.info/availability.domain=__AVAILABILITY_DOMAIN__,node.info/compartment.id_prefix=__COMPARTMENT_ID_PREFIX__,node.info/compartment.id_suffix=__COMPARTMENT_ID_SUFFIX__,node.info/node.id_prefix=__NODE_ID_PREFIX__,node.info/node.id_suffix=__NODE_ID_SUFFIX__,node.info/node.shape=__NODE_SHAPE__ \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --serialize-image-pulls=false \\\n  --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem \\\n  --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --eviction-hard=memory.available\u003c500Mi,nodefs.available\u003c2Gi,imagefs.available\u003c2Gi \\\n  --cloud-provider=external \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "template": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --docker=unix:///var/run/docker.sock \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/node=,failure-domain.beta.kubernetes.io/region=${region},failure-domain.beta.kubernetes.io/zone=${zone},node.info/external.ipaddress=__EXT_IP__,node.info/availability.domain=__AVAILABILITY_DOMAIN__,node.info/compartment.id_prefix=__COMPARTMENT_ID_PREFIX__,node.info/compartment.id_suffix=__COMPARTMENT_ID_SUFFIX__,node.info/node.id_prefix=__NODE_ID_PREFIX__,node.info/node.id_suffix=__NODE_ID_SUFFIX__,node.info/node.shape=__NODE_SHAPE__ \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --serialize-image-pulls=false \\\n  --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem \\\n  --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --eviction-hard=memory.available\u003c500Mi,nodefs.available\u003c2Gi,imagefs.available\u003c2Gi \\\n  --cloud-provider=external \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "vars.%": "5",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443",
                            "vars.region": "us-ashburn-1",
                            "vars.zone": "US-ASHBURN-AD-1"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-preflight": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "9044b796cb8623c6c6980dc3bea4d2971116d9e0f7a7128261f21b024e4110ec",
                        "attributes": {
                            "id": "9044b796cb8623c6c6980dc3bea4d2971116d9e0f7a7128261f21b024e4110ec",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/manifests /etc/kubernetes/auth\n\n# add tools\ncurl --retry 3 http://stedolan.github.io/jq/download/linux64/jq -o /usr/local/bin/jq \u0026\u0026 chmod +x /usr/local/bin/jq\nbash -x /root/setup.sh 2\u003e\u00261 | tee -a /root/setup.log\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/manifests /etc/kubernetes/auth\n\n# add tools\ncurl --retry 3 http://stedolan.github.io/jq/download/linux64/jq -o /usr/local/bin/jq \u0026\u0026 chmod +x /usr/local/bin/jq\nbash -x /root/setup.sh 2\u003e\u00261 | tee -a /root/setup.log\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-template": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "e5a1155228712888eec83dd354c04583fa422cee9889c6e1ed1ce562e4a17d03",
                        "attributes": {
                            "id": "e5a1155228712888eec83dd354c04583fa422cee9889c6e1ed1ce562e4a17d03",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\nNAMESPACE=$(echo -n \"kubernetes.oraclevcn.com\" | sed \"s/\\.oraclevcn\\.com//g\")\nFQDN_HOSTNAME=$(hostname -f)\n\n# Pull instance metadata\ncurl -sL --retry 3 http://169.254.169.254/opc/v1/instance/ | tee /tmp/instance_meta.json\n\n## Create policy file that blocks autostart of services on install\nprintf '#!/bin/sh\\necho \"All runlevel operations denied by policy\" \u003e\u00262\\nexit 101\\n' \u003e/tmp/policy-rc.d \u0026\u0026 chmod +x /tmp/policy-rc.d\nexport K8S_API_SERVER_LB=https://129.213.198.168:443\nexport RANDFILE=$(mktemp)\nexport HOSTNAME=$(hostname)\n\nexport IP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\n\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\nexport WORKER_IP=$IP_LOCAL\n\n## k8s_ver swap option\n######################################\nk8sversion=\"1.9.6\"\n\nif [[ $k8sversion =~ ^[0-1]+\\.[0-7]+ ]]; then\n    SWAP_OPTION=\"\"\nelse\n    SWAP_OPTION=\"--fail-swap-on=false\"\nfi\n\n## Disable TX checksum offloading so we don't break VXLAN\n######################################\nBROADCOM_DRIVER=$(lsmod | grep bnxt_en | awk '{print $1}')\nif [[ -n \"${BROADCOM_DRIVER}\" ]]; then\n   echo \"Disabling hardware TX checksum offloading\"\n   ethtool --offload $(ip -o -4 route show to default | awk '{print $5}') tx off\nfi\n\n## Setup NVMe drives and mount at /var/lib/docker\n######################################\nNVMEVGNAME=\"NVMeVG\"\nNVMELVNAME=\"DockerVol\"\nNVMEDEVS=$(lsblk -I259 -pn -oNAME -d)\nif [[ ! -z \"${NVMEDEVS}\" ]]; then\n    lvs ${NVMEVGNAME}/${NVMELVNAME} --noheadings --logonly 1\u003e/dev/null\n    if [ $$? -ne 0 ]; then\n\tpvcreate ${NVMEDEVS}\n\tvgcreate ${NVMEVGNAME} ${NVMEDEVS}\n\tlvcreate --extents 100%FREE --name ${NVMELVNAME} ${NVMEVGNAME} ${NVMEDEVS}\n\tmkfs -t xfs /dev/${NVMEVGNAME}/${NVMELVNAME}\n\tmkdir -p /var/lib/docker\n\tmount -t xfs /dev/${NVMEVGNAME}/${NVMELVNAME} /var/lib/docker\n\techo \"/dev/${NVMEVGNAME}/${NVMELVNAME} /var/lib/docker xfs rw,relatime,seclabel,attr2,inode64,noquota 0 2\" \u003e\u003e /etc/fstab\n    fi\nfi\n\n## Login iSCSI volume mount and create filesystem\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"${iqn}\" ]; then\n    echo \"iSCSI Login ${iqn}\"\n    iscsiadm -m node -o new -T ${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T ${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T ${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1) /var/lib/docker xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p /var/lib/docker\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" /var/lib/docker\nfi\n\nuntil yum -y install docker-engine-17.06.2.ol; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=50m --log-opt max-file=5\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl start docker\n\n## Output /etc/environment_params\n######################################\necho \"IPV4_PRIVATE_0=$IP_LOCAL\" \u003e\u003e/etc/environment_params\necho \"ETCD_IP=$ETCD_ENDPOINTS\" \u003e\u003e/etc/environment_params\necho \"K8S_API_SERVER_LB=$K8S_API_SERVER_LB\" \u003e\u003e/etc/environment_params\necho \"FQDN_HOSTNAME=$FQDN_HOSTNAME\" \u003e\u003e/etc/environment_params\n\n## Drop firewall rules\n######################################\niptables -F\n\ncat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\n# Disable SELinux and firewall\nsetenforce 0\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsystemctl stop firewalld.service\nsystemctl disable firewalld.service\n\n## Install Flex Volume Driver for OCI\n#####################################\nmkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/\ncurl -L --retry 3 https://github.com/oracle/oci-flexvolume-driver/releases/download/0.7.1/oci -o/usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\nchmod a+x /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\n\n\n## Install kubelet, kubectl, and kubernetes-cni\n###############################################\nyum-config-manager --add-repo http://yum.kubernetes.io/repos/kubernetes-el7-x86_64\nyum search -y kubernetes\n\nVER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep 1.9.6 | tail -n 1)\nif [[ -z \"${VER_IN_REPO}\" ]]; then\n   MAJOR_VER=$(echo 1.9.6 | cut -d. -f-2)\n   echo \"Falling back to latest version available in: $MAJOR_VER\"\n   VER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep $MAJOR_VER | tail -n 1)\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\n   ## Replace kubelet binary since rpm at the exact k8s_ver was not available.\n   curl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v1.9.6/bin/linux/amd64/kubelet -o /bin/kubelet \u0026\u0026 chmod 755 /bin/kubelet\nelse\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\nfi\n\n# Check if kubernetes-cni was automatically installed as a dependency\nK8S_CNI=$(rpm -qa | grep kubernetes-cni)\nif [[ -z \"${K8S_CNI}\" ]]; then\n   echo \"Installing: $K8S_CNI\"\n   yum install -y kubernetes-cni\nelse\n   echo \"$K8S_CNI already installed\"\nfi\n\ncurl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v1.9.6/bin/linux/amd64/kubectl -o /bin/kubectl \u0026\u0026 chmod 755 /bin/kubectl\n\n## FQDN constructed from live environment since DNS label for the subnet is optional\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" /etc/kubernetes/manifests/kube-proxy.yaml \u003e/tmp/kube-proxy.yaml\ncat /tmp/kube-proxy.yaml \u003e/etc/kubernetes/manifests/kube-proxy.yaml\n\n## kubelet for the worker\n######################################\nsystemctl daemon-reload\n\nAVAILABILITY_DOMAIN=$(jq -r '.availabilityDomain' /tmp/instance_meta.json | sed 's/:/-/g')\nread COMPARTMENT_ID_0 COMPARTMENT_ID_1 \u003c\u003c\u003c $(jq -r '.compartmentId' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nread NODE_ID_0 NODE_ID_1 \u003c\u003c\u003c $(jq -r '.id' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nNODE_SHAPE=$(jq -r '.shape' /tmp/instance_meta.json)\n\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" \\\n    -e \"s/__EXT_IP__/$EXTERNAL_IP/g\" \\\n    -e \"s/__AVAILABILITY_DOMAIN__/$AVAILABILITY_DOMAIN/g\" \\\n    -e \"s/__COMPARTMENT_ID_PREFIX__/$COMPARTMENT_ID_0/g\" \\\n    -e \"s/__COMPARTMENT_ID_SUFFIX__/$COMPARTMENT_ID_1/g\" \\\n    -e \"s/__NODE_ID_PREFIX__/$NODE_ID_0/g\" \\\n    -e \"s/__NODE_ID_SUFFIX__/$NODE_ID_1/g\" \\\n    -e \"s/__NODE_SHAPE__/$NODE_SHAPE/g\" \\\n    -e \"s/__SWAP_OPTION__/$SWAP_OPTION/g\" \\\n    /root/services/kubelet.service \u003e /etc/systemd/system/kubelet.service\n\n\n## Wait for k8s master to be available. There is a possible race on pod networks otherwise.\nuntil [ \"$(curl -k --cert /etc/kubernetes/ssl/apiserver.pem --key /etc/kubernetes/ssl/apiserver-key.pem $K8S_API_SERVER_LB/healthz 2\u003e/dev/null)\" == \"ok\" ]; do\n\tsleep 3\ndone\n\n# Setup CUDA devices before starting kubelet, so it detects the gpu(s)\n/sbin/modprobe nvidia\nif [ \"$?\" -eq 0 ]; then\n\t# Create the /dev/nvidia* files by running nvidia-smi\n\tnvidia-smi\nfi\n\n/sbin/modprobe nvidia-uvm\nif [ \"$?\" -eq 0 ]; then\n\t# Find out the major device number used by the nvidia-uvm driver\n\tDEVICE=$(grep nvidia-uvm /proc/devices | awk '{print $1}')\n\tmknod -m 666 /dev/nvidia-uvm c $DEVICE 0\nfi\n\nsleep $[ ( $RANDOM % 10 )  + 1 ]s\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n\nyum install -y nfs-utils\n\n######################################\necho \"Finished running setup.sh\"\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\nNAMESPACE=$(echo -n \"${domain_name}\" | sed \"s/\\.oraclevcn\\.com//g\")\nFQDN_HOSTNAME=$(hostname -f)\n\n# Pull instance metadata\ncurl -sL --retry 3 http://169.254.169.254/opc/v1/instance/ | tee /tmp/instance_meta.json\n\n## Create policy file that blocks autostart of services on install\nprintf '#!/bin/sh\\necho \"All runlevel operations denied by policy\" \u003e\u00262\\nexit 101\\n' \u003e/tmp/policy-rc.d \u0026\u0026 chmod +x /tmp/policy-rc.d\nexport K8S_API_SERVER_LB=${master_lb}\nexport RANDFILE=$(mktemp)\nexport HOSTNAME=$(hostname)\n\nexport IP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\n\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\nexport WORKER_IP=$IP_LOCAL\n\n## k8s_ver swap option\n######################################\nk8sversion=\"${k8s_ver}\"\n\nif [[ $k8sversion =~ ^[0-1]+\\.[0-7]+ ]]; then\n    SWAP_OPTION=\"\"\nelse\n    SWAP_OPTION=\"--fail-swap-on=false\"\nfi\n\n## Disable TX checksum offloading so we don't break VXLAN\n######################################\nBROADCOM_DRIVER=$(lsmod | grep bnxt_en | awk '{print $1}')\nif [[ -n \"$${BROADCOM_DRIVER}\" ]]; then\n   echo \"Disabling hardware TX checksum offloading\"\n   ethtool --offload $(ip -o -4 route show to default | awk '{print $5}') tx off\nfi\n\n## Setup NVMe drives and mount at /var/lib/docker\n######################################\nNVMEVGNAME=\"NVMeVG\"\nNVMELVNAME=\"DockerVol\"\nNVMEDEVS=$(lsblk -I259 -pn -oNAME -d)\nif [[ ! -z \"$${NVMEDEVS}\" ]]; then\n    lvs $${NVMEVGNAME}/$${NVMELVNAME} --noheadings --logonly 1\u003e/dev/null\n    if [ $$? -ne 0 ]; then\n\tpvcreate $${NVMEDEVS}\n\tvgcreate $${NVMEVGNAME} $${NVMEDEVS}\n\tlvcreate --extents 100%FREE --name $${NVMELVNAME} $${NVMEVGNAME} $${NVMEDEVS}\n\tmkfs -t xfs /dev/$${NVMEVGNAME}/$${NVMELVNAME}\n\tmkdir -p /var/lib/docker\n\tmount -t xfs /dev/$${NVMEVGNAME}/$${NVMELVNAME} /var/lib/docker\n\techo \"/dev/$${NVMEVGNAME}/$${NVMELVNAME} /var/lib/docker xfs rw,relatime,seclabel,attr2,inode64,noquota 0 2\" \u003e\u003e /etc/fstab\n    fi\nfi\n\n## Login iSCSI volume mount and create filesystem\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"$${iqn}\" ]; then\n    echo \"iSCSI Login $${iqn}\"\n    iscsiadm -m node -o new -T $${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T $${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T $${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1) ${worker_iscsi_volume_mount} xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p ${worker_iscsi_volume_mount}\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ${worker_iscsi_volume_mount}\nfi\n\nuntil yum -y install docker-engine-${docker_ver}; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=${docker_max_log_size} --log-opt max-file=${docker_max_log_files}\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl start docker\n\n## Output /etc/environment_params\n######################################\necho \"IPV4_PRIVATE_0=$IP_LOCAL\" \u003e\u003e/etc/environment_params\necho \"ETCD_IP=$ETCD_ENDPOINTS\" \u003e\u003e/etc/environment_params\necho \"K8S_API_SERVER_LB=$K8S_API_SERVER_LB\" \u003e\u003e/etc/environment_params\necho \"FQDN_HOSTNAME=$FQDN_HOSTNAME\" \u003e\u003e/etc/environment_params\n\n## Drop firewall rules\n######################################\niptables -F\n\ncat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\n# Disable SELinux and firewall\nsetenforce 0\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsystemctl stop firewalld.service\nsystemctl disable firewalld.service\n\n## Install Flex Volume Driver for OCI\n#####################################\nmkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/\ncurl -L --retry 3 https://github.com/oracle/oci-flexvolume-driver/releases/download/${flexvolume_driver_version}/oci -o/usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\nchmod a+x /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\n\n\n## Install kubelet, kubectl, and kubernetes-cni\n###############################################\nyum-config-manager --add-repo http://yum.kubernetes.io/repos/kubernetes-el7-x86_64\nyum search -y kubernetes\n\nVER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep ${k8s_ver} | tail -n 1)\nif [[ -z \"$${VER_IN_REPO}\" ]]; then\n   MAJOR_VER=$(echo ${k8s_ver} | cut -d. -f-2)\n   echo \"Falling back to latest version available in: $MAJOR_VER\"\n   VER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep $MAJOR_VER | tail -n 1)\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\n   ## Replace kubelet binary since rpm at the exact k8s_ver was not available.\n   curl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v${k8s_ver}/bin/linux/amd64/kubelet -o /bin/kubelet \u0026\u0026 chmod 755 /bin/kubelet\nelse\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\nfi\n\n# Check if kubernetes-cni was automatically installed as a dependency\nK8S_CNI=$(rpm -qa | grep kubernetes-cni)\nif [[ -z \"$${K8S_CNI}\" ]]; then\n   echo \"Installing: $K8S_CNI\"\n   yum install -y kubernetes-cni\nelse\n   echo \"$K8S_CNI already installed\"\nfi\n\ncurl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v${k8s_ver}/bin/linux/amd64/kubectl -o /bin/kubectl \u0026\u0026 chmod 755 /bin/kubectl\n\n## FQDN constructed from live environment since DNS label for the subnet is optional\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" /etc/kubernetes/manifests/kube-proxy.yaml \u003e/tmp/kube-proxy.yaml\ncat /tmp/kube-proxy.yaml \u003e/etc/kubernetes/manifests/kube-proxy.yaml\n\n## kubelet for the worker\n######################################\nsystemctl daemon-reload\n\nAVAILABILITY_DOMAIN=$(jq -r '.availabilityDomain' /tmp/instance_meta.json | sed 's/:/-/g')\nread COMPARTMENT_ID_0 COMPARTMENT_ID_1 \u003c\u003c\u003c $(jq -r '.compartmentId' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nread NODE_ID_0 NODE_ID_1 \u003c\u003c\u003c $(jq -r '.id' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nNODE_SHAPE=$(jq -r '.shape' /tmp/instance_meta.json)\n\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" \\\n    -e \"s/__EXT_IP__/$EXTERNAL_IP/g\" \\\n    -e \"s/__AVAILABILITY_DOMAIN__/$AVAILABILITY_DOMAIN/g\" \\\n    -e \"s/__COMPARTMENT_ID_PREFIX__/$COMPARTMENT_ID_0/g\" \\\n    -e \"s/__COMPARTMENT_ID_SUFFIX__/$COMPARTMENT_ID_1/g\" \\\n    -e \"s/__NODE_ID_PREFIX__/$NODE_ID_0/g\" \\\n    -e \"s/__NODE_ID_SUFFIX__/$NODE_ID_1/g\" \\\n    -e \"s/__NODE_SHAPE__/$NODE_SHAPE/g\" \\\n    -e \"s/__SWAP_OPTION__/$SWAP_OPTION/g\" \\\n    /root/services/kubelet.service \u003e /etc/systemd/system/kubelet.service\n\n${reverse_proxy_setup}\n## Wait for k8s master to be available. There is a possible race on pod networks otherwise.\nuntil [ \"$(curl -k --cert /etc/kubernetes/ssl/apiserver.pem --key /etc/kubernetes/ssl/apiserver-key.pem $K8S_API_SERVER_LB/healthz 2\u003e/dev/null)\" == \"ok\" ]; do\n\tsleep 3\ndone\n\n# Setup CUDA devices before starting kubelet, so it detects the gpu(s)\n/sbin/modprobe nvidia\nif [ \"$?\" -eq 0 ]; then\n\t# Create the /dev/nvidia* files by running nvidia-smi\n\tnvidia-smi\nfi\n\n/sbin/modprobe nvidia-uvm\nif [ \"$?\" -eq 0 ]; then\n\t# Find out the major device number used by the nvidia-uvm driver\n\tDEVICE=$(grep nvidia-uvm /proc/devices | awk '{print $1}')\n\tmknod -m 666 /dev/nvidia-uvm c $DEVICE 0\nfi\n\nsleep $[ ( $RANDOM % 10 )  + 1 ]s\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n\nyum install -y nfs-utils\n\n######################################\necho \"Finished running setup.sh\"\n",
                            "vars.%": "9",
                            "vars.docker_max_log_files": "5",
                            "vars.docker_max_log_size": "50m",
                            "vars.docker_ver": "17.06.2.ol",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.flexvolume_driver_version": "0.7.1",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443",
                            "vars.reverse_proxy_setup": "",
                            "vars.worker_iscsi_volume_mount": "/var/lib/docker"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.worker-kubeconfig": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "50c46b4b5e846f02b7c1681ecee94820d0304f0e00cf2b8dcb13fe7d8b00ea09",
                        "attributes": {
                            "id": "50c46b4b5e846f02b7c1681ecee94820d0304f0e00cf2b8dcb13fe7d8b00ea09",
                            "rendered": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    certificate-authority: /etc/kubernetes/ssl/ca.pem\n    server: https://129.213.198.168:443\nusers:\n- name: kubelet\n  user:\n    client-certificate: /etc/kubernetes/ssl/apiserver.pem\n    client-key: /etc/kubernetes/ssl/apiserver-key.pem\ncontexts:\n- context:\n    cluster: local\n    user: kubelet\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "template": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    certificate-authority: /etc/kubernetes/ssl/ca.pem\n    server: ${master_lb}\nusers:\n- name: kubelet\n  user:\n    client-certificate: /etc/kubernetes/ssl/apiserver.pem\n    client-key: /etc/kubernetes/ssl/apiserver-key.pem\ncontexts:\n- context:\n    cluster: local\n    user: kubelet\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "vars.%": "3",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-k8sworker-ad2"
            ],
            "outputs": {
                "ids": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "instance_host_names": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.841477854 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:51.841477854 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.76451446 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.76451446 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.kube-proxy": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "60d085ced18e28432b36e3e82aaa6ca7758ce6100f5709f67bb301c692c56116",
                        "attributes": {
                            "id": "60d085ced18e28432b36e3e82aaa6ca7758ce6100f5709f67bb301c692c56116",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=https://129.213.198.168:443\n    - --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml\n    - --proxy-mode=iptables\n    - --cluster-cidr=10.99.0.0/16\n    - --masquerade-all\n    - --hostname-override=__FQDN_HOSTNAME__\n    - --v=2\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/ssl/certs\n        name: \"ssl-certs\"\n      - mountPath: /etc/kubernetes/manifests/worker-kubeconfig.yaml\n        name: \"kubeconfig\"\n        readOnly: true\n      - mountPath: /etc/kubernetes/ssl\n        name: \"etc-kube-ssl\"\n        readOnly: true\n  volumes:\n    - name: \"ssl-certs\"\n      hostPath:\n        path: \"/usr/share/ca-certificates\"\n    - name: \"kubeconfig\"\n      hostPath:\n        path: \"/etc/kubernetes/manifests/worker-kubeconfig.yaml\"\n    - name: \"etc-kube-ssl\"\n      hostPath:\n        path: \"/etc/kubernetes/ssl\"\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=${master_lb}\n    - --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml\n    - --proxy-mode=iptables\n    - --cluster-cidr=${flannel_network_cidr}\n    - --masquerade-all\n    - --hostname-override=__FQDN_HOSTNAME__\n    - --v=2\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/ssl/certs\n        name: \"ssl-certs\"\n      - mountPath: /etc/kubernetes/manifests/worker-kubeconfig.yaml\n        name: \"kubeconfig\"\n        readOnly: true\n      - mountPath: /etc/kubernetes/ssl\n        name: \"etc-kube-ssl\"\n        readOnly: true\n  volumes:\n    - name: \"ssl-certs\"\n      hostPath:\n        path: \"/usr/share/ca-certificates\"\n    - name: \"kubeconfig\"\n      hostPath:\n        path: \"/etc/kubernetes/manifests/worker-kubeconfig.yaml\"\n    - name: \"etc-kube-ssl\"\n      hostPath:\n        path: \"/etc/kubernetes/ssl\"\n",
                            "vars.%": "4",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kubelet-service": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "1833645ca1028eefdb54206bc7ed823c73eedacd627280d72ee0db75dcbeb89b",
                        "attributes": {
                            "id": "1833645ca1028eefdb54206bc7ed823c73eedacd627280d72ee0db75dcbeb89b",
                            "rendered": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --docker=unix:///var/run/docker.sock \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/node=,failure-domain.beta.kubernetes.io/region=us-ashburn-1,failure-domain.beta.kubernetes.io/zone=US-ASHBURN-AD-2,node.info/external.ipaddress=__EXT_IP__,node.info/availability.domain=__AVAILABILITY_DOMAIN__,node.info/compartment.id_prefix=__COMPARTMENT_ID_PREFIX__,node.info/compartment.id_suffix=__COMPARTMENT_ID_SUFFIX__,node.info/node.id_prefix=__NODE_ID_PREFIX__,node.info/node.id_suffix=__NODE_ID_SUFFIX__,node.info/node.shape=__NODE_SHAPE__ \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --serialize-image-pulls=false \\\n  --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem \\\n  --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --eviction-hard=memory.available\u003c500Mi,nodefs.available\u003c2Gi,imagefs.available\u003c2Gi \\\n  --cloud-provider=external \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "template": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --docker=unix:///var/run/docker.sock \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/node=,failure-domain.beta.kubernetes.io/region=${region},failure-domain.beta.kubernetes.io/zone=${zone},node.info/external.ipaddress=__EXT_IP__,node.info/availability.domain=__AVAILABILITY_DOMAIN__,node.info/compartment.id_prefix=__COMPARTMENT_ID_PREFIX__,node.info/compartment.id_suffix=__COMPARTMENT_ID_SUFFIX__,node.info/node.id_prefix=__NODE_ID_PREFIX__,node.info/node.id_suffix=__NODE_ID_SUFFIX__,node.info/node.shape=__NODE_SHAPE__ \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --serialize-image-pulls=false \\\n  --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem \\\n  --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --eviction-hard=memory.available\u003c500Mi,nodefs.available\u003c2Gi,imagefs.available\u003c2Gi \\\n  --cloud-provider=external \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "vars.%": "5",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443",
                            "vars.region": "us-ashburn-1",
                            "vars.zone": "US-ASHBURN-AD-2"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-preflight": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "9044b796cb8623c6c6980dc3bea4d2971116d9e0f7a7128261f21b024e4110ec",
                        "attributes": {
                            "id": "9044b796cb8623c6c6980dc3bea4d2971116d9e0f7a7128261f21b024e4110ec",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/manifests /etc/kubernetes/auth\n\n# add tools\ncurl --retry 3 http://stedolan.github.io/jq/download/linux64/jq -o /usr/local/bin/jq \u0026\u0026 chmod +x /usr/local/bin/jq\nbash -x /root/setup.sh 2\u003e\u00261 | tee -a /root/setup.log\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/manifests /etc/kubernetes/auth\n\n# add tools\ncurl --retry 3 http://stedolan.github.io/jq/download/linux64/jq -o /usr/local/bin/jq \u0026\u0026 chmod +x /usr/local/bin/jq\nbash -x /root/setup.sh 2\u003e\u00261 | tee -a /root/setup.log\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-template": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "e5a1155228712888eec83dd354c04583fa422cee9889c6e1ed1ce562e4a17d03",
                        "attributes": {
                            "id": "e5a1155228712888eec83dd354c04583fa422cee9889c6e1ed1ce562e4a17d03",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\nNAMESPACE=$(echo -n \"kubernetes.oraclevcn.com\" | sed \"s/\\.oraclevcn\\.com//g\")\nFQDN_HOSTNAME=$(hostname -f)\n\n# Pull instance metadata\ncurl -sL --retry 3 http://169.254.169.254/opc/v1/instance/ | tee /tmp/instance_meta.json\n\n## Create policy file that blocks autostart of services on install\nprintf '#!/bin/sh\\necho \"All runlevel operations denied by policy\" \u003e\u00262\\nexit 101\\n' \u003e/tmp/policy-rc.d \u0026\u0026 chmod +x /tmp/policy-rc.d\nexport K8S_API_SERVER_LB=https://129.213.198.168:443\nexport RANDFILE=$(mktemp)\nexport HOSTNAME=$(hostname)\n\nexport IP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\n\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\nexport WORKER_IP=$IP_LOCAL\n\n## k8s_ver swap option\n######################################\nk8sversion=\"1.9.6\"\n\nif [[ $k8sversion =~ ^[0-1]+\\.[0-7]+ ]]; then\n    SWAP_OPTION=\"\"\nelse\n    SWAP_OPTION=\"--fail-swap-on=false\"\nfi\n\n## Disable TX checksum offloading so we don't break VXLAN\n######################################\nBROADCOM_DRIVER=$(lsmod | grep bnxt_en | awk '{print $1}')\nif [[ -n \"${BROADCOM_DRIVER}\" ]]; then\n   echo \"Disabling hardware TX checksum offloading\"\n   ethtool --offload $(ip -o -4 route show to default | awk '{print $5}') tx off\nfi\n\n## Setup NVMe drives and mount at /var/lib/docker\n######################################\nNVMEVGNAME=\"NVMeVG\"\nNVMELVNAME=\"DockerVol\"\nNVMEDEVS=$(lsblk -I259 -pn -oNAME -d)\nif [[ ! -z \"${NVMEDEVS}\" ]]; then\n    lvs ${NVMEVGNAME}/${NVMELVNAME} --noheadings --logonly 1\u003e/dev/null\n    if [ $$? -ne 0 ]; then\n\tpvcreate ${NVMEDEVS}\n\tvgcreate ${NVMEVGNAME} ${NVMEDEVS}\n\tlvcreate --extents 100%FREE --name ${NVMELVNAME} ${NVMEVGNAME} ${NVMEDEVS}\n\tmkfs -t xfs /dev/${NVMEVGNAME}/${NVMELVNAME}\n\tmkdir -p /var/lib/docker\n\tmount -t xfs /dev/${NVMEVGNAME}/${NVMELVNAME} /var/lib/docker\n\techo \"/dev/${NVMEVGNAME}/${NVMELVNAME} /var/lib/docker xfs rw,relatime,seclabel,attr2,inode64,noquota 0 2\" \u003e\u003e /etc/fstab\n    fi\nfi\n\n## Login iSCSI volume mount and create filesystem\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"${iqn}\" ]; then\n    echo \"iSCSI Login ${iqn}\"\n    iscsiadm -m node -o new -T ${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T ${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T ${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1) /var/lib/docker xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p /var/lib/docker\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" /var/lib/docker\nfi\n\nuntil yum -y install docker-engine-17.06.2.ol; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=50m --log-opt max-file=5\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl start docker\n\n## Output /etc/environment_params\n######################################\necho \"IPV4_PRIVATE_0=$IP_LOCAL\" \u003e\u003e/etc/environment_params\necho \"ETCD_IP=$ETCD_ENDPOINTS\" \u003e\u003e/etc/environment_params\necho \"K8S_API_SERVER_LB=$K8S_API_SERVER_LB\" \u003e\u003e/etc/environment_params\necho \"FQDN_HOSTNAME=$FQDN_HOSTNAME\" \u003e\u003e/etc/environment_params\n\n## Drop firewall rules\n######################################\niptables -F\n\ncat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\n# Disable SELinux and firewall\nsetenforce 0\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsystemctl stop firewalld.service\nsystemctl disable firewalld.service\n\n## Install Flex Volume Driver for OCI\n#####################################\nmkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/\ncurl -L --retry 3 https://github.com/oracle/oci-flexvolume-driver/releases/download/0.7.1/oci -o/usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\nchmod a+x /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\n\n\n## Install kubelet, kubectl, and kubernetes-cni\n###############################################\nyum-config-manager --add-repo http://yum.kubernetes.io/repos/kubernetes-el7-x86_64\nyum search -y kubernetes\n\nVER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep 1.9.6 | tail -n 1)\nif [[ -z \"${VER_IN_REPO}\" ]]; then\n   MAJOR_VER=$(echo 1.9.6 | cut -d. -f-2)\n   echo \"Falling back to latest version available in: $MAJOR_VER\"\n   VER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep $MAJOR_VER | tail -n 1)\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\n   ## Replace kubelet binary since rpm at the exact k8s_ver was not available.\n   curl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v1.9.6/bin/linux/amd64/kubelet -o /bin/kubelet \u0026\u0026 chmod 755 /bin/kubelet\nelse\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\nfi\n\n# Check if kubernetes-cni was automatically installed as a dependency\nK8S_CNI=$(rpm -qa | grep kubernetes-cni)\nif [[ -z \"${K8S_CNI}\" ]]; then\n   echo \"Installing: $K8S_CNI\"\n   yum install -y kubernetes-cni\nelse\n   echo \"$K8S_CNI already installed\"\nfi\n\ncurl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v1.9.6/bin/linux/amd64/kubectl -o /bin/kubectl \u0026\u0026 chmod 755 /bin/kubectl\n\n## FQDN constructed from live environment since DNS label for the subnet is optional\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" /etc/kubernetes/manifests/kube-proxy.yaml \u003e/tmp/kube-proxy.yaml\ncat /tmp/kube-proxy.yaml \u003e/etc/kubernetes/manifests/kube-proxy.yaml\n\n## kubelet for the worker\n######################################\nsystemctl daemon-reload\n\nAVAILABILITY_DOMAIN=$(jq -r '.availabilityDomain' /tmp/instance_meta.json | sed 's/:/-/g')\nread COMPARTMENT_ID_0 COMPARTMENT_ID_1 \u003c\u003c\u003c $(jq -r '.compartmentId' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nread NODE_ID_0 NODE_ID_1 \u003c\u003c\u003c $(jq -r '.id' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nNODE_SHAPE=$(jq -r '.shape' /tmp/instance_meta.json)\n\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" \\\n    -e \"s/__EXT_IP__/$EXTERNAL_IP/g\" \\\n    -e \"s/__AVAILABILITY_DOMAIN__/$AVAILABILITY_DOMAIN/g\" \\\n    -e \"s/__COMPARTMENT_ID_PREFIX__/$COMPARTMENT_ID_0/g\" \\\n    -e \"s/__COMPARTMENT_ID_SUFFIX__/$COMPARTMENT_ID_1/g\" \\\n    -e \"s/__NODE_ID_PREFIX__/$NODE_ID_0/g\" \\\n    -e \"s/__NODE_ID_SUFFIX__/$NODE_ID_1/g\" \\\n    -e \"s/__NODE_SHAPE__/$NODE_SHAPE/g\" \\\n    -e \"s/__SWAP_OPTION__/$SWAP_OPTION/g\" \\\n    /root/services/kubelet.service \u003e /etc/systemd/system/kubelet.service\n\n\n## Wait for k8s master to be available. There is a possible race on pod networks otherwise.\nuntil [ \"$(curl -k --cert /etc/kubernetes/ssl/apiserver.pem --key /etc/kubernetes/ssl/apiserver-key.pem $K8S_API_SERVER_LB/healthz 2\u003e/dev/null)\" == \"ok\" ]; do\n\tsleep 3\ndone\n\n# Setup CUDA devices before starting kubelet, so it detects the gpu(s)\n/sbin/modprobe nvidia\nif [ \"$?\" -eq 0 ]; then\n\t# Create the /dev/nvidia* files by running nvidia-smi\n\tnvidia-smi\nfi\n\n/sbin/modprobe nvidia-uvm\nif [ \"$?\" -eq 0 ]; then\n\t# Find out the major device number used by the nvidia-uvm driver\n\tDEVICE=$(grep nvidia-uvm /proc/devices | awk '{print $1}')\n\tmknod -m 666 /dev/nvidia-uvm c $DEVICE 0\nfi\n\nsleep $[ ( $RANDOM % 10 )  + 1 ]s\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n\nyum install -y nfs-utils\n\n######################################\necho \"Finished running setup.sh\"\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\nNAMESPACE=$(echo -n \"${domain_name}\" | sed \"s/\\.oraclevcn\\.com//g\")\nFQDN_HOSTNAME=$(hostname -f)\n\n# Pull instance metadata\ncurl -sL --retry 3 http://169.254.169.254/opc/v1/instance/ | tee /tmp/instance_meta.json\n\n## Create policy file that blocks autostart of services on install\nprintf '#!/bin/sh\\necho \"All runlevel operations denied by policy\" \u003e\u00262\\nexit 101\\n' \u003e/tmp/policy-rc.d \u0026\u0026 chmod +x /tmp/policy-rc.d\nexport K8S_API_SERVER_LB=${master_lb}\nexport RANDFILE=$(mktemp)\nexport HOSTNAME=$(hostname)\n\nexport IP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\n\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\nexport WORKER_IP=$IP_LOCAL\n\n## k8s_ver swap option\n######################################\nk8sversion=\"${k8s_ver}\"\n\nif [[ $k8sversion =~ ^[0-1]+\\.[0-7]+ ]]; then\n    SWAP_OPTION=\"\"\nelse\n    SWAP_OPTION=\"--fail-swap-on=false\"\nfi\n\n## Disable TX checksum offloading so we don't break VXLAN\n######################################\nBROADCOM_DRIVER=$(lsmod | grep bnxt_en | awk '{print $1}')\nif [[ -n \"$${BROADCOM_DRIVER}\" ]]; then\n   echo \"Disabling hardware TX checksum offloading\"\n   ethtool --offload $(ip -o -4 route show to default | awk '{print $5}') tx off\nfi\n\n## Setup NVMe drives and mount at /var/lib/docker\n######################################\nNVMEVGNAME=\"NVMeVG\"\nNVMELVNAME=\"DockerVol\"\nNVMEDEVS=$(lsblk -I259 -pn -oNAME -d)\nif [[ ! -z \"$${NVMEDEVS}\" ]]; then\n    lvs $${NVMEVGNAME}/$${NVMELVNAME} --noheadings --logonly 1\u003e/dev/null\n    if [ $$? -ne 0 ]; then\n\tpvcreate $${NVMEDEVS}\n\tvgcreate $${NVMEVGNAME} $${NVMEDEVS}\n\tlvcreate --extents 100%FREE --name $${NVMELVNAME} $${NVMEVGNAME} $${NVMEDEVS}\n\tmkfs -t xfs /dev/$${NVMEVGNAME}/$${NVMELVNAME}\n\tmkdir -p /var/lib/docker\n\tmount -t xfs /dev/$${NVMEVGNAME}/$${NVMELVNAME} /var/lib/docker\n\techo \"/dev/$${NVMEVGNAME}/$${NVMELVNAME} /var/lib/docker xfs rw,relatime,seclabel,attr2,inode64,noquota 0 2\" \u003e\u003e /etc/fstab\n    fi\nfi\n\n## Login iSCSI volume mount and create filesystem\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"$${iqn}\" ]; then\n    echo \"iSCSI Login $${iqn}\"\n    iscsiadm -m node -o new -T $${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T $${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T $${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1) ${worker_iscsi_volume_mount} xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p ${worker_iscsi_volume_mount}\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ${worker_iscsi_volume_mount}\nfi\n\nuntil yum -y install docker-engine-${docker_ver}; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=${docker_max_log_size} --log-opt max-file=${docker_max_log_files}\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl start docker\n\n## Output /etc/environment_params\n######################################\necho \"IPV4_PRIVATE_0=$IP_LOCAL\" \u003e\u003e/etc/environment_params\necho \"ETCD_IP=$ETCD_ENDPOINTS\" \u003e\u003e/etc/environment_params\necho \"K8S_API_SERVER_LB=$K8S_API_SERVER_LB\" \u003e\u003e/etc/environment_params\necho \"FQDN_HOSTNAME=$FQDN_HOSTNAME\" \u003e\u003e/etc/environment_params\n\n## Drop firewall rules\n######################################\niptables -F\n\ncat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\n# Disable SELinux and firewall\nsetenforce 0\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsystemctl stop firewalld.service\nsystemctl disable firewalld.service\n\n## Install Flex Volume Driver for OCI\n#####################################\nmkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/\ncurl -L --retry 3 https://github.com/oracle/oci-flexvolume-driver/releases/download/${flexvolume_driver_version}/oci -o/usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\nchmod a+x /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\n\n\n## Install kubelet, kubectl, and kubernetes-cni\n###############################################\nyum-config-manager --add-repo http://yum.kubernetes.io/repos/kubernetes-el7-x86_64\nyum search -y kubernetes\n\nVER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep ${k8s_ver} | tail -n 1)\nif [[ -z \"$${VER_IN_REPO}\" ]]; then\n   MAJOR_VER=$(echo ${k8s_ver} | cut -d. -f-2)\n   echo \"Falling back to latest version available in: $MAJOR_VER\"\n   VER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep $MAJOR_VER | tail -n 1)\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\n   ## Replace kubelet binary since rpm at the exact k8s_ver was not available.\n   curl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v${k8s_ver}/bin/linux/amd64/kubelet -o /bin/kubelet \u0026\u0026 chmod 755 /bin/kubelet\nelse\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\nfi\n\n# Check if kubernetes-cni was automatically installed as a dependency\nK8S_CNI=$(rpm -qa | grep kubernetes-cni)\nif [[ -z \"$${K8S_CNI}\" ]]; then\n   echo \"Installing: $K8S_CNI\"\n   yum install -y kubernetes-cni\nelse\n   echo \"$K8S_CNI already installed\"\nfi\n\ncurl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v${k8s_ver}/bin/linux/amd64/kubectl -o /bin/kubectl \u0026\u0026 chmod 755 /bin/kubectl\n\n## FQDN constructed from live environment since DNS label for the subnet is optional\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" /etc/kubernetes/manifests/kube-proxy.yaml \u003e/tmp/kube-proxy.yaml\ncat /tmp/kube-proxy.yaml \u003e/etc/kubernetes/manifests/kube-proxy.yaml\n\n## kubelet for the worker\n######################################\nsystemctl daemon-reload\n\nAVAILABILITY_DOMAIN=$(jq -r '.availabilityDomain' /tmp/instance_meta.json | sed 's/:/-/g')\nread COMPARTMENT_ID_0 COMPARTMENT_ID_1 \u003c\u003c\u003c $(jq -r '.compartmentId' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nread NODE_ID_0 NODE_ID_1 \u003c\u003c\u003c $(jq -r '.id' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nNODE_SHAPE=$(jq -r '.shape' /tmp/instance_meta.json)\n\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" \\\n    -e \"s/__EXT_IP__/$EXTERNAL_IP/g\" \\\n    -e \"s/__AVAILABILITY_DOMAIN__/$AVAILABILITY_DOMAIN/g\" \\\n    -e \"s/__COMPARTMENT_ID_PREFIX__/$COMPARTMENT_ID_0/g\" \\\n    -e \"s/__COMPARTMENT_ID_SUFFIX__/$COMPARTMENT_ID_1/g\" \\\n    -e \"s/__NODE_ID_PREFIX__/$NODE_ID_0/g\" \\\n    -e \"s/__NODE_ID_SUFFIX__/$NODE_ID_1/g\" \\\n    -e \"s/__NODE_SHAPE__/$NODE_SHAPE/g\" \\\n    -e \"s/__SWAP_OPTION__/$SWAP_OPTION/g\" \\\n    /root/services/kubelet.service \u003e /etc/systemd/system/kubelet.service\n\n${reverse_proxy_setup}\n## Wait for k8s master to be available. There is a possible race on pod networks otherwise.\nuntil [ \"$(curl -k --cert /etc/kubernetes/ssl/apiserver.pem --key /etc/kubernetes/ssl/apiserver-key.pem $K8S_API_SERVER_LB/healthz 2\u003e/dev/null)\" == \"ok\" ]; do\n\tsleep 3\ndone\n\n# Setup CUDA devices before starting kubelet, so it detects the gpu(s)\n/sbin/modprobe nvidia\nif [ \"$?\" -eq 0 ]; then\n\t# Create the /dev/nvidia* files by running nvidia-smi\n\tnvidia-smi\nfi\n\n/sbin/modprobe nvidia-uvm\nif [ \"$?\" -eq 0 ]; then\n\t# Find out the major device number used by the nvidia-uvm driver\n\tDEVICE=$(grep nvidia-uvm /proc/devices | awk '{print $1}')\n\tmknod -m 666 /dev/nvidia-uvm c $DEVICE 0\nfi\n\nsleep $[ ( $RANDOM % 10 )  + 1 ]s\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n\nyum install -y nfs-utils\n\n######################################\necho \"Finished running setup.sh\"\n",
                            "vars.%": "9",
                            "vars.docker_max_log_files": "5",
                            "vars.docker_max_log_size": "50m",
                            "vars.docker_ver": "17.06.2.ol",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.flexvolume_driver_version": "0.7.1",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443",
                            "vars.reverse_proxy_setup": "",
                            "vars.worker_iscsi_volume_mount": "/var/lib/docker"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.worker-kubeconfig": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "50c46b4b5e846f02b7c1681ecee94820d0304f0e00cf2b8dcb13fe7d8b00ea09",
                        "attributes": {
                            "id": "50c46b4b5e846f02b7c1681ecee94820d0304f0e00cf2b8dcb13fe7d8b00ea09",
                            "rendered": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    certificate-authority: /etc/kubernetes/ssl/ca.pem\n    server: https://129.213.198.168:443\nusers:\n- name: kubelet\n  user:\n    client-certificate: /etc/kubernetes/ssl/apiserver.pem\n    client-key: /etc/kubernetes/ssl/apiserver-key.pem\ncontexts:\n- context:\n    cluster: local\n    user: kubelet\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "template": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    certificate-authority: /etc/kubernetes/ssl/ca.pem\n    server: ${master_lb}\nusers:\n- name: kubelet\n  user:\n    client-certificate: /etc/kubernetes/ssl/apiserver.pem\n    client-key: /etc/kubernetes/ssl/apiserver-key.pem\ncontexts:\n- context:\n    cluster: local\n    user: kubelet\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "vars.%": "3",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "instances-k8sworker-ad3"
            ],
            "outputs": {},
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.792633427 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:51.792633427 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.72403248 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:20:51.72403248 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.template_file.kube-proxy": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "60d085ced18e28432b36e3e82aaa6ca7758ce6100f5709f67bb301c692c56116",
                        "attributes": {
                            "id": "60d085ced18e28432b36e3e82aaa6ca7758ce6100f5709f67bb301c692c56116",
                            "rendered": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v1.9.6_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=https://129.213.198.168:443\n    - --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml\n    - --proxy-mode=iptables\n    - --cluster-cidr=10.99.0.0/16\n    - --masquerade-all\n    - --hostname-override=__FQDN_HOSTNAME__\n    - --v=2\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/ssl/certs\n        name: \"ssl-certs\"\n      - mountPath: /etc/kubernetes/manifests/worker-kubeconfig.yaml\n        name: \"kubeconfig\"\n        readOnly: true\n      - mountPath: /etc/kubernetes/ssl\n        name: \"etc-kube-ssl\"\n        readOnly: true\n  volumes:\n    - name: \"ssl-certs\"\n      hostPath:\n        path: \"/usr/share/ca-certificates\"\n    - name: \"kubeconfig\"\n      hostPath:\n        path: \"/etc/kubernetes/manifests/worker-kubeconfig.yaml\"\n    - name: \"etc-kube-ssl\"\n      hostPath:\n        path: \"/etc/kubernetes/ssl\"\n",
                            "template": "apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-proxy\n  namespace: kube-system\n  labels:\n    k8s-app: kube-proxy\n  annotations:\n    scheduler.alpha.kubernetes.io/critical-pod: ''\n    scheduler.alpha.kubernetes.io/tolerations: '[{\"key\":\"CriticalAddonsOnly\", \"operator\":\"Exists\"}]'\nspec:\n  hostNetwork: true\n  containers:\n  - name: kube-proxy\n    image: quay.io/coreos/hyperkube:v${k8s_ver}_coreos.0\n    command:\n    - /hyperkube\n    - proxy\n    - --master=${master_lb}\n    - --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml\n    - --proxy-mode=iptables\n    - --cluster-cidr=${flannel_network_cidr}\n    - --masquerade-all\n    - --hostname-override=__FQDN_HOSTNAME__\n    - --v=2\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/ssl/certs\n        name: \"ssl-certs\"\n      - mountPath: /etc/kubernetes/manifests/worker-kubeconfig.yaml\n        name: \"kubeconfig\"\n        readOnly: true\n      - mountPath: /etc/kubernetes/ssl\n        name: \"etc-kube-ssl\"\n        readOnly: true\n  volumes:\n    - name: \"ssl-certs\"\n      hostPath:\n        path: \"/usr/share/ca-certificates\"\n    - name: \"kubeconfig\"\n      hostPath:\n        path: \"/etc/kubernetes/manifests/worker-kubeconfig.yaml\"\n    - name: \"etc-kube-ssl\"\n      hostPath:\n        path: \"/etc/kubernetes/ssl\"\n",
                            "vars.%": "4",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.flannel_network_cidr": "10.99.0.0/16",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.kubelet-service": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "58214587d18c20819654639e650a6457eee43c1a622869b1d437551caf44b4c3",
                        "attributes": {
                            "id": "58214587d18c20819654639e650a6457eee43c1a622869b1d437551caf44b4c3",
                            "rendered": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --docker=unix:///var/run/docker.sock \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/node=,failure-domain.beta.kubernetes.io/region=us-ashburn-1,failure-domain.beta.kubernetes.io/zone=US-ASHBURN-AD-3,node.info/external.ipaddress=__EXT_IP__,node.info/availability.domain=__AVAILABILITY_DOMAIN__,node.info/compartment.id_prefix=__COMPARTMENT_ID_PREFIX__,node.info/compartment.id_suffix=__COMPARTMENT_ID_SUFFIX__,node.info/node.id_prefix=__NODE_ID_PREFIX__,node.info/node.id_suffix=__NODE_ID_SUFFIX__,node.info/node.shape=__NODE_SHAPE__ \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --serialize-image-pulls=false \\\n  --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem \\\n  --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --eviction-hard=memory.available\u003c500Mi,nodefs.available\u003c2Gi,imagefs.available\u003c2Gi \\\n  --cloud-provider=external \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "template": "[Unit]\nRequires=docker.service\nAfter=docker.service\n[Service]\nEnvironmentFile=/etc/environment_params\nExecStart=/usr/bin/kubelet \\\n  --allow-privileged=true \\\n  --cluster_dns=10.21.21.21 \\\n  --cluster_domain=cluster.local \\\n  --container-runtime=docker \\\n  --docker=unix:///var/run/docker.sock \\\n  --hostname-override=__FQDN_HOSTNAME__ \\\n  --kubeconfig=/etc/kubernetes/manifests/worker-kubeconfig.yaml \\\n  --require-kubeconfig=true \\\n  --network-plugin=cni \\\n  --node-labels node-role.kubernetes.io/node=,failure-domain.beta.kubernetes.io/region=${region},failure-domain.beta.kubernetes.io/zone=${zone},node.info/external.ipaddress=__EXT_IP__,node.info/availability.domain=__AVAILABILITY_DOMAIN__,node.info/compartment.id_prefix=__COMPARTMENT_ID_PREFIX__,node.info/compartment.id_suffix=__COMPARTMENT_ID_SUFFIX__,node.info/node.id_prefix=__NODE_ID_PREFIX__,node.info/node.id_suffix=__NODE_ID_SUFFIX__,node.info/node.shape=__NODE_SHAPE__ \\\n  --pod-manifest-path=/etc/kubernetes/manifests \\\n  --register-node=true \\\n  --serialize-image-pulls=false \\\n  --tls-cert-file=/etc/kubernetes/ssl/apiserver.pem \\\n  --tls-private-key-file=/etc/kubernetes/ssl/apiserver-key.pem \\\n  --feature-gates=ExperimentalCriticalPodAnnotation=true,Accelerators=true \\\n  --eviction-hard=memory.available\u003c500Mi,nodefs.available\u003c2Gi,imagefs.available\u003c2Gi \\\n  --cloud-provider=external \\\n  --provider-id=__NODE_ID_PREFIX__.__NODE_ID_SUFFIX__ \\\n  __SWAP_OPTION__ --v=2\nRestart=always\nRestartSec=10\n[Install]\nWantedBy=multi-user.target\n",
                            "vars.%": "5",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443",
                            "vars.region": "us-ashburn-1",
                            "vars.zone": "US-ASHBURN-AD-3"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-preflight": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "9044b796cb8623c6c6980dc3bea4d2971116d9e0f7a7128261f21b024e4110ec",
                        "attributes": {
                            "id": "9044b796cb8623c6c6980dc3bea4d2971116d9e0f7a7128261f21b024e4110ec",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/manifests /etc/kubernetes/auth\n\n# add tools\ncurl --retry 3 http://stedolan.github.io/jq/download/linux64/jq -o /usr/local/bin/jq \u0026\u0026 chmod +x /usr/local/bin/jq\nbash -x /root/setup.sh 2\u003e\u00261 | tee -a /root/setup.log\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\n\nmkdir -p /etc/kubernetes/manifests /etc/kubernetes/auth\n\n# add tools\ncurl --retry 3 http://stedolan.github.io/jq/download/linux64/jq -o /usr/local/bin/jq \u0026\u0026 chmod +x /usr/local/bin/jq\nbash -x /root/setup.sh 2\u003e\u00261 | tee -a /root/setup.log\n",
                            "vars.%": "1",
                            "vars.k8s_ver": "1.9.6"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.setup-template": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "e5a1155228712888eec83dd354c04583fa422cee9889c6e1ed1ce562e4a17d03",
                        "attributes": {
                            "id": "e5a1155228712888eec83dd354c04583fa422cee9889c6e1ed1ce562e4a17d03",
                            "rendered": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\nNAMESPACE=$(echo -n \"kubernetes.oraclevcn.com\" | sed \"s/\\.oraclevcn\\.com//g\")\nFQDN_HOSTNAME=$(hostname -f)\n\n# Pull instance metadata\ncurl -sL --retry 3 http://169.254.169.254/opc/v1/instance/ | tee /tmp/instance_meta.json\n\n## Create policy file that blocks autostart of services on install\nprintf '#!/bin/sh\\necho \"All runlevel operations denied by policy\" \u003e\u00262\\nexit 101\\n' \u003e/tmp/policy-rc.d \u0026\u0026 chmod +x /tmp/policy-rc.d\nexport K8S_API_SERVER_LB=https://129.213.198.168:443\nexport RANDFILE=$(mktemp)\nexport HOSTNAME=$(hostname)\n\nexport IP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\n\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\nexport WORKER_IP=$IP_LOCAL\n\n## k8s_ver swap option\n######################################\nk8sversion=\"1.9.6\"\n\nif [[ $k8sversion =~ ^[0-1]+\\.[0-7]+ ]]; then\n    SWAP_OPTION=\"\"\nelse\n    SWAP_OPTION=\"--fail-swap-on=false\"\nfi\n\n## Disable TX checksum offloading so we don't break VXLAN\n######################################\nBROADCOM_DRIVER=$(lsmod | grep bnxt_en | awk '{print $1}')\nif [[ -n \"${BROADCOM_DRIVER}\" ]]; then\n   echo \"Disabling hardware TX checksum offloading\"\n   ethtool --offload $(ip -o -4 route show to default | awk '{print $5}') tx off\nfi\n\n## Setup NVMe drives and mount at /var/lib/docker\n######################################\nNVMEVGNAME=\"NVMeVG\"\nNVMELVNAME=\"DockerVol\"\nNVMEDEVS=$(lsblk -I259 -pn -oNAME -d)\nif [[ ! -z \"${NVMEDEVS}\" ]]; then\n    lvs ${NVMEVGNAME}/${NVMELVNAME} --noheadings --logonly 1\u003e/dev/null\n    if [ $$? -ne 0 ]; then\n\tpvcreate ${NVMEDEVS}\n\tvgcreate ${NVMEVGNAME} ${NVMEDEVS}\n\tlvcreate --extents 100%FREE --name ${NVMELVNAME} ${NVMEVGNAME} ${NVMEDEVS}\n\tmkfs -t xfs /dev/${NVMEVGNAME}/${NVMELVNAME}\n\tmkdir -p /var/lib/docker\n\tmount -t xfs /dev/${NVMEVGNAME}/${NVMELVNAME} /var/lib/docker\n\techo \"/dev/${NVMEVGNAME}/${NVMELVNAME} /var/lib/docker xfs rw,relatime,seclabel,attr2,inode64,noquota 0 2\" \u003e\u003e /etc/fstab\n    fi\nfi\n\n## Login iSCSI volume mount and create filesystem\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"${iqn}\" ]; then\n    echo \"iSCSI Login ${iqn}\"\n    iscsiadm -m node -o new -T ${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T ${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T ${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1) /var/lib/docker xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p /var/lib/docker\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-${iqn}-lun-1\" /var/lib/docker\nfi\n\nuntil yum -y install docker-engine-17.06.2.ol; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=50m --log-opt max-file=5\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl start docker\n\n## Output /etc/environment_params\n######################################\necho \"IPV4_PRIVATE_0=$IP_LOCAL\" \u003e\u003e/etc/environment_params\necho \"ETCD_IP=$ETCD_ENDPOINTS\" \u003e\u003e/etc/environment_params\necho \"K8S_API_SERVER_LB=$K8S_API_SERVER_LB\" \u003e\u003e/etc/environment_params\necho \"FQDN_HOSTNAME=$FQDN_HOSTNAME\" \u003e\u003e/etc/environment_params\n\n## Drop firewall rules\n######################################\niptables -F\n\ncat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\n# Disable SELinux and firewall\nsetenforce 0\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsystemctl stop firewalld.service\nsystemctl disable firewalld.service\n\n## Install Flex Volume Driver for OCI\n#####################################\nmkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/\ncurl -L --retry 3 https://github.com/oracle/oci-flexvolume-driver/releases/download/0.7.1/oci -o/usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\nchmod a+x /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\n\n\n## Install kubelet, kubectl, and kubernetes-cni\n###############################################\nyum-config-manager --add-repo http://yum.kubernetes.io/repos/kubernetes-el7-x86_64\nyum search -y kubernetes\n\nVER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep 1.9.6 | tail -n 1)\nif [[ -z \"${VER_IN_REPO}\" ]]; then\n   MAJOR_VER=$(echo 1.9.6 | cut -d. -f-2)\n   echo \"Falling back to latest version available in: $MAJOR_VER\"\n   VER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep $MAJOR_VER | tail -n 1)\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\n   ## Replace kubelet binary since rpm at the exact k8s_ver was not available.\n   curl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v1.9.6/bin/linux/amd64/kubelet -o /bin/kubelet \u0026\u0026 chmod 755 /bin/kubelet\nelse\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\nfi\n\n# Check if kubernetes-cni was automatically installed as a dependency\nK8S_CNI=$(rpm -qa | grep kubernetes-cni)\nif [[ -z \"${K8S_CNI}\" ]]; then\n   echo \"Installing: $K8S_CNI\"\n   yum install -y kubernetes-cni\nelse\n   echo \"$K8S_CNI already installed\"\nfi\n\ncurl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v1.9.6/bin/linux/amd64/kubectl -o /bin/kubectl \u0026\u0026 chmod 755 /bin/kubectl\n\n## FQDN constructed from live environment since DNS label for the subnet is optional\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" /etc/kubernetes/manifests/kube-proxy.yaml \u003e/tmp/kube-proxy.yaml\ncat /tmp/kube-proxy.yaml \u003e/etc/kubernetes/manifests/kube-proxy.yaml\n\n## kubelet for the worker\n######################################\nsystemctl daemon-reload\n\nAVAILABILITY_DOMAIN=$(jq -r '.availabilityDomain' /tmp/instance_meta.json | sed 's/:/-/g')\nread COMPARTMENT_ID_0 COMPARTMENT_ID_1 \u003c\u003c\u003c $(jq -r '.compartmentId' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nread NODE_ID_0 NODE_ID_1 \u003c\u003c\u003c $(jq -r '.id' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nNODE_SHAPE=$(jq -r '.shape' /tmp/instance_meta.json)\n\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" \\\n    -e \"s/__EXT_IP__/$EXTERNAL_IP/g\" \\\n    -e \"s/__AVAILABILITY_DOMAIN__/$AVAILABILITY_DOMAIN/g\" \\\n    -e \"s/__COMPARTMENT_ID_PREFIX__/$COMPARTMENT_ID_0/g\" \\\n    -e \"s/__COMPARTMENT_ID_SUFFIX__/$COMPARTMENT_ID_1/g\" \\\n    -e \"s/__NODE_ID_PREFIX__/$NODE_ID_0/g\" \\\n    -e \"s/__NODE_ID_SUFFIX__/$NODE_ID_1/g\" \\\n    -e \"s/__NODE_SHAPE__/$NODE_SHAPE/g\" \\\n    -e \"s/__SWAP_OPTION__/$SWAP_OPTION/g\" \\\n    /root/services/kubelet.service \u003e /etc/systemd/system/kubelet.service\n\n\n## Wait for k8s master to be available. There is a possible race on pod networks otherwise.\nuntil [ \"$(curl -k --cert /etc/kubernetes/ssl/apiserver.pem --key /etc/kubernetes/ssl/apiserver-key.pem $K8S_API_SERVER_LB/healthz 2\u003e/dev/null)\" == \"ok\" ]; do\n\tsleep 3\ndone\n\n# Setup CUDA devices before starting kubelet, so it detects the gpu(s)\n/sbin/modprobe nvidia\nif [ \"$?\" -eq 0 ]; then\n\t# Create the /dev/nvidia* files by running nvidia-smi\n\tnvidia-smi\nfi\n\n/sbin/modprobe nvidia-uvm\nif [ \"$?\" -eq 0 ]; then\n\t# Find out the major device number used by the nvidia-uvm driver\n\tDEVICE=$(grep nvidia-uvm /proc/devices | awk '{print $1}')\n\tmknod -m 666 /dev/nvidia-uvm c $DEVICE 0\nfi\n\nsleep $[ ( $RANDOM % 10 )  + 1 ]s\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n\nyum install -y nfs-utils\n\n######################################\necho \"Finished running setup.sh\"\n",
                            "template": "#!/bin/bash -x\n\nEXTERNAL_IP=$(curl -s -m 10 http://whatismyip.akamai.com/)\nNAMESPACE=$(echo -n \"${domain_name}\" | sed \"s/\\.oraclevcn\\.com//g\")\nFQDN_HOSTNAME=$(hostname -f)\n\n# Pull instance metadata\ncurl -sL --retry 3 http://169.254.169.254/opc/v1/instance/ | tee /tmp/instance_meta.json\n\n## Create policy file that blocks autostart of services on install\nprintf '#!/bin/sh\\necho \"All runlevel operations denied by policy\" \u003e\u00262\\nexit 101\\n' \u003e/tmp/policy-rc.d \u0026\u0026 chmod +x /tmp/policy-rc.d\nexport K8S_API_SERVER_LB=${master_lb}\nexport RANDFILE=$(mktemp)\nexport HOSTNAME=$(hostname)\n\nexport IP_LOCAL=$(ip route show to 0.0.0.0/0 | awk '{ print $5 }' | xargs ip addr show | grep -Po 'inet \\K[\\d.]+')\n\nSUBNET=$(getent hosts $IP_LOCAL | awk '{print $2}' | cut -d. -f2)\nexport WORKER_IP=$IP_LOCAL\n\n## k8s_ver swap option\n######################################\nk8sversion=\"${k8s_ver}\"\n\nif [[ $k8sversion =~ ^[0-1]+\\.[0-7]+ ]]; then\n    SWAP_OPTION=\"\"\nelse\n    SWAP_OPTION=\"--fail-swap-on=false\"\nfi\n\n## Disable TX checksum offloading so we don't break VXLAN\n######################################\nBROADCOM_DRIVER=$(lsmod | grep bnxt_en | awk '{print $1}')\nif [[ -n \"$${BROADCOM_DRIVER}\" ]]; then\n   echo \"Disabling hardware TX checksum offloading\"\n   ethtool --offload $(ip -o -4 route show to default | awk '{print $5}') tx off\nfi\n\n## Setup NVMe drives and mount at /var/lib/docker\n######################################\nNVMEVGNAME=\"NVMeVG\"\nNVMELVNAME=\"DockerVol\"\nNVMEDEVS=$(lsblk -I259 -pn -oNAME -d)\nif [[ ! -z \"$${NVMEDEVS}\" ]]; then\n    lvs $${NVMEVGNAME}/$${NVMELVNAME} --noheadings --logonly 1\u003e/dev/null\n    if [ $$? -ne 0 ]; then\n\tpvcreate $${NVMEDEVS}\n\tvgcreate $${NVMEVGNAME} $${NVMEDEVS}\n\tlvcreate --extents 100%FREE --name $${NVMELVNAME} $${NVMEVGNAME} $${NVMEDEVS}\n\tmkfs -t xfs /dev/$${NVMEVGNAME}/$${NVMELVNAME}\n\tmkdir -p /var/lib/docker\n\tmount -t xfs /dev/$${NVMEVGNAME}/$${NVMELVNAME} /var/lib/docker\n\techo \"/dev/$${NVMEVGNAME}/$${NVMELVNAME} /var/lib/docker xfs rw,relatime,seclabel,attr2,inode64,noquota 0 2\" \u003e\u003e /etc/fstab\n    fi\nfi\n\n## Login iSCSI volume mount and create filesystem\n######################################\niqn=$(iscsiadm --mode discoverydb --type sendtargets --portal 169.254.2.2:3260 --discover| cut -f2 -d\" \")\n\nif [ -n \"$${iqn}\" ]; then\n    echo \"iSCSI Login $${iqn}\"\n    iscsiadm -m node -o new -T $${iqn} -p 169.254.2.2:3260\n    iscsiadm -m node -o update -T $${iqn} -n node.startup -v automatic\n    iscsiadm -m node -T $${iqn} -p 169.254.2.2:3260 -l\n    # Wait for device to apear...\n    until [[ -e \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ]]; do sleep 1 \u0026\u0026 echo -n \".\"; done\n    # If the volume has been created and formatted before but it's just a new instance this may fail\n    # but if so ignore and carry on.\n    mkfs -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\";\n    echo \"$$(readlink -f /dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1) ${worker_iscsi_volume_mount} xfs defaults,noatime,_netdev 0 2\" \u003e\u003e /etc/fstab\n    mkdir -p ${worker_iscsi_volume_mount}\n    mount -t xfs \"/dev/disk/by-path/ip-169.254.2.2:3260-iscsi-$${iqn}-lun-1\" ${worker_iscsi_volume_mount}\nfi\n\nuntil yum -y install docker-engine-${docker_ver}; do sleep 1 \u0026\u0026 echo -n \".\"; done\n\ncat \u003c\u003cEOF \u003e /etc/sysconfig/docker\nOPTIONS=\"--selinux-enabled --log-opt max-size=${docker_max_log_size} --log-opt max-file=${docker_max_log_files}\"\nDOCKER_CERT_PATH=/etc/docker\nGOTRACEBACK=crash\nEOF\n\nsystemctl daemon-reload\nsystemctl enable docker\nsystemctl start docker\n\n## Output /etc/environment_params\n######################################\necho \"IPV4_PRIVATE_0=$IP_LOCAL\" \u003e\u003e/etc/environment_params\necho \"ETCD_IP=$ETCD_ENDPOINTS\" \u003e\u003e/etc/environment_params\necho \"K8S_API_SERVER_LB=$K8S_API_SERVER_LB\" \u003e\u003e/etc/environment_params\necho \"FQDN_HOSTNAME=$FQDN_HOSTNAME\" \u003e\u003e/etc/environment_params\n\n## Drop firewall rules\n######################################\niptables -F\n\ncat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo\n[kubernetes]\nname=Kubernetes\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\nEOF\n\n# Disable SELinux and firewall\nsetenforce 0\nsudo sed -i  s/SELINUX=enforcing/SELINUX=permissive/ /etc/selinux/config\nsystemctl stop firewalld.service\nsystemctl disable firewalld.service\n\n## Install Flex Volume Driver for OCI\n#####################################\nmkdir -p /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/\ncurl -L --retry 3 https://github.com/oracle/oci-flexvolume-driver/releases/download/${flexvolume_driver_version}/oci -o/usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\nchmod a+x /usr/libexec/kubernetes/kubelet-plugins/volume/exec/oracle~oci/oci\n\n\n## Install kubelet, kubectl, and kubernetes-cni\n###############################################\nyum-config-manager --add-repo http://yum.kubernetes.io/repos/kubernetes-el7-x86_64\nyum search -y kubernetes\n\nVER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep ${k8s_ver} | tail -n 1)\nif [[ -z \"$${VER_IN_REPO}\" ]]; then\n   MAJOR_VER=$(echo ${k8s_ver} | cut -d. -f-2)\n   echo \"Falling back to latest version available in: $MAJOR_VER\"\n   VER_IN_REPO=$(repoquery --nvr --show-duplicates kubelet | sort --version-sort | grep $MAJOR_VER | tail -n 1)\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\n   ## Replace kubelet binary since rpm at the exact k8s_ver was not available.\n   curl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v${k8s_ver}/bin/linux/amd64/kubelet -o /bin/kubelet \u0026\u0026 chmod 755 /bin/kubelet\nelse\n   echo \"Installing kubelet version: $VER_IN_REPO\"\n   yum install -y $VER_IN_REPO\nfi\n\n# Check if kubernetes-cni was automatically installed as a dependency\nK8S_CNI=$(rpm -qa | grep kubernetes-cni)\nif [[ -z \"$${K8S_CNI}\" ]]; then\n   echo \"Installing: $K8S_CNI\"\n   yum install -y kubernetes-cni\nelse\n   echo \"$K8S_CNI already installed\"\nfi\n\ncurl -L --retry 3 http://storage.googleapis.com/kubernetes-release/release/v${k8s_ver}/bin/linux/amd64/kubectl -o /bin/kubectl \u0026\u0026 chmod 755 /bin/kubectl\n\n## FQDN constructed from live environment since DNS label for the subnet is optional\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" /etc/kubernetes/manifests/kube-proxy.yaml \u003e/tmp/kube-proxy.yaml\ncat /tmp/kube-proxy.yaml \u003e/etc/kubernetes/manifests/kube-proxy.yaml\n\n## kubelet for the worker\n######################################\nsystemctl daemon-reload\n\nAVAILABILITY_DOMAIN=$(jq -r '.availabilityDomain' /tmp/instance_meta.json | sed 's/:/-/g')\nread COMPARTMENT_ID_0 COMPARTMENT_ID_1 \u003c\u003c\u003c $(jq -r '.compartmentId' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nread NODE_ID_0 NODE_ID_1 \u003c\u003c\u003c $(jq -r '.id' /tmp/instance_meta.json | perl -pe 's/(.*?\\.){4}\\K/ /g' | perl -pe 's/\\.+\\s/ /g')\nNODE_SHAPE=$(jq -r '.shape' /tmp/instance_meta.json)\n\nsed -e \"s/__FQDN_HOSTNAME__/$FQDN_HOSTNAME/g\" \\\n    -e \"s/__EXT_IP__/$EXTERNAL_IP/g\" \\\n    -e \"s/__AVAILABILITY_DOMAIN__/$AVAILABILITY_DOMAIN/g\" \\\n    -e \"s/__COMPARTMENT_ID_PREFIX__/$COMPARTMENT_ID_0/g\" \\\n    -e \"s/__COMPARTMENT_ID_SUFFIX__/$COMPARTMENT_ID_1/g\" \\\n    -e \"s/__NODE_ID_PREFIX__/$NODE_ID_0/g\" \\\n    -e \"s/__NODE_ID_SUFFIX__/$NODE_ID_1/g\" \\\n    -e \"s/__NODE_SHAPE__/$NODE_SHAPE/g\" \\\n    -e \"s/__SWAP_OPTION__/$SWAP_OPTION/g\" \\\n    /root/services/kubelet.service \u003e /etc/systemd/system/kubelet.service\n\n${reverse_proxy_setup}\n## Wait for k8s master to be available. There is a possible race on pod networks otherwise.\nuntil [ \"$(curl -k --cert /etc/kubernetes/ssl/apiserver.pem --key /etc/kubernetes/ssl/apiserver-key.pem $K8S_API_SERVER_LB/healthz 2\u003e/dev/null)\" == \"ok\" ]; do\n\tsleep 3\ndone\n\n# Setup CUDA devices before starting kubelet, so it detects the gpu(s)\n/sbin/modprobe nvidia\nif [ \"$?\" -eq 0 ]; then\n\t# Create the /dev/nvidia* files by running nvidia-smi\n\tnvidia-smi\nfi\n\n/sbin/modprobe nvidia-uvm\nif [ \"$?\" -eq 0 ]; then\n\t# Find out the major device number used by the nvidia-uvm driver\n\tDEVICE=$(grep nvidia-uvm /proc/devices | awk '{print $1}')\n\tmknod -m 666 /dev/nvidia-uvm c $DEVICE 0\nfi\n\nsleep $[ ( $RANDOM % 10 )  + 1 ]s\nsystemctl daemon-reload\nsystemctl enable kubelet\nsystemctl start kubelet\n\nyum install -y nfs-utils\n\n######################################\necho \"Finished running setup.sh\"\n",
                            "vars.%": "9",
                            "vars.docker_max_log_files": "5",
                            "vars.docker_max_log_size": "50m",
                            "vars.docker_ver": "17.06.2.ol",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.flexvolume_driver_version": "0.7.1",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443",
                            "vars.reverse_proxy_setup": "",
                            "vars.worker_iscsi_volume_mount": "/var/lib/docker"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.worker-kubeconfig": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "50c46b4b5e846f02b7c1681ecee94820d0304f0e00cf2b8dcb13fe7d8b00ea09",
                        "attributes": {
                            "id": "50c46b4b5e846f02b7c1681ecee94820d0304f0e00cf2b8dcb13fe7d8b00ea09",
                            "rendered": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    certificate-authority: /etc/kubernetes/ssl/ca.pem\n    server: https://129.213.198.168:443\nusers:\n- name: kubelet\n  user:\n    client-certificate: /etc/kubernetes/ssl/apiserver.pem\n    client-key: /etc/kubernetes/ssl/apiserver-key.pem\ncontexts:\n- context:\n    cluster: local\n    user: kubelet\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "template": "apiVersion: v1\nkind: Config\nclusters:\n- name: local\n  cluster:\n    certificate-authority: /etc/kubernetes/ssl/ca.pem\n    server: ${master_lb}\nusers:\n- name: kubelet\n  user:\n    client-certificate: /etc/kubernetes/ssl/apiserver.pem\n    client-key: /etc/kubernetes/ssl/apiserver-key.pem\ncontexts:\n- context:\n    cluster: local\n    user: kubelet\n  name: kubelet-context\ncurrent-context: kubelet-context\n",
                            "vars.%": "3",
                            "vars.domain_name": "kubernetes.oraclevcn.com",
                            "vars.k8s_ver": "1.9.6",
                            "vars.master_lb": "https://129.213.198.168:443"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "k8s-tls"
            ],
            "outputs": {
                "api_server_admin_token": {
                    "sensitive": false,
                    "type": "string",
                    "value": "56d89cea5bd825c5dcaedfbf8bd6bf5e"
                },
                "api_server_cert_pem": {
                    "sensitive": false,
                    "type": "string",
                    "value": "-----BEGIN CERTIFICATE-----\nMIIDtzCCAp+gAwIBAgIQakExFRzw73ebhR6ouRgM9jANBgkqhkiG9w0BAQsFADAS\nMRAwDgYDVQQDEwdrdWJlLWNhMB4XDTE5MDIwODAyMjQwNFoXDTIxMTEwNDAyMjQw\nNFowJTEXMBUGA1UEChMOc3lzdGVtOm1hc3RlcnMxCjAIBgNVBAMMASowggEiMA0G\nCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDtb5OCYlLojCYjuGgNQrM+Ips2V/oP\nzzhfVY0eVsWj4DqkOoWmV9PUItVYS2/D42p6TFYtkf8O5qmNhPe8Vq37Djesc5sn\nIP8Sd7a33FY26aKyRaHJFw6Vn22UuSOG21BMozyibxfGpW0UJeuCzk+CqV7CdVwD\npvJDwvqlnl9FB5/EhEva7ytTS3HLfBLG//Pm6eC7vll14SiXV5AFY2SNvxsz8T4E\nak/b7Qf4b8mWdgKQuW55wzbmesriYBb1IA5kwZebPlO0DuvoFxph4vjfb3CpFzGF\neNhPd8hdblBqATwrGo0ZBi+hPoBGYnlmPtsH95KeMiGJfhAlsVGuoCK/AgMBAAGj\ngfUwgfIwDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEF\nBQcDAjAMBgNVHRMBAf8EAjAAMB8GA1UdIwQYMBaAFLr6s2Mj9xrPY2SyhVZXVmlW\n6pnRMIGRBgNVHREEgYkwgYaCCTEwLjIxLjAuMYIJbG9jYWxob3N0ggprdWJlcm5l\ndGVzghJrdWJlcm5ldGVzLmRlZmF1bHSCFmt1YmVybmV0ZXMuZGVmYXVsdC5zdmOC\nJGt1YmVybmV0ZXMuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbIcEgdXGqIcEChUA\nAYcEfwAAATANBgkqhkiG9w0BAQsFAAOCAQEANxcaHsQ+O7/bRi1gMC05G3jdvulg\nQMf6HzJY7tRDDQVoJa4H2kpbS61m7rLKvqf0YTIb9UanxIl6kIyk2JkJaLEccZ19\n/4WyjRIQRf3Hc/YsL1pELUz3htyLd0m2BGhJuc0xI70lQOWOFM4f4cVeAniXmA74\nK8JNuVZrpC5pz3R4OnXbXE5pbHTbPwJa4nJrmA63oEVbNB0XVUiGwtgdpQFPowVA\ns98oq3dgP8tDAf+B6o0v2+foASppkpNXu33pAkDGZC2/OHY+IGIuuPWKv+jA8KzW\nHj3R/4sgDbXkbGO9Sy76F17a+1W0OTUz5dVOFCsEPOQELCu++YDvrjsiqg==\n-----END CERTIFICATE-----\n"
                },
                "api_server_private_key_pem": {
                    "sensitive": false,
                    "type": "string",
                    "value": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEA7W+TgmJS6IwmI7hoDUKzPiKbNlf6D884X1WNHlbFo+A6pDqF\nplfT1CLVWEtvw+NqekxWLZH/DuapjYT3vFat+w43rHObJyD/Ene2t9xWNumiskWh\nyRcOlZ9tlLkjhttQTKM8om8XxqVtFCXrgs5PgqlewnVcA6byQ8L6pZ5fRQefxIRL\n2u8rU0txy3wSxv/z5ungu75ZdeEol1eQBWNkjb8bM/E+BGpP2+0H+G/JlnYCkLlu\necM25nrK4mAW9SAOZMGXmz5TtA7r6BcaYeL4329wqRcxhXjYT3fIXW5QagE8KxqN\nGQYvoT6ARmJ5Zj7bB/eSnjIhiX4QJbFRrqAivwIDAQABAoIBAQDML0KUQsf3seZu\nm3vnw29vRMVjk365L8PTwDeOWqK2TfNAHg+nQCoraRU9TAo+VAjSSWlm4QGNp/Ex\ngaKl9YjCuLRJ+lT37llMYWThcns11++RDW6XBtwE8ciDuD8EDwBcF5jiO1UgAEzw\nobeJkrAvtkWGRvStM1ltynRQDwTwz3iYabMx2XV3z0tcl6vz7sYt8+61ZiBGZJ6T\nZI0Eqh16h+DHlJCi2VVUYo6i+QV39UverH9f0t2QQKbmmt7AYkB7Fl7XSCzw7fPa\ne4mOf3GHNyWCuwgtT1NLme7cBYa88JdfCdRUmHP+nU/weJgKIi5557Jzh7r7w+cR\nv4DY4pgxAoGBAPi31dWUj9JY3xZzLju/Qj0ZFEPfbB/Y5Vo7xZ0KIsOaxV6y6C3v\nYIEEPjF8dOz6OG88C+3T7qMRQi32Lxc1YTRxX/6ZaZs3/cSonn+qPp2HuvR2XKp+\n5J9w1iZkRKBd7ImBw5vedVUo6PLPOGmpF7yn0UYmqQV9epCn3SVoTJv5AoGBAPRj\nLelyetc51usp/rzaziSiPvR4n2/LyudanZt9tiWMwPg+DreOJBWc62xNBelD6W8/\nLo7zNko0wQbjlImds22WfLYHkDHBNeR6gqEKQxeb9roVSGzQpVgKEFvFqQ9GSyil\nJWpztYVR0raiJ6NbJ/FNRoiqRbjZh+zc4hMCNTJ3AoGAPPym/HYvRf7wxQp9Pb1K\nOr0ZkQMJ+k0vAA9EB5vipmAfIXdxI0JdQYWO0oeYDDvW9r+clTawf1/OAIMrTN+T\n9E4QoddwY9U47q4CH3/ZVrtfhm43jr8KxGXgvQ09Hq2pQJaHJoNH9hfP9yoExTPn\nVCU6VZ9JNsVr9miS+4c1sdECgYEAsizhG1OItgQIalmqzLvmEZVsusZ6z4JQQ46w\nW94yf3v4cMSl7DOooU1P4xzg02nc9mulITm2+jEuDjy8XfzpBVvzPq+S9IN+LD8Z\noBmgQsVGA/NiY1tXQTHNLWuVz3obb92/wrXrwPCf5OGibpoWK/qAE0G5JYULcai0\n9tDkQg8CgYEAjePBQTAmeigHdlooeGGIz24LjXxzH8NqAVxxrIDhJ//6tqTsEf9T\nr9TbfmE+UVVidUmE1r88DUOZWhzwJE0s1xFBxxChhCKz6PrWmRe6LNilncMwk4qX\nYapeG4Ayte6pkPGqYiaOcCcFtMAP0lwv6tjRyF2E2xQrNIV/+Bhz3TM=\n-----END RSA PRIVATE KEY-----\n"
                },
                "root_ca_key": {
                    "sensitive": false,
                    "type": "string",
                    "value": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEAymZqiWDxK1tTDSfyUsDh5FL/geP8PxbqiU4ROdvG+wJby/na\n3x8+HHseS0+YgWIviIaR6Q71gZCbDwG3t9EHJpkfAAh5LlRiePi+JoPu9wThszXA\nRSOQei/M2Me+faE7fvaE1j/RNPfOuSu5p6bcGaiB/ujM5qwn0r5TTtEuYBEigLpa\nHdxCSMK7X9uWpckSvShB+qvn1xnkzQAbXdlLHkqir6+df4iFIMJytpg+t0cWrwq2\nNAf7y0N9X5UXsMaJyfW7UNHSkiLv4hc2U0XG1xHaxYZd4ErztCCf+nfLh/fHZBWM\n1lB0ZMuF6c+GW62E+Ig3KafYFgz7QR6kMiXBWwIDAQABAoIBAQCRsfeuvKHeW/cE\n2WSOPVpeSYCzt7G0mIJsJE4yIAq0VZZO1qS/SHYlelrsS3e0a0FcPcJ6ydHgWn/D\n5bCiGU3UcxTlqTPSLdxUyHnYr9As8M6nemHVYyx1SENlKSPuu0lgs4Qb1gR65Idi\ntB8ImAyIS8yH+nzE79ga0/aUHfAMJgDwxNS/Qi/fV+fbPXtmBlNol5QuUklkE4Qd\n7cXqWVJ2PF3f703lTRHe4TuN6q1E30yYTpxos7twwKpmLyzTzm/R9oaeOlhyQFfY\n9bbVI5Hq6mYBmgIXxkDH1tfoO9bi/aGhd80OYUiA4gUP3QBdTT2hFMbax/d1B0OS\n7+Ka/SABAoGBAPQ/LmVIY2dnzxgEAUt68r/MVnKxJyYdQCl4eLzdAFTpjdwVCoie\n/fv67K+mZ6AbWyxOdZZ0kuwg4ZQtXdB3ZXQjvV63fdm1/VmOE98s+Qlz1TXI/aQB\nsux8rwkKmdlXi2JqpAIeeAWAiu3eFbdDSt4kivoYtW+JpsjJPKEW0toBAoGBANQj\nvB0ZEfk3ICPBD2/rDkYu+B3UqXwaJ6ezPkk7FrX1cv8lfc44kHzXPhxo2LyQ06Ps\nARBXI0As/JIIAtH+7dmFijvA9TYLuNQ5+qi/nhlMglDKAKcxVcdTGWDDkQZhzTin\n3WKSbvLD5ZIAVzgjupaZ5Bp4JLXsvLa7f/U+JENbAoGBAM+/7fa4W9TYt4312iQZ\nr+D0LZPgmywQNUMQ9aGvWVjgT4mjXBJZKi/qfufo4ruMiUBmfB49ibrPPRCMhf+L\njv/6ZljqOmG0KorCDqUF283ueKwHCbc2urnsU/Wczr/Pdv9/NYGX6P7FF2a8QDxh\nQI0zCAMygSEeNH8UrD1Y7IABAoGBAIyPoPUmx2H5xLHsGe5uMOcP+BbL8gDo052q\nhnq/TC0ElU256cHaeOI/PEhWsEVBMPpMRegt1I2RQUkBRd0erTqT4SP2loNZAP6d\n7Bgj3v2kVDRzpDsj1VJdHVOgQVeZNgF0OJw3qovwgQxcbW4lPlzLWviu4qQoWGI7\nmm1E34JBAoGATte+c89TMfQl5Dc4MnAmdq9DSCWsXrfVRJ4K/MeatDzN5m2+XqOj\npgctDublYDL5c1HmWRcek7giD1IRnF9+m/gVbjoO8dDT+3+rcITcu//g2x2cRjCH\nZiseuXAkzsfPZXiLthtm5VlrBXBoEs++MVNR77eN+NB5VbkWRGtktS8=\n-----END RSA PRIVATE KEY-----\n"
                },
                "root_ca_pem": {
                    "sensitive": false,
                    "type": "string",
                    "value": "-----BEGIN CERTIFICATE-----\nMIIDDzCCAfegAwIBAgIQFEkWp10c+v5ochlZQwhCJzANBgkqhkiG9w0BAQsFADAS\nMRAwDgYDVQQDEwdrdWJlLWNhMB4XDTE5MDIwODAyMjExMVoXDTIxMTEwNDAyMjEx\nMVowEjEQMA4GA1UEAxMHa3ViZS1jYTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCC\nAQoCggEBAMpmaolg8StbUw0n8lLA4eRS/4Hj/D8W6olOETnbxvsCW8v52t8fPhx7\nHktPmIFiL4iGkekO9YGQmw8Bt7fRByaZHwAIeS5UYnj4viaD7vcE4bM1wEUjkHov\nzNjHvn2hO372hNY/0TT3zrkruaem3Bmogf7ozOasJ9K+U07RLmARIoC6Wh3cQkjC\nu1/blqXJEr0oQfqr59cZ5M0AG13ZSx5Koq+vnX+IhSDCcraYPrdHFq8KtjQH+8tD\nfV+VF7DGicn1u1DR0pIi7+IXNlNFxtcR2sWGXeBK87Qgn/p3y4f3x2QVjNZQdGTL\nhenPhluthPiINymn2BYM+0EepDIlwVsCAwEAAaNhMF8wDgYDVR0PAQH/BAQDAgIk\nMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjAPBgNVHRMBAf8EBTADAQH/\nMB0GA1UdDgQWBBS6+rNjI/caz2NksoVWV1ZpVuqZ0TANBgkqhkiG9w0BAQsFAAOC\nAQEAmM9CRYXe1O7mDrp5wRxQ0aLy87gsx6Z/Edb5s2cVA6EZPFDBS0dRJHy/WT9U\nd8u0nepGXHXu0/p4X4nErm8+06NQHgygjK8NGMtW0nxSS39IvlKQpepsYzHMrLV4\nBlYfzEMFyFeRTjHlIVF9p7J4aMBQVEA41J/rvphaNU2nXaThBE6VusaEj/k996L2\nHLvmmyS9zpIFk4hJtUaz2yNQfV8avCjmY3vpWofJ+YaHvWZ1LVYATlakmhwprqAt\nwiGw4skudV0gYHKxz1pazODcovll831MCFu/D0gtYj7E/bBpERs6RkiyRpoNdaan\nacnvk7icSK9cVkMMcKrDKfF3MA==\n-----END CERTIFICATE-----\n"
                },
                "ssh_private_key": {
                    "sensitive": false,
                    "type": "string",
                    "value": "-----BEGIN RSA PRIVATE KEY-----\nMIIEowIBAAKCAQEAt7t/HV5OGVYSIqjDpukZGTg+VF1KBhQeNS3ZSZdocvQkhFwq\nUUy7K6vnFp/l+zEw7TCQ9vwfAiMkbGJ6XmqEUHf7iXPK6z8nJ5VXbakyy9QzRlBd\nIDJL2p6nWDKf1VeRbk03MGZ5DT56cuW/ynyEPBY44DHWreqdTwBxltxPZuBum9su\nbV1kFwxMedyk6cp57aKPTKgO8p1VX2cGm7JDV3zMeof1tzwUkdK/NcPLDEBuW4nF\nFSsthTQB9sC4yL9Yp9tzBRryTk3H1cXTGweeS3NsCw+wSfrgpQ87i2UwQOa0wet9\nrjswGZg2zA5fXtKkO7B7HbihqA552eQiTOWF5wIDAQABAoIBAHI4/0qbwUPhDX88\nmf3fNjpGjAFYyddDlJANA+PLXCTzAOzEe451fHsm8JBRMeHa8AbVRZo2nXRvsoor\nItYltEJuhRMryIA9j7L9FhBXuvua3ZGeDncgraWpMnITbuhr+z6uhFvzqNgB+pAJ\noxVYGcFdM1i1wzf1/nwJ05QtPLPAT3oF1SFNcoVRyNaTHp6RLHk8UZVP5Cl4toFm\n60mnrWBhqVbXSwqIFTB9TDIHnO0zI5L7/x/P2Ya+iGjlCWAXcrwrIGxZA7hhU9pQ\n4HrjM8uOAsZPLXg28+x06rqDJoLy39k/1VqrzZ0Zwe4Qbf8vzbvWYONLtRtSYILd\n5f7j+vECgYEA2an2lnwypesBbELtG4tN6WqEkcYz06N8bW0ARiU3Va3B2NRJVYU4\n9k+9LgLehPRRSEbOlxtNISlGQGtKblwvhY3XHeYWjtBtfmaURwL5Izc2gq02YqfX\nd2RQXTZ37ZE4Woj+wf+xtFIHYJ2b5B5lg+l+sx8MIOUvPezeBvbzH7kCgYEA2Beg\n4KhfFwz1ByGKlowPgVXg99qNiBA/BaDff+xuJ3zcb+krlPSmGIsEgPXy69943gYB\nfsSMLMbyAKhf/VieqRmqek8YF7TcYirokXFJm8dgLXgZyKOJbpjwVezWrzq77PSI\nfFsLMaTF2tamB3c0iho8GzzkvGIWZWgXkAfAYp8CgYEAvc/g0ORnypbAe+d1G+ME\nQ3v3NaRRR8s207oNVh5YPegztmGRvflabjmlMP2hjPH9+/h7afyN61AyCjVGCC1t\n55qEsHcYztvl0CemQLLQDiy05Yoldi0F0gDxsAey18IfEZyMBSN0lVo/QrrO2kTD\npCA3s/5sNjeGVgs8p3gtFkkCgYBdEKgPuVPiuIjavl5SghW3bQYLmMu1mtGZmfRH\nwsqaJRNG+1Pyvf6+uTiCVep+HWuPq2R/dSStsCzPjbRxhvYl+9DJBkFpDFKR0MsC\nwJikB5TrYDsyhwQMZr+zMeIv64q9/X6+l/NVORKhMiqlMnilNbFHRc15OIFOwSrM\ntBnuHwKBgGEtmX8KeyrXCHVo4dfSoYbmrDXR+OutOHsh62XgQwD0RpS5dWCzhwQi\n5YHwJPZ0b5t08BW8IJmnFZbQLCgRUBmsT++OQ5kzZZfr5v7my5Dspkz6T77+syHx\nzHRKYLOZ23HbVOI/6PCfQkiTNMjt88PFhk6PupC7COqSqYOdRcPt\n-----END RSA PRIVATE KEY-----\n"
                },
                "ssh_public_key_openssh": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3u38dXk4ZVhIiqMOm6RkZOD5UXUoGFB41LdlJl2hy9CSEXCpRTLsrq+cWn+X7MTDtMJD2/B8CIyRsYnpeaoRQd/uJc8rrPycnlVdtqTLL1DNGUF0gMkvanqdYMp/VV5FuTTcwZnkNPnpy5b/KfIQ8FjjgMdat6p1PAHGW3E9m4G6b2y5tXWQXDEx53KTpynntoo9MqA7ynVVfZwabskNXfMx6h/W3PBSR0r81w8sMQG5bicUVKy2FNAH2wLjIv1in23MFGvJOTcfVxdMbB55Lc2wLD7BJ+uClDzuLZTBA5rTB632uOzAZmDbMDl9e0qQ7sHsduKGoDnnZ5CJM5YXn\n"
                }
            },
            "resources": {
                "random_id.token-auth": {
                    "type": "random_id",
                    "depends_on": [],
                    "primary": {
                        "id": "Vtic6lvYJcXcrt-_i9a_Xg",
                        "attributes": {
                            "b64": "Vtic6lvYJcXcrt-_i9a_Xg",
                            "b64_std": "Vtic6lvYJcXcrt+/i9a/Xg==",
                            "b64_url": "Vtic6lvYJcXcrt-_i9a_Xg",
                            "byte_length": "16",
                            "dec": "115438326382658928084180630253122010974",
                            "hex": "56d89cea5bd825c5dcaedfbf8bd6bf5e",
                            "id": "Vtic6lvYJcXcrt-_i9a_Xg"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.random"
                },
                "tls_cert_request.api-server": {
                    "type": "tls_cert_request",
                    "depends_on": [
                        "tls_private_key.api-server"
                    ],
                    "primary": {
                        "id": "990bc775b89e89687dc0b486aab86f632ee7524e",
                        "attributes": {
                            "cert_request_pem": "-----BEGIN CERTIFICATE REQUEST-----\nMIIDEzCCAfsCAQAwJTEXMBUGA1UEChMOc3lzdGVtOm1hc3RlcnMxCjAIBgNVBAMM\nASowggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDtb5OCYlLojCYjuGgN\nQrM+Ips2V/oPzzhfVY0eVsWj4DqkOoWmV9PUItVYS2/D42p6TFYtkf8O5qmNhPe8\nVq37Djesc5snIP8Sd7a33FY26aKyRaHJFw6Vn22UuSOG21BMozyibxfGpW0UJeuC\nzk+CqV7CdVwDpvJDwvqlnl9FB5/EhEva7ytTS3HLfBLG//Pm6eC7vll14SiXV5AF\nY2SNvxsz8T4Eak/b7Qf4b8mWdgKQuW55wzbmesriYBb1IA5kwZebPlO0DuvoFxph\n4vjfb3CpFzGFeNhPd8hdblBqATwrGo0ZBi+hPoBGYnlmPtsH95KeMiGJfhAlsVGu\noCK/AgMBAAGggagwgaUGCSqGSIb3DQEJDjGBlzCBlDCBkQYDVR0RBIGJMIGGggkx\nMC4yMS4wLjGCCWxvY2FsaG9zdIIKa3ViZXJuZXRlc4ISa3ViZXJuZXRlcy5kZWZh\ndWx0ghZrdWJlcm5ldGVzLmRlZmF1bHQuc3ZjgiRrdWJlcm5ldGVzLmRlZmF1bHQu\nc3ZjLmNsdXN0ZXIubG9jYWyHBIHVxqiHBAoVAAGHBH8AAAEwDQYJKoZIhvcNAQEL\nBQADggEBAK2bZx8nVeseg6NdRda1WVRrRrU7PWui9azH/KMqiydGoP6ivOV7Vgkd\nVJEFEGdUR7UMtVYOFapueWaDivobLwN10xV5fsYKPWDtXB6eqKU/or6FX16tpd/m\n6e897O0NmdN2883IUjtjxpr6MEpyG2XsRZuj6Wlcucjf6BC6CE3T12vuQNRTszPf\nCfLELpZqJ5Mw8hzwTDqXjTxHxZebYUf63T9lt0QkTyChhCz3BtgrfvB1a5a2DsLD\neXCGb+/Ddhq4HQeaddiEM9tGeae6P3HDZLLYjiKipDt4zbjGv3XwfSThYXZKOX9C\nVoaTOSXjctfutPGSH2gKwn+IteSmgYY=\n-----END CERTIFICATE REQUEST-----\n",
                            "dns_names.#": "6",
                            "dns_names.0": "10.21.0.1",
                            "dns_names.1": "localhost",
                            "dns_names.2": "kubernetes",
                            "dns_names.3": "kubernetes.default",
                            "dns_names.4": "kubernetes.default.svc",
                            "dns_names.5": "kubernetes.default.svc.cluster.local",
                            "id": "990bc775b89e89687dc0b486aab86f632ee7524e",
                            "ip_addresses.#": "3",
                            "ip_addresses.0": "129.213.198.168",
                            "ip_addresses.1": "10.21.0.1",
                            "ip_addresses.2": "127.0.0.1",
                            "key_algorithm": "RSA",
                            "private_key_pem": "7df7e9cee4484058a7aa9009fd73f50ee87177a6",
                            "subject.#": "1",
                            "subject.0.common_name": "*",
                            "subject.0.country": "",
                            "subject.0.locality": "",
                            "subject.0.organization": "system:masters",
                            "subject.0.organizational_unit": "",
                            "subject.0.postal_code": "",
                            "subject.0.province": "",
                            "subject.0.serial_number": "",
                            "subject.0.street_address.#": "0"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.tls"
                },
                "tls_locally_signed_cert.api-server": {
                    "type": "tls_locally_signed_cert",
                    "depends_on": [
                        "tls_cert_request.api-server",
                        "tls_private_key.root-ca",
                        "tls_self_signed_cert.root-ca"
                    ],
                    "primary": {
                        "id": "141236662359824691378723414031507918070",
                        "attributes": {
                            "allowed_uses.#": "4",
                            "allowed_uses.0": "key_encipherment",
                            "allowed_uses.1": "server_auth",
                            "allowed_uses.2": "client_auth",
                            "allowed_uses.3": "digital_signature",
                            "ca_cert_pem": "0aa1db3294741250a1e1f3e6120d6be08e022f91",
                            "ca_key_algorithm": "RSA",
                            "ca_private_key_pem": "196bbc9c05bc6ce654a5673a5ca6399431091111",
                            "cert_pem": "-----BEGIN CERTIFICATE-----\nMIIDtzCCAp+gAwIBAgIQakExFRzw73ebhR6ouRgM9jANBgkqhkiG9w0BAQsFADAS\nMRAwDgYDVQQDEwdrdWJlLWNhMB4XDTE5MDIwODAyMjQwNFoXDTIxMTEwNDAyMjQw\nNFowJTEXMBUGA1UEChMOc3lzdGVtOm1hc3RlcnMxCjAIBgNVBAMMASowggEiMA0G\nCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDtb5OCYlLojCYjuGgNQrM+Ips2V/oP\nzzhfVY0eVsWj4DqkOoWmV9PUItVYS2/D42p6TFYtkf8O5qmNhPe8Vq37Djesc5sn\nIP8Sd7a33FY26aKyRaHJFw6Vn22UuSOG21BMozyibxfGpW0UJeuCzk+CqV7CdVwD\npvJDwvqlnl9FB5/EhEva7ytTS3HLfBLG//Pm6eC7vll14SiXV5AFY2SNvxsz8T4E\nak/b7Qf4b8mWdgKQuW55wzbmesriYBb1IA5kwZebPlO0DuvoFxph4vjfb3CpFzGF\neNhPd8hdblBqATwrGo0ZBi+hPoBGYnlmPtsH95KeMiGJfhAlsVGuoCK/AgMBAAGj\ngfUwgfIwDgYDVR0PAQH/BAQDAgWgMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEF\nBQcDAjAMBgNVHRMBAf8EAjAAMB8GA1UdIwQYMBaAFLr6s2Mj9xrPY2SyhVZXVmlW\n6pnRMIGRBgNVHREEgYkwgYaCCTEwLjIxLjAuMYIJbG9jYWxob3N0ggprdWJlcm5l\ndGVzghJrdWJlcm5ldGVzLmRlZmF1bHSCFmt1YmVybmV0ZXMuZGVmYXVsdC5zdmOC\nJGt1YmVybmV0ZXMuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbIcEgdXGqIcEChUA\nAYcEfwAAATANBgkqhkiG9w0BAQsFAAOCAQEANxcaHsQ+O7/bRi1gMC05G3jdvulg\nQMf6HzJY7tRDDQVoJa4H2kpbS61m7rLKvqf0YTIb9UanxIl6kIyk2JkJaLEccZ19\n/4WyjRIQRf3Hc/YsL1pELUz3htyLd0m2BGhJuc0xI70lQOWOFM4f4cVeAniXmA74\nK8JNuVZrpC5pz3R4OnXbXE5pbHTbPwJa4nJrmA63oEVbNB0XVUiGwtgdpQFPowVA\ns98oq3dgP8tDAf+B6o0v2+foASppkpNXu33pAkDGZC2/OHY+IGIuuPWKv+jA8KzW\nHj3R/4sgDbXkbGO9Sy76F17a+1W0OTUz5dVOFCsEPOQELCu++YDvrjsiqg==\n-----END CERTIFICATE-----\n",
                            "cert_request_pem": "c8e9532eaeaa41f0097d8643b048011568c8fc1e",
                            "early_renewal_hours": "0",
                            "id": "141236662359824691378723414031507918070",
                            "validity_end_time": "2021-11-04T02:24:04.914191577Z",
                            "validity_period_hours": "24000",
                            "validity_start_time": "2019-02-08T02:24:04.914191577Z"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.tls"
                },
                "tls_private_key.api-server": {
                    "type": "tls_private_key",
                    "depends_on": [],
                    "primary": {
                        "id": "00b11e4c4cc643849a6f4fc635c6d3288d2cb6f6",
                        "attributes": {
                            "algorithm": "RSA",
                            "ecdsa_curve": "P224",
                            "id": "00b11e4c4cc643849a6f4fc635c6d3288d2cb6f6",
                            "private_key_pem": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEA7W+TgmJS6IwmI7hoDUKzPiKbNlf6D884X1WNHlbFo+A6pDqF\nplfT1CLVWEtvw+NqekxWLZH/DuapjYT3vFat+w43rHObJyD/Ene2t9xWNumiskWh\nyRcOlZ9tlLkjhttQTKM8om8XxqVtFCXrgs5PgqlewnVcA6byQ8L6pZ5fRQefxIRL\n2u8rU0txy3wSxv/z5ungu75ZdeEol1eQBWNkjb8bM/E+BGpP2+0H+G/JlnYCkLlu\necM25nrK4mAW9SAOZMGXmz5TtA7r6BcaYeL4329wqRcxhXjYT3fIXW5QagE8KxqN\nGQYvoT6ARmJ5Zj7bB/eSnjIhiX4QJbFRrqAivwIDAQABAoIBAQDML0KUQsf3seZu\nm3vnw29vRMVjk365L8PTwDeOWqK2TfNAHg+nQCoraRU9TAo+VAjSSWlm4QGNp/Ex\ngaKl9YjCuLRJ+lT37llMYWThcns11++RDW6XBtwE8ciDuD8EDwBcF5jiO1UgAEzw\nobeJkrAvtkWGRvStM1ltynRQDwTwz3iYabMx2XV3z0tcl6vz7sYt8+61ZiBGZJ6T\nZI0Eqh16h+DHlJCi2VVUYo6i+QV39UverH9f0t2QQKbmmt7AYkB7Fl7XSCzw7fPa\ne4mOf3GHNyWCuwgtT1NLme7cBYa88JdfCdRUmHP+nU/weJgKIi5557Jzh7r7w+cR\nv4DY4pgxAoGBAPi31dWUj9JY3xZzLju/Qj0ZFEPfbB/Y5Vo7xZ0KIsOaxV6y6C3v\nYIEEPjF8dOz6OG88C+3T7qMRQi32Lxc1YTRxX/6ZaZs3/cSonn+qPp2HuvR2XKp+\n5J9w1iZkRKBd7ImBw5vedVUo6PLPOGmpF7yn0UYmqQV9epCn3SVoTJv5AoGBAPRj\nLelyetc51usp/rzaziSiPvR4n2/LyudanZt9tiWMwPg+DreOJBWc62xNBelD6W8/\nLo7zNko0wQbjlImds22WfLYHkDHBNeR6gqEKQxeb9roVSGzQpVgKEFvFqQ9GSyil\nJWpztYVR0raiJ6NbJ/FNRoiqRbjZh+zc4hMCNTJ3AoGAPPym/HYvRf7wxQp9Pb1K\nOr0ZkQMJ+k0vAA9EB5vipmAfIXdxI0JdQYWO0oeYDDvW9r+clTawf1/OAIMrTN+T\n9E4QoddwY9U47q4CH3/ZVrtfhm43jr8KxGXgvQ09Hq2pQJaHJoNH9hfP9yoExTPn\nVCU6VZ9JNsVr9miS+4c1sdECgYEAsizhG1OItgQIalmqzLvmEZVsusZ6z4JQQ46w\nW94yf3v4cMSl7DOooU1P4xzg02nc9mulITm2+jEuDjy8XfzpBVvzPq+S9IN+LD8Z\noBmgQsVGA/NiY1tXQTHNLWuVz3obb92/wrXrwPCf5OGibpoWK/qAE0G5JYULcai0\n9tDkQg8CgYEAjePBQTAmeigHdlooeGGIz24LjXxzH8NqAVxxrIDhJ//6tqTsEf9T\nr9TbfmE+UVVidUmE1r88DUOZWhzwJE0s1xFBxxChhCKz6PrWmRe6LNilncMwk4qX\nYapeG4Ayte6pkPGqYiaOcCcFtMAP0lwv6tjRyF2E2xQrNIV/+Bhz3TM=\n-----END RSA PRIVATE KEY-----\n",
                            "public_key_fingerprint_md5": "3d:ca:49:bd:8c:b9:e2:df:a5:0e:c1:7a:4c:fd:ea:0f",
                            "public_key_openssh": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDtb5OCYlLojCYjuGgNQrM+Ips2V/oPzzhfVY0eVsWj4DqkOoWmV9PUItVYS2/D42p6TFYtkf8O5qmNhPe8Vq37Djesc5snIP8Sd7a33FY26aKyRaHJFw6Vn22UuSOG21BMozyibxfGpW0UJeuCzk+CqV7CdVwDpvJDwvqlnl9FB5/EhEva7ytTS3HLfBLG//Pm6eC7vll14SiXV5AFY2SNvxsz8T4Eak/b7Qf4b8mWdgKQuW55wzbmesriYBb1IA5kwZebPlO0DuvoFxph4vjfb3CpFzGFeNhPd8hdblBqATwrGo0ZBi+hPoBGYnlmPtsH95KeMiGJfhAlsVGuoCK/\n",
                            "public_key_pem": "-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA7W+TgmJS6IwmI7hoDUKz\nPiKbNlf6D884X1WNHlbFo+A6pDqFplfT1CLVWEtvw+NqekxWLZH/DuapjYT3vFat\n+w43rHObJyD/Ene2t9xWNumiskWhyRcOlZ9tlLkjhttQTKM8om8XxqVtFCXrgs5P\ngqlewnVcA6byQ8L6pZ5fRQefxIRL2u8rU0txy3wSxv/z5ungu75ZdeEol1eQBWNk\njb8bM/E+BGpP2+0H+G/JlnYCkLluecM25nrK4mAW9SAOZMGXmz5TtA7r6BcaYeL4\n329wqRcxhXjYT3fIXW5QagE8KxqNGQYvoT6ARmJ5Zj7bB/eSnjIhiX4QJbFRrqAi\nvwIDAQAB\n-----END PUBLIC KEY-----\n",
                            "rsa_bits": "2048"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.tls"
                },
                "tls_private_key.root-ca": {
                    "type": "tls_private_key",
                    "depends_on": [],
                    "primary": {
                        "id": "7219798781fb71d18da1f42a2f79c4d180d5cdda",
                        "attributes": {
                            "algorithm": "RSA",
                            "ecdsa_curve": "P224",
                            "id": "7219798781fb71d18da1f42a2f79c4d180d5cdda",
                            "private_key_pem": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEAymZqiWDxK1tTDSfyUsDh5FL/geP8PxbqiU4ROdvG+wJby/na\n3x8+HHseS0+YgWIviIaR6Q71gZCbDwG3t9EHJpkfAAh5LlRiePi+JoPu9wThszXA\nRSOQei/M2Me+faE7fvaE1j/RNPfOuSu5p6bcGaiB/ujM5qwn0r5TTtEuYBEigLpa\nHdxCSMK7X9uWpckSvShB+qvn1xnkzQAbXdlLHkqir6+df4iFIMJytpg+t0cWrwq2\nNAf7y0N9X5UXsMaJyfW7UNHSkiLv4hc2U0XG1xHaxYZd4ErztCCf+nfLh/fHZBWM\n1lB0ZMuF6c+GW62E+Ig3KafYFgz7QR6kMiXBWwIDAQABAoIBAQCRsfeuvKHeW/cE\n2WSOPVpeSYCzt7G0mIJsJE4yIAq0VZZO1qS/SHYlelrsS3e0a0FcPcJ6ydHgWn/D\n5bCiGU3UcxTlqTPSLdxUyHnYr9As8M6nemHVYyx1SENlKSPuu0lgs4Qb1gR65Idi\ntB8ImAyIS8yH+nzE79ga0/aUHfAMJgDwxNS/Qi/fV+fbPXtmBlNol5QuUklkE4Qd\n7cXqWVJ2PF3f703lTRHe4TuN6q1E30yYTpxos7twwKpmLyzTzm/R9oaeOlhyQFfY\n9bbVI5Hq6mYBmgIXxkDH1tfoO9bi/aGhd80OYUiA4gUP3QBdTT2hFMbax/d1B0OS\n7+Ka/SABAoGBAPQ/LmVIY2dnzxgEAUt68r/MVnKxJyYdQCl4eLzdAFTpjdwVCoie\n/fv67K+mZ6AbWyxOdZZ0kuwg4ZQtXdB3ZXQjvV63fdm1/VmOE98s+Qlz1TXI/aQB\nsux8rwkKmdlXi2JqpAIeeAWAiu3eFbdDSt4kivoYtW+JpsjJPKEW0toBAoGBANQj\nvB0ZEfk3ICPBD2/rDkYu+B3UqXwaJ6ezPkk7FrX1cv8lfc44kHzXPhxo2LyQ06Ps\nARBXI0As/JIIAtH+7dmFijvA9TYLuNQ5+qi/nhlMglDKAKcxVcdTGWDDkQZhzTin\n3WKSbvLD5ZIAVzgjupaZ5Bp4JLXsvLa7f/U+JENbAoGBAM+/7fa4W9TYt4312iQZ\nr+D0LZPgmywQNUMQ9aGvWVjgT4mjXBJZKi/qfufo4ruMiUBmfB49ibrPPRCMhf+L\njv/6ZljqOmG0KorCDqUF283ueKwHCbc2urnsU/Wczr/Pdv9/NYGX6P7FF2a8QDxh\nQI0zCAMygSEeNH8UrD1Y7IABAoGBAIyPoPUmx2H5xLHsGe5uMOcP+BbL8gDo052q\nhnq/TC0ElU256cHaeOI/PEhWsEVBMPpMRegt1I2RQUkBRd0erTqT4SP2loNZAP6d\n7Bgj3v2kVDRzpDsj1VJdHVOgQVeZNgF0OJw3qovwgQxcbW4lPlzLWviu4qQoWGI7\nmm1E34JBAoGATte+c89TMfQl5Dc4MnAmdq9DSCWsXrfVRJ4K/MeatDzN5m2+XqOj\npgctDublYDL5c1HmWRcek7giD1IRnF9+m/gVbjoO8dDT+3+rcITcu//g2x2cRjCH\nZiseuXAkzsfPZXiLthtm5VlrBXBoEs++MVNR77eN+NB5VbkWRGtktS8=\n-----END RSA PRIVATE KEY-----\n",
                            "public_key_fingerprint_md5": "92:68:9d:c1:0a:10:1a:e4:20:20:d4:57:3a:99:3d:f2",
                            "public_key_openssh": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDKZmqJYPErW1MNJ/JSwOHkUv+B4/w/FuqJThE528b7AlvL+drfHz4cex5LT5iBYi+IhpHpDvWBkJsPAbe30QcmmR8ACHkuVGJ4+L4mg+73BOGzNcBFI5B6L8zYx759oTt+9oTWP9E09865K7mnptwZqIH+6MzmrCfSvlNO0S5gESKAulod3EJIwrtf25alyRK9KEH6q+fXGeTNABtd2UseSqKvr51/iIUgwnK2mD63RxavCrY0B/vLQ31flRewxonJ9btQ0dKSIu/iFzZTRcbXEdrFhl3gSvO0IJ/6d8uH98dkFYzWUHRky4Xpz4ZbrYT4iDcpp9gWDPtBHqQyJcFb\n",
                            "public_key_pem": "-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAymZqiWDxK1tTDSfyUsDh\n5FL/geP8PxbqiU4ROdvG+wJby/na3x8+HHseS0+YgWIviIaR6Q71gZCbDwG3t9EH\nJpkfAAh5LlRiePi+JoPu9wThszXARSOQei/M2Me+faE7fvaE1j/RNPfOuSu5p6bc\nGaiB/ujM5qwn0r5TTtEuYBEigLpaHdxCSMK7X9uWpckSvShB+qvn1xnkzQAbXdlL\nHkqir6+df4iFIMJytpg+t0cWrwq2NAf7y0N9X5UXsMaJyfW7UNHSkiLv4hc2U0XG\n1xHaxYZd4ErztCCf+nfLh/fHZBWM1lB0ZMuF6c+GW62E+Ig3KafYFgz7QR6kMiXB\nWwIDAQAB\n-----END PUBLIC KEY-----\n",
                            "rsa_bits": "2048"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.tls"
                },
                "tls_private_key.ssh": {
                    "type": "tls_private_key",
                    "depends_on": [],
                    "primary": {
                        "id": "55bfce7233b97bc677b9c49b693d4bd46236926a",
                        "attributes": {
                            "algorithm": "RSA",
                            "ecdsa_curve": "P224",
                            "id": "55bfce7233b97bc677b9c49b693d4bd46236926a",
                            "private_key_pem": "-----BEGIN RSA PRIVATE KEY-----\nMIIEowIBAAKCAQEAt7t/HV5OGVYSIqjDpukZGTg+VF1KBhQeNS3ZSZdocvQkhFwq\nUUy7K6vnFp/l+zEw7TCQ9vwfAiMkbGJ6XmqEUHf7iXPK6z8nJ5VXbakyy9QzRlBd\nIDJL2p6nWDKf1VeRbk03MGZ5DT56cuW/ynyEPBY44DHWreqdTwBxltxPZuBum9su\nbV1kFwxMedyk6cp57aKPTKgO8p1VX2cGm7JDV3zMeof1tzwUkdK/NcPLDEBuW4nF\nFSsthTQB9sC4yL9Yp9tzBRryTk3H1cXTGweeS3NsCw+wSfrgpQ87i2UwQOa0wet9\nrjswGZg2zA5fXtKkO7B7HbihqA552eQiTOWF5wIDAQABAoIBAHI4/0qbwUPhDX88\nmf3fNjpGjAFYyddDlJANA+PLXCTzAOzEe451fHsm8JBRMeHa8AbVRZo2nXRvsoor\nItYltEJuhRMryIA9j7L9FhBXuvua3ZGeDncgraWpMnITbuhr+z6uhFvzqNgB+pAJ\noxVYGcFdM1i1wzf1/nwJ05QtPLPAT3oF1SFNcoVRyNaTHp6RLHk8UZVP5Cl4toFm\n60mnrWBhqVbXSwqIFTB9TDIHnO0zI5L7/x/P2Ya+iGjlCWAXcrwrIGxZA7hhU9pQ\n4HrjM8uOAsZPLXg28+x06rqDJoLy39k/1VqrzZ0Zwe4Qbf8vzbvWYONLtRtSYILd\n5f7j+vECgYEA2an2lnwypesBbELtG4tN6WqEkcYz06N8bW0ARiU3Va3B2NRJVYU4\n9k+9LgLehPRRSEbOlxtNISlGQGtKblwvhY3XHeYWjtBtfmaURwL5Izc2gq02YqfX\nd2RQXTZ37ZE4Woj+wf+xtFIHYJ2b5B5lg+l+sx8MIOUvPezeBvbzH7kCgYEA2Beg\n4KhfFwz1ByGKlowPgVXg99qNiBA/BaDff+xuJ3zcb+krlPSmGIsEgPXy69943gYB\nfsSMLMbyAKhf/VieqRmqek8YF7TcYirokXFJm8dgLXgZyKOJbpjwVezWrzq77PSI\nfFsLMaTF2tamB3c0iho8GzzkvGIWZWgXkAfAYp8CgYEAvc/g0ORnypbAe+d1G+ME\nQ3v3NaRRR8s207oNVh5YPegztmGRvflabjmlMP2hjPH9+/h7afyN61AyCjVGCC1t\n55qEsHcYztvl0CemQLLQDiy05Yoldi0F0gDxsAey18IfEZyMBSN0lVo/QrrO2kTD\npCA3s/5sNjeGVgs8p3gtFkkCgYBdEKgPuVPiuIjavl5SghW3bQYLmMu1mtGZmfRH\nwsqaJRNG+1Pyvf6+uTiCVep+HWuPq2R/dSStsCzPjbRxhvYl+9DJBkFpDFKR0MsC\nwJikB5TrYDsyhwQMZr+zMeIv64q9/X6+l/NVORKhMiqlMnilNbFHRc15OIFOwSrM\ntBnuHwKBgGEtmX8KeyrXCHVo4dfSoYbmrDXR+OutOHsh62XgQwD0RpS5dWCzhwQi\n5YHwJPZ0b5t08BW8IJmnFZbQLCgRUBmsT++OQ5kzZZfr5v7my5Dspkz6T77+syHx\nzHRKYLOZ23HbVOI/6PCfQkiTNMjt88PFhk6PupC7COqSqYOdRcPt\n-----END RSA PRIVATE KEY-----\n",
                            "public_key_fingerprint_md5": "18:92:4a:96:7b:d8:97:37:e3:73:39:e1:0d:d3:e1:c3",
                            "public_key_openssh": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3u38dXk4ZVhIiqMOm6RkZOD5UXUoGFB41LdlJl2hy9CSEXCpRTLsrq+cWn+X7MTDtMJD2/B8CIyRsYnpeaoRQd/uJc8rrPycnlVdtqTLL1DNGUF0gMkvanqdYMp/VV5FuTTcwZnkNPnpy5b/KfIQ8FjjgMdat6p1PAHGW3E9m4G6b2y5tXWQXDEx53KTpynntoo9MqA7ynVVfZwabskNXfMx6h/W3PBSR0r81w8sMQG5bicUVKy2FNAH2wLjIv1in23MFGvJOTcfVxdMbB55Lc2wLD7BJ+uClDzuLZTBA5rTB632uOzAZmDbMDl9e0qQ7sHsduKGoDnnZ5CJM5YXn\n",
                            "public_key_pem": "-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAt7t/HV5OGVYSIqjDpukZ\nGTg+VF1KBhQeNS3ZSZdocvQkhFwqUUy7K6vnFp/l+zEw7TCQ9vwfAiMkbGJ6XmqE\nUHf7iXPK6z8nJ5VXbakyy9QzRlBdIDJL2p6nWDKf1VeRbk03MGZ5DT56cuW/ynyE\nPBY44DHWreqdTwBxltxPZuBum9subV1kFwxMedyk6cp57aKPTKgO8p1VX2cGm7JD\nV3zMeof1tzwUkdK/NcPLDEBuW4nFFSsthTQB9sC4yL9Yp9tzBRryTk3H1cXTGwee\nS3NsCw+wSfrgpQ87i2UwQOa0wet9rjswGZg2zA5fXtKkO7B7HbihqA552eQiTOWF\n5wIDAQAB\n-----END PUBLIC KEY-----\n",
                            "rsa_bits": "2048"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.tls"
                },
                "tls_self_signed_cert.root-ca": {
                    "type": "tls_self_signed_cert",
                    "depends_on": [
                        "tls_private_key.root-ca"
                    ],
                    "primary": {
                        "id": "26964057059302921214806691339290821159",
                        "attributes": {
                            "allowed_uses.#": "4",
                            "allowed_uses.0": "key_encipherment",
                            "allowed_uses.1": "cert_signing",
                            "allowed_uses.2": "server_auth",
                            "allowed_uses.3": "client_auth",
                            "cert_pem": "-----BEGIN CERTIFICATE-----\nMIIDDzCCAfegAwIBAgIQFEkWp10c+v5ochlZQwhCJzANBgkqhkiG9w0BAQsFADAS\nMRAwDgYDVQQDEwdrdWJlLWNhMB4XDTE5MDIwODAyMjExMVoXDTIxMTEwNDAyMjEx\nMVowEjEQMA4GA1UEAxMHa3ViZS1jYTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCC\nAQoCggEBAMpmaolg8StbUw0n8lLA4eRS/4Hj/D8W6olOETnbxvsCW8v52t8fPhx7\nHktPmIFiL4iGkekO9YGQmw8Bt7fRByaZHwAIeS5UYnj4viaD7vcE4bM1wEUjkHov\nzNjHvn2hO372hNY/0TT3zrkruaem3Bmogf7ozOasJ9K+U07RLmARIoC6Wh3cQkjC\nu1/blqXJEr0oQfqr59cZ5M0AG13ZSx5Koq+vnX+IhSDCcraYPrdHFq8KtjQH+8tD\nfV+VF7DGicn1u1DR0pIi7+IXNlNFxtcR2sWGXeBK87Qgn/p3y4f3x2QVjNZQdGTL\nhenPhluthPiINymn2BYM+0EepDIlwVsCAwEAAaNhMF8wDgYDVR0PAQH/BAQDAgIk\nMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjAPBgNVHRMBAf8EBTADAQH/\nMB0GA1UdDgQWBBS6+rNjI/caz2NksoVWV1ZpVuqZ0TANBgkqhkiG9w0BAQsFAAOC\nAQEAmM9CRYXe1O7mDrp5wRxQ0aLy87gsx6Z/Edb5s2cVA6EZPFDBS0dRJHy/WT9U\nd8u0nepGXHXu0/p4X4nErm8+06NQHgygjK8NGMtW0nxSS39IvlKQpepsYzHMrLV4\nBlYfzEMFyFeRTjHlIVF9p7J4aMBQVEA41J/rvphaNU2nXaThBE6VusaEj/k996L2\nHLvmmyS9zpIFk4hJtUaz2yNQfV8avCjmY3vpWofJ+YaHvWZ1LVYATlakmhwprqAt\nwiGw4skudV0gYHKxz1pazODcovll831MCFu/D0gtYj7E/bBpERs6RkiyRpoNdaan\nacnvk7icSK9cVkMMcKrDKfF3MA==\n-----END CERTIFICATE-----\n",
                            "early_renewal_hours": "0",
                            "id": "26964057059302921214806691339290821159",
                            "is_ca_certificate": "true",
                            "key_algorithm": "RSA",
                            "private_key_pem": "196bbc9c05bc6ce654a5673a5ca6399431091111",
                            "subject.#": "1",
                            "subject.0.common_name": "kube-ca",
                            "subject.0.country": "",
                            "subject.0.locality": "",
                            "subject.0.organization": "",
                            "subject.0.organizational_unit": "",
                            "subject.0.postal_code": "",
                            "subject.0.province": "",
                            "subject.0.serial_number": "",
                            "subject.0.street_address.#": "0",
                            "validity_end_time": "2021-11-04T02:21:11.299735774Z",
                            "validity_period_hours": "24000",
                            "validity_start_time": "2019-02-08T02:21:11.299735774Z"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.tls"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "k8smaster-public-lb"
            ],
            "outputs": {
                "backendset_name": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "backendset-https"
                    ]
                },
                "ip_addresses": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "129.213.198.168"
                    ]
                },
                "load_balancer_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.loadbalancer.oc1.iad.aaaaaaaadynmpm3xzyc7x7zmcwvzbk2zirkl4ve6mzlemdroohmmyk22s3va"
                    ]
                }
            },
            "resources": {
                "oci_load_balancer.lb-k8smaster": {
                    "type": "oci_load_balancer",
                    "depends_on": [],
                    "primary": {
                        "id": "ocid1.loadbalancer.oc1.iad.aaaaaaaadynmpm3xzyc7x7zmcwvzbk2zirkl4ve6mzlemdroohmmyk22s3va",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "lb-k8smaster",
                            "id": "ocid1.loadbalancer.oc1.iad.aaaaaaaadynmpm3xzyc7x7zmcwvzbk2zirkl4ve6mzlemdroohmmyk22s3va",
                            "ip_addresses.#": "1",
                            "ip_addresses.0": "129.213.198.168",
                            "is_private": "false",
                            "shape": "400Mbps",
                            "state": "ACTIVE",
                            "subnet_ids.#": "2",
                            "subnet_ids.0": "ocid1.subnet.oc1.iad.aaaaaaaagzy4dlm25w6gn7z523ss56qvdk3cnpfsrcigk3curx33toaktvja",
                            "subnet_ids.1": "ocid1.subnet.oc1.iad.aaaaaaaadcgbuknfac25c6tf5ivuyylpixb7uamdpzjz5u3sc6nq6jklfq7a",
                            "time_created": "2019-02-08 02:23:16.208 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_load_balancer_backendset.lb-k8smaster-https": {
                    "type": "oci_load_balancer_backendset",
                    "depends_on": [
                        "oci_load_balancer.lb-k8smaster"
                    ],
                    "primary": {
                        "id": "backendset-https",
                        "attributes": {
                            "backend.#": "0",
                            "health_checker.#": "1",
                            "health_checker.0.interval_ms": "30000",
                            "health_checker.0.port": "443",
                            "health_checker.0.protocol": "TCP",
                            "health_checker.0.response_body_regex": ".*",
                            "health_checker.0.retries": "3",
                            "health_checker.0.return_code": "200",
                            "health_checker.0.timeout_in_millis": "3000",
                            "health_checker.0.url_path": "",
                            "id": "backendset-https",
                            "load_balancer_id": "ocid1.loadbalancer.oc1.iad.aaaaaaaadynmpm3xzyc7x7zmcwvzbk2zirkl4ve6mzlemdroohmmyk22s3va",
                            "name": "backendset-https",
                            "policy": "ROUND_ROBIN",
                            "session_persistence_configuration.#": "0",
                            "ssl_configuration.#": "0",
                            "state": "SUCCEEDED"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_load_balancer_listener.port-https": {
                    "type": "oci_load_balancer_listener",
                    "depends_on": [
                        "oci_load_balancer.lb-k8smaster",
                        "oci_load_balancer_backendset.lb-k8smaster-https"
                    ],
                    "primary": {
                        "id": "port-https",
                        "attributes": {
                            "connection_configuration.#": "1",
                            "connection_configuration.0.idle_timeout_in_seconds": "300",
                            "default_backend_set_name": "backendset-https",
                            "hostname_names.#": "0",
                            "id": "port-https",
                            "load_balancer_id": "ocid1.loadbalancer.oc1.iad.aaaaaaaadynmpm3xzyc7x7zmcwvzbk2zirkl4ve6mzlemdroohmmyk22s3va",
                            "name": "port-https",
                            "port": "443",
                            "protocol": "TCP",
                            "ssl_configuration.#": "0",
                            "state": "SUCCEEDED"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "kubeconfig"
            ],
            "outputs": {},
            "resources": {},
            "depends_on": []
        },
        {
            "path": [
                "root",
                "oci-cloud-controller"
            ],
            "outputs": {
                "cloud-provider-json": {
                    "sensitive": false,
                    "type": "string",
                    "value": "{\n    \"apiVersion\": \"v1\",\n    \"data\": {\n        \"cloud-provider.yaml\": \"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\"\n    },\n    \"kind\": \"Secret\",\n    \"metadata\": {\n        \"name\": \"oci-cloud-controller-manager\",\n        \"namespace\": \"kube-system\"\n    },\n    \"type\": \"Opaque\"\n}\n"
                }
            },
            "resources": {
                "data.template_file.cloud-provider-json": {
                    "type": "template_file",
                    "depends_on": [
                        "data.template_file.oci-cloud-controller-secret"
                    ],
                    "primary": {
                        "id": "7144a43bdcc37c0019b99331056939cb6905ef01a1a099fd7830a1b57c282780",
                        "attributes": {
                            "id": "7144a43bdcc37c0019b99331056939cb6905ef01a1a099fd7830a1b57c282780",
                            "rendered": "{\n    \"apiVersion\": \"v1\",\n    \"data\": {\n        \"cloud-provider.yaml\": \"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\"\n    },\n    \"kind\": \"Secret\",\n    \"metadata\": {\n        \"name\": \"oci-cloud-controller-manager\",\n        \"namespace\": \"kube-system\"\n    },\n    \"type\": \"Opaque\"\n}\n",
                            "template": "{\n    \"apiVersion\": \"v1\",\n    \"data\": {\n        \"cloud-provider.yaml\": \"${cloud_provider_secret_yaml}\"\n    },\n    \"kind\": \"Secret\",\n    \"metadata\": {\n        \"name\": \"oci-cloud-controller-manager\",\n        \"namespace\": \"kube-system\"\n    },\n    \"type\": \"Opaque\"\n}\n",
                            "vars.%": "1",
                            "vars.cloud_provider_secret_yaml": "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"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "data.template_file.oci-cloud-controller-secret": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "fcf4bcf3aa0deecc9cd1f504fd2307fc8618d5a10b9d3fabef1b2893cb52eb91",
                        "attributes": {
                            "id": "fcf4bcf3aa0deecc9cd1f504fd2307fc8618d5a10b9d3fabef1b2893cb52eb91",
                            "rendered": "auth:\n  region: us-ashburn-1\n  tenancy: ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq\n  compartment: ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq\n  user: ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq\n  key: \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"\n  fingerprint: 04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0\n  key_passphrase: \n  \nloadBalancer:\n  # disableSecurityListManagement disables the automatic creation of ingress\n  # rules for the node subnets and egress rules for the load balancers to the\n  # node subnets.\n  #\n  # If security list management is disabled, then it requires that the user\n  # has setup a rule that allows inbound traffic to the appropriate ports\n  # for kube proxy health port, node port ranges, and health check port ranges.\n  # E.g. 10.82.0.0/16 30000-32000\n  disableSecurityListManagement: false\n\n  # subnet1 configures one of two subnets to which load balancers will be added.\n  # OCI load balancers require two subnets to ensure high availability.\n  subnet1: ocid1.subnet.oc1.iad.aaaaaaaawlpvf7zgpwlu6hovzi5nbdinf4iinzsagb4rqdf6qr5l6a3t7uba\n\n  # subnet2 configures the second of two subnets to which load balancers will\n  # be added.  OCI load balancers require two subnets to ensure high\n  # availability.\n  subnet2: ocid1.subnet.oc1.iad.aaaaaaaa2ohaovg3thspzp2vjpwje6akrdmgxtj3k57bgsgcja63235la36a\n",
                            "template": "auth:\n  region: ${region}\n  tenancy: ${tenancy}\n  compartment: ${compartment}\n  user: ${user}\n  key: ${key}\n  fingerprint: ${fingerprint}\n  key_passphrase: ${key_passphrase}\n  \nloadBalancer:\n  # disableSecurityListManagement disables the automatic creation of ingress\n  # rules for the node subnets and egress rules for the load balancers to the\n  # node subnets.\n  #\n  # If security list management is disabled, then it requires that the user\n  # has setup a rule that allows inbound traffic to the appropriate ports\n  # for kube proxy health port, node port ranges, and health check port ranges.\n  # E.g. 10.82.0.0/16 30000-32000\n  disableSecurityListManagement: false\n\n  # subnet1 configures one of two subnets to which load balancers will be added.\n  # OCI load balancers require two subnets to ensure high availability.\n  subnet1: ${subnet1}\n\n  # subnet2 configures the second of two subnets to which load balancers will\n  # be added.  OCI load balancers require two subnets to ensure high\n  # availability.\n  subnet2: ${subnet2}\n",
                            "vars.%": "9",
                            "vars.compartment": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "vars.fingerprint": "04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0",
                            "vars.key": "\"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"",
                            "vars.key_passphrase": "",
                            "vars.region": "us-ashburn-1",
                            "vars.subnet1": "ocid1.subnet.oc1.iad.aaaaaaaawlpvf7zgpwlu6hovzi5nbdinf4iinzsagb4rqdf6qr5l6a3t7uba",
                            "vars.subnet2": "ocid1.subnet.oc1.iad.aaaaaaaa2ohaovg3thspzp2vjpwje6akrdmgxtj3k57bgsgcja63235la36a",
                            "vars.tenancy": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "vars.user": "ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "oci-flexvolume-driver"
            ],
            "outputs": {
                "flex-volume-driver-yaml": {
                    "sensitive": false,
                    "type": "string",
                    "value": "---\nauth:\n  tenancy: ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq\n  user: ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq\n  key: \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"\n  fingerprint: 04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0\n  vcn: ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra\n  key_passphase: \n"
                }
            },
            "resources": {
                "data.template_file.oci-flexvolume-driver-yaml": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "dc2d29894487aa66dfc8e9292f7355231e510b778b15296c29465b2e783fa107",
                        "attributes": {
                            "id": "dc2d29894487aa66dfc8e9292f7355231e510b778b15296c29465b2e783fa107",
                            "rendered": "---\nauth:\n  tenancy: ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq\n  user: ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq\n  key: \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"\n  fingerprint: 04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0\n  vcn: ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra\n  key_passphase: \n",
                            "template": "---\nauth:\n  tenancy: ${tenancy}\n  user: ${user}\n  key: ${key}\n  fingerprint: ${fingerprint}\n  vcn: ${vcn}\n  key_passphase: ${key_passphrase}\n",
                            "vars.%": "6",
                            "vars.fingerprint": "04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0",
                            "vars.key": "\"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"",
                            "vars.key_passphrase": "",
                            "vars.tenancy": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "vars.user": "ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq",
                            "vars.vcn": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "oci-volume-provisioner"
            ],
            "outputs": {
                "volume-provisioner-yaml": {
                    "sensitive": false,
                    "type": "string",
                    "value": "auth:\n  tenancy: ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq\n  user: ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq\n  key: \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"\n  fingerprint: 04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0 \n  region: us-ashburn-1\n  compartment: ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq\n  key_passphrase: \n"
                }
            },
            "resources": {
                "data.template_file.oci-volume-provisioner-yaml": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "3a8045e89fc5bea46bf6ee38a49c45d49554b76a254990a2b28028774ed8836a",
                        "attributes": {
                            "id": "3a8045e89fc5bea46bf6ee38a49c45d49554b76a254990a2b28028774ed8836a",
                            "rendered": "auth:\n  tenancy: ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq\n  user: ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq\n  key: \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"\n  fingerprint: 04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0 \n  region: us-ashburn-1\n  compartment: ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq\n  key_passphrase: \n",
                            "template": "auth:\n  tenancy: ${tenancy}\n  user: ${user}\n  key: ${key}\n  fingerprint: ${fingerprint} \n  region: ${region}\n  compartment: ${compartment}\n  key_passphrase: ${key_passphrase}\n",
                            "vars.%": "7",
                            "vars.compartment": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "vars.fingerprint": "04:cd:31:f8:b4:87:e1:3c:c8:5d:3d:2d:ed:8e:1a:d0",
                            "vars.key": "\"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEAvZxS2i3yWb4HEo4ZkZzz6TClVGIhZ8Tp6F2A0UF86ppVUqBE\\n6GnLc0yt5dar8K4OcbLmPZwBX1T3V7T0aMc7iz/kqw5+ZkX6BGw4MLSqnZyHkGtI\\njlBQh2bCVGCQHtTtlR33oF5t1BDFjikiCVnxJZtIi6MBHVoHowXlXElREOJQYmFH\\n4ZWW5Dqe2BWp1lqfEbKvDbn2auqwoGkChaGdJ9ia93/DHuKAJg5yJrhXG8j9jHEZ\\nqFTcr+pAQdT2e8V2gpPCm+srFBdfFdbUZLnSQSH0kaVcuJx5Jv1sqIIZydiYU6mn\\nYhJwuwj3jS4iaQOgK3kDr+WvwkVjiO86pEqXbwIDAQABAoIBAA+eDpz1595IbqCy\\nn5yExvpQDW4T3xiC+ZkwCmox8K4KJDj4BnT2MdG/YRtrQSJD0+C9kYVFkj9d6jmJ\\nKBBxSJBBpP4J5ZNa9CrlFwO7/cmZmPjmPUWri9Z7Okpk4boIY8FChKDq5jTvZLY+\\n4RTQGbK1RZZqyK64OaTN2YRubYTsWpuBc31a8lQOiGfA6Z1zP3yr3BiPUceCj84W\\nU4guEjqCyJKVIg9SVcxCghsV0+YJPY5rcuqY1K1BYfeZ9T/RAle5PSJYpkDIqSgs\\nYFbEBdzy4ztM1zzxeUJMAWhe5WhpHJBRZHe33cQR5O/ggWjbaERlSICTFPvnGPFD\\nO+mzjsECgYEA9dcVP0HzzenYGJCloyLpFzxg13pvC2eSKAPL4Ru29sn42h4sp4hT\\nw8ATyJJTHUppoFMSOQZZxQkcWUzpYlmd+t+vD5+aVi9lDcTiaQGJJjAR+z2SkX/T\\nEKIwzMwlXYRA+0RRP+PnDxxIsOsqqI0isGZ8hQpX4GeWAVMNaPFMY/ECgYEAxXJZ\\nQ/YdS3GqTdRqvpkIxZWcjCZWeT+nezUIC2JxOPojhQdXQC26yb51qluVXOs2aIcB\\nSsSEqMSVmSIShYmHRhsu1MWY++dPG38rN+y0lB5OSCPKlmaQxfTyY4S03I2/mA9Y\\n76UKxwSKiwfQYr7pIp5PEQHEjzBgzsvtJTe2kV8CgYEAmpP7ECNwIXGAJzIMdF9n\\nIO0eF18so4ckJ3T7pTe/+71TdBK1EUJvKQ6FYgBfsnMvp1eUhbawi2wHHz91IBop\\nc61ibfh1GuwCJn49vrjwe8qOA+PbXRF6rWLOPHfApuSZ12RFkl7C0oV+T4AO+pyD\\ny1clxKGUT83STFLkg6/10IECgYEAuTV5HHHpqtI1YQpnEuB0RPsBPMndhaC7Fqx5\\nHky6Tir9VJS9OFttAj8hGqsL4XxVrhktkhfjJHg6p8k5PH/0H0PyWu37ghfIsc9J\\nGA12mhYPckX4i7osBTSuhcF+8gAY/6ct0qWrBWJyHtY2l9ni0HFVU2uoGHTV6kWJ\\n7sZi/9sCgYAv1oyKxTA/wBtxP7mmNiu+QyBHTi72OHj82jswSC0jyKAJq6yNlmKo\\noH3F4GLVtkeUgrLzvLxQL9d7m9NUM1ZmCr4NVhUgPZr0IH3YiDksSAF/k4mneuzY\\ncYmQ0cRwT+8TptkvOPp5NBXprkFnpGhGc39pfGuh/azjXv8CZqS/fw==\\n-----END RSA PRIVATE KEY-----\\n\"",
                            "vars.key_passphrase": "",
                            "vars.region": "us-ashburn-1",
                            "vars.tenancy": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "vars.user": "ocid1.user.oc1..aaaaaaaangsahezapgxbyaj7shxhbgzghxpiumy5bcwadbtln67btb5sampq"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "reverse-proxy"
            ],
            "outputs": {
                "setup": {
                    "sensitive": false,
                    "type": "string",
                    "value": "docker run -d -v /etc/nginx:/etc/nginx --name nginx-proxy --net=host --restart=always nginx:1.13.1\n"
                }
            },
            "resources": {
                "data.template_file.setup": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "13a587628e5b618465efde8c3660f1a25b5ccd796cc94f8acfa4761b6ecf62a0",
                        "attributes": {
                            "id": "13a587628e5b618465efde8c3660f1a25b5ccd796cc94f8acfa4761b6ecf62a0",
                            "rendered": "docker run -d -v /etc/nginx:/etc/nginx --name nginx-proxy --net=host --restart=always nginx:1.13.1\n",
                            "template": "docker run -d -v /etc/nginx:/etc/nginx --name nginx-proxy --net=host --restart=always nginx:${nginx_version}\n",
                            "vars.%": "2",
                            "vars.nginx_listen_port": "6443",
                            "vars.nginx_version": "1.13.1"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "vcn"
            ],
            "outputs": {
                "ccmlb_subnet_ad1_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaawlpvf7zgpwlu6hovzi5nbdinf4iinzsagb4rqdf6qr5l6a3t7uba"
                    ]
                },
                "ccmlb_subnet_ad2_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaa2ohaovg3thspzp2vjpwje6akrdmgxtj3k57bgsgcja63235la36a"
                    ]
                },
                "ccmlb_subnet_ad3_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaa6rg4zrgomrivnwdcfmx4audqr3lbdwvzzfvamqlz4v6cqkh4jeua"
                    ]
                },
                "control_plane_subnet_access": {
                    "sensitive": false,
                    "type": "string",
                    "value": "private"
                },
                "dhcp_options_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq"
                },
                "etcd_subnet_ad1_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaaf7xofr4fl6ceqs2wukk4it6amuzljtnj44srqfif5p43oxnemyga"
                },
                "etcd_subnet_ad2_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaaxiqvp52kdugxhyfv2svsbap34it4dymr2felbnjfi2lxjiwqvwnq"
                },
                "etcd_subnet_ad3_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaap2rwkhbboizkwub3aialqrv3xnzw6s3vpjw7dfjjydbkzbckljca"
                },
                "id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                },
                "k8smaster_subnet_ad1_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaa3mx26p2ylaqsw5no5qxnihqhxqdpqukkpt4msuevcpfguyat6d7a"
                },
                "k8smaster_subnet_ad2_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaagyxrq2uygyhhyltjjc3ghljjrjq5sk5mpmevkfdjl5uuohnkjttq"
                },
                "k8smaster_subnet_ad3_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaaumqfgoz6o7s32wqvf5ddowxz5likw5xepxcvi7xcv554w575acpa"
                },
                "k8worker_subnet_ad1_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaaefqwgcbfss43qxjvcrovz3a6zaqskdfyuif65b7eqpuz3omexuhq"
                },
                "k8worker_subnet_ad2_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaabhkzbvfotkst2mbwxyloesuq6pcvmkext3tjddfjdm3coo2geikq"
                },
                "k8worker_subnet_ad3_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.subnet.oc1.iad.aaaaaaaavop32xhqq7frm4ahwe7mwazf6soe3wtizx7wmvh4jqxfzjv7p6uq"
                },
                "nat_instance_ad1_private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "10.0.13.2"
                    ]
                },
                "nat_instance_ad1_public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "129.213.127.98"
                    ]
                },
                "nat_instance_ad2_private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "nat_instance_ad2_public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "nat_instance_ad3_private_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "nat_instance_ad3_public_ips": {
                    "sensitive": false,
                    "type": "list",
                    "value": []
                },
                "nat_subnet_ad1_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q"
                    ]
                },
                "nat_subnet_ad2_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaamezfmzw4xkoduqzuxrsfreouitkhsxnmo4uukd4btrnrwxht4nyq"
                    ]
                },
                "nat_subnet_ad3_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaak7bxex6ssockzoemup537dntkdllu44ltln224safckvdsnxrz6a"
                    ]
                },
                "public_subnet_ad1_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaagzy4dlm25w6gn7z523ss56qvdk3cnpfsrcigk3curx33toaktvja"
                    ]
                },
                "public_subnet_ad2_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaadcgbuknfac25c6tf5ivuyylpixb7uamdpzjz5u3sc6nq6jklfq7a"
                    ]
                },
                "public_subnet_ad3_id": {
                    "sensitive": false,
                    "type": "list",
                    "value": [
                        "ocid1.subnet.oc1.iad.aaaaaaaanlzfxpjupyuol5g6o6ee3weqsthblapdwcltykn572yaxsrxba3q"
                    ]
                },
                "route_for_complete_id": {
                    "sensitive": false,
                    "type": "string",
                    "value": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda"
                }
            },
            "resources": {
                "data.oci_core_images.ImageOCID": {
                    "type": "oci_core_images",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.814245297 +0000 UTC",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "CentOS-6.10-2019.01.14-0",
                            "id": "2019-02-08 02:20:51.814245297 +0000 UTC",
                            "images.#": "1",
                            "images.0.base_image_id": "",
                            "images.0.compartment_id": "",
                            "images.0.create_image_allowed": "true",
                            "images.0.display_name": "CentOS-6.10-2019.01.14-0",
                            "images.0.id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "images.0.instance_id": "",
                            "images.0.launch_mode": "NATIVE",
                            "images.0.launch_options.#": "1",
                            "images.0.launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "images.0.launch_options.0.firmware": "UEFI_64",
                            "images.0.launch_options.0.network_type": "VFIO",
                            "images.0.launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "images.0.operating_system": "CentOS",
                            "images.0.operating_system_version": "6.10",
                            "images.0.size_in_mbs": "47694",
                            "images.0.state": "AVAILABLE",
                            "images.0.time_created": "2019-01-15 20:14:56.411 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_core_private_ips.NATInstanceAD1PrivateIPDatasource": {
                    "type": "oci_core_private_ips",
                    "depends_on": [
                        "data.oci_core_vnic.NATInstanceAD1Vnic"
                    ],
                    "primary": {
                        "id": "2019-02-08 02:23:06.543362814 +0000 UTC",
                        "attributes": {
                            "id": "2019-02-08 02:23:06.543362814 +0000 UTC",
                            "private_ips.#": "1",
                            "private_ips.0.availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "private_ips.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "private_ips.0.display_name": "instance20190208022116",
                            "private_ips.0.hostname_label": "",
                            "private_ips.0.id": "ocid1.privateip.oc1.iad.abuwcljtm6rdkypazmyjbl5oujjmad4vusaz3egsvidv2mkw46fsmvfctfmq",
                            "private_ips.0.ip_address": "10.0.13.2",
                            "private_ips.0.is_primary": "true",
                            "private_ips.0.subnet_id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                            "private_ips.0.time_created": "2019-02-08 02:21:18.495 +0000 UTC",
                            "private_ips.0.vnic_id": "ocid1.vnic.oc1.iad.abuwcljt25k7wfi546lwkqfw737f3ujz6roaqiwdshn3lr7kxelgz7fgrxha",
                            "vnic_id": "ocid1.vnic.oc1.iad.abuwcljt25k7wfi546lwkqfw737f3ujz6roaqiwdshn3lr7kxelgz7fgrxha"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_core_vnic.NATInstanceAD1Vnic": {
                    "type": "oci_core_vnic",
                    "depends_on": [
                        "data.oci_core_vnic_attachments.NATInstanceAD1Vnics"
                    ],
                    "primary": {
                        "id": "ocid1.vnic.oc1.iad.abuwcljt25k7wfi546lwkqfw737f3ujz6roaqiwdshn3lr7kxelgz7fgrxha",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "instance20190208022116",
                            "id": "ocid1.vnic.oc1.iad.abuwcljt25k7wfi546lwkqfw737f3ujz6roaqiwdshn3lr7kxelgz7fgrxha",
                            "is_primary": "true",
                            "mac_address": "00:00:17:02:90:CE",
                            "private_ip_address": "10.0.13.2",
                            "public_ip_address": "129.213.127.98",
                            "skip_source_dest_check": "true",
                            "state": "AVAILABLE",
                            "subnet_id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                            "time_created": "2019-02-08 02:21:18.495 +0000 UTC",
                            "vnic_id": "ocid1.vnic.oc1.iad.abuwcljt25k7wfi546lwkqfw737f3ujz6roaqiwdshn3lr7kxelgz7fgrxha"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_core_vnic_attachments.NATInstanceAD1Vnics": {
                    "type": "oci_core_vnic_attachments",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_instance.NATInstanceAD1"
                    ],
                    "primary": {
                        "id": "2019-02-08 02:23:05.985238898 +0000 UTC",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "id": "2019-02-08 02:23:05.985238898 +0000 UTC",
                            "instance_id": "ocid1.instance.oc1.iad.abuwcljtpjvd5lifbl5bpfpngwzob2nr3n2dlpnrpynyidtjrij67kqzqo4q",
                            "vnic_attachments.#": "1",
                            "vnic_attachments.0.availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "vnic_attachments.0.compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "vnic_attachments.0.create_vnic_details.#": "0",
                            "vnic_attachments.0.display_name": "",
                            "vnic_attachments.0.id": "ocid1.vnicattachment.oc1.iad.abuwcljtlnsclxhic2ypciusfdb4kkw4ycoulmiqacydx52hr3hucfcv7jxq",
                            "vnic_attachments.0.instance_id": "ocid1.instance.oc1.iad.abuwcljtpjvd5lifbl5bpfpngwzob2nr3n2dlpnrpynyidtjrij67kqzqo4q",
                            "vnic_attachments.0.nic_index": "0",
                            "vnic_attachments.0.state": "ATTACHED",
                            "vnic_attachments.0.subnet_id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                            "vnic_attachments.0.time_created": "2019-02-08 02:21:18.732 +0000 UTC",
                            "vnic_attachments.0.vlan_tag": "783",
                            "vnic_attachments.0.vnic_id": "ocid1.vnic.oc1.iad.abuwcljt25k7wfi546lwkqfw737f3ujz6roaqiwdshn3lr7kxelgz7fgrxha"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "data.oci_identity_availability_domains.ADs": {
                    "type": "oci_identity_availability_domains",
                    "depends_on": [],
                    "primary": {
                        "id": "2019-02-08 02:20:51.743606776 +0000 UTC",
                        "attributes": {
                            "availability_domains.#": "3",
                            "availability_domains.0.compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "availability_domains.0.name": "AhKQ:US-ASHBURN-AD-1",
                            "availability_domains.1.compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "availability_domains.1.name": "AhKQ:US-ASHBURN-AD-2",
                            "availability_domains.2.compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "availability_domains.2.name": "AhKQ:US-ASHBURN-AD-3",
                            "compartment_id": "ocid1.tenancy.oc1..aaaaaaaaqaghoakhcdlsdsej676gkzli4gbeeqw3ge46kgnm224lagmfj4xq",
                            "id": "2019-02-08 02:20:51.743606776 +0000 UTC"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_instance.NATInstanceAD1": {
                    "type": "oci_core_instance",
                    "depends_on": [
                        "data.oci_core_images.ImageOCID",
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_subnet.NATSubnetAD1.*",
                        "oci_core_subnet.PublicSubnetAD1"
                    ],
                    "primary": {
                        "id": "ocid1.instance.oc1.iad.abuwcljtpjvd5lifbl5bpfpngwzob2nr3n2dlpnrpynyidtjrij67kqzqo4q",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "boot_volume_id": "ocid1.bootvolume.oc1.iad.abuwcljt3fxztxl27qijcekeqnv3nqatdztvxxogsri2ai2667hbpqro564q",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "create_vnic_details.#": "1",
                            "create_vnic_details.0.assign_public_ip": "true",
                            "create_vnic_details.0.display_name": "instance20190208022116",
                            "create_vnic_details.0.hostname_label": "",
                            "create_vnic_details.0.private_ip": "10.0.13.2",
                            "create_vnic_details.0.skip_source_dest_check": "true",
                            "create_vnic_details.0.subnet_id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                            "display_name": "instance20190208022116",
                            "hostname_label": "",
                            "id": "ocid1.instance.oc1.iad.abuwcljtpjvd5lifbl5bpfpngwzob2nr3n2dlpnrpynyidtjrij67kqzqo4q",
                            "image": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "launch_mode": "NATIVE",
                            "launch_options.#": "1",
                            "launch_options.0.boot_volume_type": "PARAVIRTUALIZED",
                            "launch_options.0.firmware": "UEFI_64",
                            "launch_options.0.network_type": "VFIO",
                            "launch_options.0.remote_data_volume_type": "PARAVIRTUALIZED",
                            "metadata.%": "2",
                            "metadata.ssh_authorized_keys": "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC3u38dXk4ZVhIiqMOm6RkZOD5UXUoGFB41LdlJl2hy9CSEXCpRTLsrq+cWn+X7MTDtMJD2/B8CIyRsYnpeaoRQd/uJc8rrPycnlVdtqTLL1DNGUF0gMkvanqdYMp/VV5FuTTcwZnkNPnpy5b/KfIQ8FjjgMdat6p1PAHGW3E9m4G6b2y5tXWQXDEx53KTpynntoo9MqA7ynVVfZwabskNXfMx6h/W3PBSR0r81w8sMQG5bicUVKy2FNAH2wLjIv1in23MFGvJOTcfVxdMbB55Lc2wLD7BJ+uClDzuLZTBA5rTB632uOzAZmDbMDl9e0qQ7sHsduKGoDnnZ5CJM5YXn\n",
                            "metadata.user_data": "I2Nsb3VkLWNvbmZpZwoKd3JpdGVfZmlsZXM6CiAgIyBDcmVhdGUgZmlsZSB0byBiZSB1c2VkIHdoZW4gZW5hYmxpbmcgaXAgZm9yd2FyZGluZwogIC0gcGF0aDogL2V0Yy9zeXNjdGwuZC85OC1pcC1mb3J3YXJkLmNvbmYKICAgIGNvbnRlbnQ6IHwKICAgICAgbmV0LmlwdjQuaXBfZm9yd2FyZCA9IDEKCnJ1bmNtZDoKICAjIFJ1biBmaXJld2FsbCBjb21tYW5kcyB0byBlbmFibGUgbWFzcXVlcmFkaW5nIGFuZCBwb3J0IGZvcndhcmRpbmcKICAjIEVuYWJsZSBpcCBmb3J3YXJkaW5nIGJ5IHNldHRpbmcgc3lzY3RsIGtlcm5lbCBwYXJhbWV0ZXIKICAtIGZpcmV3YWxsLW9mZmxpbmUtY21kIC0tZGlyZWN0IC0tYWRkLXJ1bGUgaXB2NCBuYXQgUE9TVFJPVVRJTkcgMCAtbyBlbnMzIC1qIE1BU1FVRVJBREUKICAtIGZpcmV3YWxsLW9mZmxpbmUtY21kIC0tZGlyZWN0IC0tYWRkLXJ1bGUgaXB2NCBmaWx0ZXIgRk9SV0FSRCAwIC1pIGVuczMgLWogQUNDRVBUCiAgLSAvYmluL3N5c3RlbWN0bCByZXN0YXJ0IGZpcmV3YWxsZAogIC0gc3lzY3RsIC1wIC9ldGMvc3lzY3RsLmQvOTgtaXAtZm9yd2FyZC5jb25mCg==",
                            "private_ip": "10.0.13.2",
                            "public_ip": "129.213.127.98",
                            "region": "iad",
                            "shape": "VM.Standard2.1",
                            "source_details.#": "1",
                            "source_details.0.boot_volume_size_in_gbs": "47",
                            "source_details.0.source_id": "ocid1.image.oc1.iad.aaaaaaaapemjuo7hjs2pcxrglukfszovg7rm4wcgdnz4k4adxs4rtqywkskq",
                            "source_details.0.source_type": "image",
                            "state": "RUNNING",
                            "subnet_id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                            "time_created": "2019-02-08 02:21:16.357 +0000 UTC"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 600000000000,
                                "delete": 7200000000000,
                                "update": 7200000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_internet_gateway.PublicIG": {
                    "type": "oci_core_internet_gateway",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.internetgateway.oc1.iad.aaaaaaaaufezv56bfdki67doe5zwzujkqo3fcpqvoav3rygi3escett7wbvq",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "PublicIG",
                            "enabled": "true",
                            "id": "ocid1.internetgateway.oc1.iad.aaaaaaaaufezv56bfdki67doe5zwzujkqo3fcpqvoav3rygi3escett7wbvq",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:11.331 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_route_table.NATInstanceAD1RouteTable": {
                    "type": "oci_core_route_table",
                    "depends_on": [
                        "data.oci_core_private_ips.NATInstanceAD1PrivateIPDatasource",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "NATInstanceAD1RouteTable",
                            "id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "route_rules.#": "1",
                            "route_rules.0.cidr_block": "0.0.0.0/0",
                            "route_rules.0.network_entity_id": "ocid1.privateip.oc1.iad.abuwcljtm6rdkypazmyjbl5oujjmad4vusaz3egsvidv2mkw46fsmvfctfmq",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:23:06.784 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_route_table.PublicRouteTable": {
                    "type": "oci_core_route_table",
                    "depends_on": [
                        "oci_core_internet_gateway.PublicIG",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "RouteTableForComplete",
                            "id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "route_rules.#": "1",
                            "route_rules.0.cidr_block": "0.0.0.0/0",
                            "route_rules.0.network_entity_id": "ocid1.internetgateway.oc1.iad.aaaaaaaaufezv56bfdki67doe5zwzujkqo3fcpqvoav3rygi3escett7wbvq",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:12.322 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_security_list.EtcdSubnet": {
                    "type": "oci_core_security_list",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.securitylist.oc1.iad.aaaaaaaaa4p6phc3zxmxkdqwaqrwx75dtma5jpkpheo37sapv5ivlhm4tyoa",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "etcd_security_list",
                            "egress_security_rules.#": "1",
                            "egress_security_rules.0.destination": "0.0.0.0/0",
                            "egress_security_rules.0.icmp_options.#": "0",
                            "egress_security_rules.0.protocol": "all",
                            "egress_security_rules.0.stateless": "false",
                            "egress_security_rules.0.tcp_options.#": "0",
                            "egress_security_rules.0.udp_options.#": "0",
                            "id": "ocid1.securitylist.oc1.iad.aaaaaaaaa4p6phc3zxmxkdqwaqrwx75dtma5jpkpheo37sapv5ivlhm4tyoa",
                            "ingress_security_rules.#": "7",
                            "ingress_security_rules.0.icmp_options.#": "1",
                            "ingress_security_rules.0.icmp_options.0.code": "4",
                            "ingress_security_rules.0.icmp_options.0.type": "3",
                            "ingress_security_rules.0.protocol": "1",
                            "ingress_security_rules.0.source": "0.0.0.0/0",
                            "ingress_security_rules.0.stateless": "false",
                            "ingress_security_rules.0.tcp_options.#": "0",
                            "ingress_security_rules.0.udp_options.#": "0",
                            "ingress_security_rules.1.icmp_options.#": "1",
                            "ingress_security_rules.1.icmp_options.0.code": "4",
                            "ingress_security_rules.1.icmp_options.0.type": "3",
                            "ingress_security_rules.1.protocol": "1",
                            "ingress_security_rules.1.source": "10.0.0.0/16",
                            "ingress_security_rules.1.stateless": "false",
                            "ingress_security_rules.1.tcp_options.#": "0",
                            "ingress_security_rules.1.udp_options.#": "0",
                            "ingress_security_rules.2.icmp_options.#": "0",
                            "ingress_security_rules.2.protocol": "6",
                            "ingress_security_rules.2.source": "129.144.0.0/12",
                            "ingress_security_rules.2.stateless": "false",
                            "ingress_security_rules.2.tcp_options.#": "0",
                            "ingress_security_rules.2.udp_options.#": "0",
                            "ingress_security_rules.3.icmp_options.#": "0",
                            "ingress_security_rules.3.protocol": "6",
                            "ingress_security_rules.3.source": "129.213.0.0/16",
                            "ingress_security_rules.3.stateless": "false",
                            "ingress_security_rules.3.tcp_options.#": "0",
                            "ingress_security_rules.3.udp_options.#": "0",
                            "ingress_security_rules.4.icmp_options.#": "0",
                            "ingress_security_rules.4.protocol": "6",
                            "ingress_security_rules.4.source": "10.0.0.0/16",
                            "ingress_security_rules.4.stateless": "false",
                            "ingress_security_rules.4.tcp_options.#": "0",
                            "ingress_security_rules.4.udp_options.#": "0",
                            "ingress_security_rules.5.icmp_options.#": "0",
                            "ingress_security_rules.5.protocol": "6",
                            "ingress_security_rules.5.source": "0.0.0.0/0",
                            "ingress_security_rules.5.stateless": "false",
                            "ingress_security_rules.5.tcp_options.#": "1",
                            "ingress_security_rules.5.tcp_options.0.max": "22",
                            "ingress_security_rules.5.tcp_options.0.min": "22",
                            "ingress_security_rules.5.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.5.udp_options.#": "0",
                            "ingress_security_rules.6.icmp_options.#": "0",
                            "ingress_security_rules.6.protocol": "6",
                            "ingress_security_rules.6.source": "0.0.0.0/0",
                            "ingress_security_rules.6.stateless": "false",
                            "ingress_security_rules.6.tcp_options.#": "1",
                            "ingress_security_rules.6.tcp_options.0.max": "2380",
                            "ingress_security_rules.6.tcp_options.0.min": "2379",
                            "ingress_security_rules.6.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.6.udp_options.#": "0",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:12.625 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_security_list.K8SCCMLBSubnet": {
                    "type": "oci_core_security_list",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.securitylist.oc1.iad.aaaaaaaax34gq4i6roykhxocqbr5osjlfyhbznwprtisyk37qz6ztyrz65pq",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "k8sCCM_security_list",
                            "egress_security_rules.#": "1",
                            "egress_security_rules.0.destination": "0.0.0.0/0",
                            "egress_security_rules.0.icmp_options.#": "0",
                            "egress_security_rules.0.protocol": "all",
                            "egress_security_rules.0.stateless": "false",
                            "egress_security_rules.0.tcp_options.#": "0",
                            "egress_security_rules.0.udp_options.#": "0",
                            "id": "ocid1.securitylist.oc1.iad.aaaaaaaax34gq4i6roykhxocqbr5osjlfyhbznwprtisyk37qz6ztyrz65pq",
                            "ingress_security_rules.#": "0",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:11.632 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_security_list.K8SMasterSubnet": {
                    "type": "oci_core_security_list",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.securitylist.oc1.iad.aaaaaaaawt5inyhnosbf6oqsq5tjf7izyr7agdscf3uiaao2r6yol5zkp5gq",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "k8sMaster_security_list",
                            "egress_security_rules.#": "1",
                            "egress_security_rules.0.destination": "0.0.0.0/0",
                            "egress_security_rules.0.icmp_options.#": "0",
                            "egress_security_rules.0.protocol": "all",
                            "egress_security_rules.0.stateless": "false",
                            "egress_security_rules.0.tcp_options.#": "0",
                            "egress_security_rules.0.udp_options.#": "0",
                            "id": "ocid1.securitylist.oc1.iad.aaaaaaaawt5inyhnosbf6oqsq5tjf7izyr7agdscf3uiaao2r6yol5zkp5gq",
                            "ingress_security_rules.#": "9",
                            "ingress_security_rules.0.icmp_options.#": "1",
                            "ingress_security_rules.0.icmp_options.0.code": "4",
                            "ingress_security_rules.0.icmp_options.0.type": "3",
                            "ingress_security_rules.0.protocol": "1",
                            "ingress_security_rules.0.source": "0.0.0.0/0",
                            "ingress_security_rules.0.stateless": "false",
                            "ingress_security_rules.0.tcp_options.#": "0",
                            "ingress_security_rules.0.udp_options.#": "0",
                            "ingress_security_rules.1.icmp_options.#": "1",
                            "ingress_security_rules.1.icmp_options.0.code": "4",
                            "ingress_security_rules.1.icmp_options.0.type": "3",
                            "ingress_security_rules.1.protocol": "1",
                            "ingress_security_rules.1.source": "10.0.0.0/16",
                            "ingress_security_rules.1.stateless": "false",
                            "ingress_security_rules.1.tcp_options.#": "0",
                            "ingress_security_rules.1.udp_options.#": "0",
                            "ingress_security_rules.2.icmp_options.#": "0",
                            "ingress_security_rules.2.protocol": "6",
                            "ingress_security_rules.2.source": "129.144.0.0/12",
                            "ingress_security_rules.2.stateless": "false",
                            "ingress_security_rules.2.tcp_options.#": "0",
                            "ingress_security_rules.2.udp_options.#": "0",
                            "ingress_security_rules.3.icmp_options.#": "0",
                            "ingress_security_rules.3.protocol": "6",
                            "ingress_security_rules.3.source": "129.213.0.0/16",
                            "ingress_security_rules.3.stateless": "false",
                            "ingress_security_rules.3.tcp_options.#": "0",
                            "ingress_security_rules.3.udp_options.#": "0",
                            "ingress_security_rules.4.icmp_options.#": "0",
                            "ingress_security_rules.4.protocol": "all",
                            "ingress_security_rules.4.source": "10.0.0.0/16",
                            "ingress_security_rules.4.stateless": "false",
                            "ingress_security_rules.4.tcp_options.#": "0",
                            "ingress_security_rules.4.udp_options.#": "0",
                            "ingress_security_rules.5.icmp_options.#": "0",
                            "ingress_security_rules.5.protocol": "6",
                            "ingress_security_rules.5.source": "0.0.0.0/0",
                            "ingress_security_rules.5.stateless": "false",
                            "ingress_security_rules.5.tcp_options.#": "1",
                            "ingress_security_rules.5.tcp_options.0.max": "22",
                            "ingress_security_rules.5.tcp_options.0.min": "22",
                            "ingress_security_rules.5.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.5.udp_options.#": "0",
                            "ingress_security_rules.6.icmp_options.#": "0",
                            "ingress_security_rules.6.protocol": "6",
                            "ingress_security_rules.6.source": "10.0.0.0/16",
                            "ingress_security_rules.6.stateless": "false",
                            "ingress_security_rules.6.tcp_options.#": "1",
                            "ingress_security_rules.6.tcp_options.0.max": "8080",
                            "ingress_security_rules.6.tcp_options.0.min": "8080",
                            "ingress_security_rules.6.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.6.udp_options.#": "0",
                            "ingress_security_rules.7.icmp_options.#": "0",
                            "ingress_security_rules.7.protocol": "6",
                            "ingress_security_rules.7.source": "0.0.0.0/0",
                            "ingress_security_rules.7.stateless": "false",
                            "ingress_security_rules.7.tcp_options.#": "1",
                            "ingress_security_rules.7.tcp_options.0.max": "443",
                            "ingress_security_rules.7.tcp_options.0.min": "443",
                            "ingress_security_rules.7.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.7.udp_options.#": "0",
                            "ingress_security_rules.8.icmp_options.#": "0",
                            "ingress_security_rules.8.protocol": "6",
                            "ingress_security_rules.8.source": "0.0.0.0/0",
                            "ingress_security_rules.8.stateless": "false",
                            "ingress_security_rules.8.tcp_options.#": "1",
                            "ingress_security_rules.8.tcp_options.0.max": "32767",
                            "ingress_security_rules.8.tcp_options.0.min": "30000",
                            "ingress_security_rules.8.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.8.udp_options.#": "0",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:11.786 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_security_list.K8SWorkerSubnet": {
                    "type": "oci_core_security_list",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.securitylist.oc1.iad.aaaaaaaapfu5z7jgx23a727aqqv6hohpebxccs4mmbpxlmwxnqkqfrg45igq",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "k8sWorker_security_list",
                            "egress_security_rules.#": "1",
                            "egress_security_rules.0.destination": "0.0.0.0/0",
                            "egress_security_rules.0.icmp_options.#": "0",
                            "egress_security_rules.0.protocol": "all",
                            "egress_security_rules.0.stateless": "false",
                            "egress_security_rules.0.tcp_options.#": "0",
                            "egress_security_rules.0.udp_options.#": "0",
                            "id": "ocid1.securitylist.oc1.iad.aaaaaaaapfu5z7jgx23a727aqqv6hohpebxccs4mmbpxlmwxnqkqfrg45igq",
                            "ingress_security_rules.#": "7",
                            "ingress_security_rules.0.icmp_options.#": "1",
                            "ingress_security_rules.0.icmp_options.0.code": "4",
                            "ingress_security_rules.0.icmp_options.0.type": "3",
                            "ingress_security_rules.0.protocol": "1",
                            "ingress_security_rules.0.source": "0.0.0.0/0",
                            "ingress_security_rules.0.stateless": "false",
                            "ingress_security_rules.0.tcp_options.#": "0",
                            "ingress_security_rules.0.udp_options.#": "0",
                            "ingress_security_rules.1.icmp_options.#": "1",
                            "ingress_security_rules.1.icmp_options.0.code": "4",
                            "ingress_security_rules.1.icmp_options.0.type": "3",
                            "ingress_security_rules.1.protocol": "1",
                            "ingress_security_rules.1.source": "10.0.0.0/16",
                            "ingress_security_rules.1.stateless": "false",
                            "ingress_security_rules.1.tcp_options.#": "0",
                            "ingress_security_rules.1.udp_options.#": "0",
                            "ingress_security_rules.2.icmp_options.#": "0",
                            "ingress_security_rules.2.protocol": "6",
                            "ingress_security_rules.2.source": "129.144.0.0/12",
                            "ingress_security_rules.2.stateless": "false",
                            "ingress_security_rules.2.tcp_options.#": "0",
                            "ingress_security_rules.2.udp_options.#": "0",
                            "ingress_security_rules.3.icmp_options.#": "0",
                            "ingress_security_rules.3.protocol": "6",
                            "ingress_security_rules.3.source": "129.213.0.0/16",
                            "ingress_security_rules.3.stateless": "false",
                            "ingress_security_rules.3.tcp_options.#": "0",
                            "ingress_security_rules.3.udp_options.#": "0",
                            "ingress_security_rules.4.icmp_options.#": "0",
                            "ingress_security_rules.4.protocol": "all",
                            "ingress_security_rules.4.source": "10.0.0.0/16",
                            "ingress_security_rules.4.stateless": "false",
                            "ingress_security_rules.4.tcp_options.#": "0",
                            "ingress_security_rules.4.udp_options.#": "0",
                            "ingress_security_rules.5.icmp_options.#": "0",
                            "ingress_security_rules.5.protocol": "6",
                            "ingress_security_rules.5.source": "0.0.0.0/0",
                            "ingress_security_rules.5.stateless": "false",
                            "ingress_security_rules.5.tcp_options.#": "1",
                            "ingress_security_rules.5.tcp_options.0.max": "22",
                            "ingress_security_rules.5.tcp_options.0.min": "22",
                            "ingress_security_rules.5.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.5.udp_options.#": "0",
                            "ingress_security_rules.6.icmp_options.#": "0",
                            "ingress_security_rules.6.protocol": "6",
                            "ingress_security_rules.6.source": "0.0.0.0/0",
                            "ingress_security_rules.6.stateless": "false",
                            "ingress_security_rules.6.tcp_options.#": "1",
                            "ingress_security_rules.6.tcp_options.0.max": "32767",
                            "ingress_security_rules.6.tcp_options.0.min": "30000",
                            "ingress_security_rules.6.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.6.udp_options.#": "0",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:12.188 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_security_list.NatSecurityList": {
                    "type": "oci_core_security_list",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.securitylist.oc1.iad.aaaaaaaaockktlfg4bwymtpj3b6lh7diqsi4kdqdsz2dyt2ms3vlhjcockra",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "nat_security_list",
                            "egress_security_rules.#": "1",
                            "egress_security_rules.0.destination": "0.0.0.0/0",
                            "egress_security_rules.0.icmp_options.#": "0",
                            "egress_security_rules.0.protocol": "all",
                            "egress_security_rules.0.stateless": "false",
                            "egress_security_rules.0.tcp_options.#": "0",
                            "egress_security_rules.0.udp_options.#": "0",
                            "id": "ocid1.securitylist.oc1.iad.aaaaaaaaockktlfg4bwymtpj3b6lh7diqsi4kdqdsz2dyt2ms3vlhjcockra",
                            "ingress_security_rules.#": "9",
                            "ingress_security_rules.0.icmp_options.#": "1",
                            "ingress_security_rules.0.icmp_options.0.code": "4",
                            "ingress_security_rules.0.icmp_options.0.type": "3",
                            "ingress_security_rules.0.protocol": "1",
                            "ingress_security_rules.0.source": "0.0.0.0/0",
                            "ingress_security_rules.0.stateless": "false",
                            "ingress_security_rules.0.tcp_options.#": "0",
                            "ingress_security_rules.0.udp_options.#": "0",
                            "ingress_security_rules.1.icmp_options.#": "1",
                            "ingress_security_rules.1.icmp_options.0.code": "4",
                            "ingress_security_rules.1.icmp_options.0.type": "3",
                            "ingress_security_rules.1.protocol": "1",
                            "ingress_security_rules.1.source": "10.0.0.0/16",
                            "ingress_security_rules.1.stateless": "false",
                            "ingress_security_rules.1.tcp_options.#": "0",
                            "ingress_security_rules.1.udp_options.#": "0",
                            "ingress_security_rules.2.icmp_options.#": "0",
                            "ingress_security_rules.2.protocol": "6",
                            "ingress_security_rules.2.source": "129.144.0.0/12",
                            "ingress_security_rules.2.stateless": "false",
                            "ingress_security_rules.2.tcp_options.#": "0",
                            "ingress_security_rules.2.udp_options.#": "0",
                            "ingress_security_rules.3.icmp_options.#": "0",
                            "ingress_security_rules.3.protocol": "6",
                            "ingress_security_rules.3.source": "129.213.0.0/16",
                            "ingress_security_rules.3.stateless": "false",
                            "ingress_security_rules.3.tcp_options.#": "0",
                            "ingress_security_rules.3.udp_options.#": "0",
                            "ingress_security_rules.4.icmp_options.#": "0",
                            "ingress_security_rules.4.protocol": "all",
                            "ingress_security_rules.4.source": "10.0.0.0/16",
                            "ingress_security_rules.4.stateless": "false",
                            "ingress_security_rules.4.tcp_options.#": "0",
                            "ingress_security_rules.4.udp_options.#": "0",
                            "ingress_security_rules.5.icmp_options.#": "0",
                            "ingress_security_rules.5.protocol": "6",
                            "ingress_security_rules.5.source": "0.0.0.0/0",
                            "ingress_security_rules.5.stateless": "false",
                            "ingress_security_rules.5.tcp_options.#": "1",
                            "ingress_security_rules.5.tcp_options.0.max": "22",
                            "ingress_security_rules.5.tcp_options.0.min": "22",
                            "ingress_security_rules.5.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.5.udp_options.#": "0",
                            "ingress_security_rules.6.icmp_options.#": "0",
                            "ingress_security_rules.6.protocol": "6",
                            "ingress_security_rules.6.source": "0.0.0.0/0",
                            "ingress_security_rules.6.stateless": "false",
                            "ingress_security_rules.6.tcp_options.#": "1",
                            "ingress_security_rules.6.tcp_options.0.max": "80",
                            "ingress_security_rules.6.tcp_options.0.min": "80",
                            "ingress_security_rules.6.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.6.udp_options.#": "0",
                            "ingress_security_rules.7.icmp_options.#": "0",
                            "ingress_security_rules.7.protocol": "6",
                            "ingress_security_rules.7.source": "0.0.0.0/0",
                            "ingress_security_rules.7.stateless": "false",
                            "ingress_security_rules.7.tcp_options.#": "1",
                            "ingress_security_rules.7.tcp_options.0.max": "443",
                            "ingress_security_rules.7.tcp_options.0.min": "443",
                            "ingress_security_rules.7.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.7.udp_options.#": "0",
                            "ingress_security_rules.8.icmp_options.#": "0",
                            "ingress_security_rules.8.protocol": "6",
                            "ingress_security_rules.8.source": "0.0.0.0/0",
                            "ingress_security_rules.8.stateless": "false",
                            "ingress_security_rules.8.tcp_options.#": "1",
                            "ingress_security_rules.8.tcp_options.0.max": "2380",
                            "ingress_security_rules.8.tcp_options.0.min": "2379",
                            "ingress_security_rules.8.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.8.udp_options.#": "0",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:11.777 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_security_list.PublicSecurityList": {
                    "type": "oci_core_security_list",
                    "depends_on": [
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.securitylist.oc1.iad.aaaaaaaawbv3fdaczk43yakr57nxyflyvz5v2x6qhohkfkjcdlctab2zy2pa",
                        "attributes": {
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "display_name": "public_security_list",
                            "egress_security_rules.#": "1",
                            "egress_security_rules.0.destination": "0.0.0.0/0",
                            "egress_security_rules.0.icmp_options.#": "0",
                            "egress_security_rules.0.protocol": "all",
                            "egress_security_rules.0.stateless": "false",
                            "egress_security_rules.0.tcp_options.#": "0",
                            "egress_security_rules.0.udp_options.#": "0",
                            "id": "ocid1.securitylist.oc1.iad.aaaaaaaawbv3fdaczk43yakr57nxyflyvz5v2x6qhohkfkjcdlctab2zy2pa",
                            "ingress_security_rules.#": "9",
                            "ingress_security_rules.0.icmp_options.#": "1",
                            "ingress_security_rules.0.icmp_options.0.code": "4",
                            "ingress_security_rules.0.icmp_options.0.type": "3",
                            "ingress_security_rules.0.protocol": "1",
                            "ingress_security_rules.0.source": "0.0.0.0/0",
                            "ingress_security_rules.0.stateless": "false",
                            "ingress_security_rules.0.tcp_options.#": "0",
                            "ingress_security_rules.0.udp_options.#": "0",
                            "ingress_security_rules.1.icmp_options.#": "1",
                            "ingress_security_rules.1.icmp_options.0.code": "4",
                            "ingress_security_rules.1.icmp_options.0.type": "3",
                            "ingress_security_rules.1.protocol": "1",
                            "ingress_security_rules.1.source": "10.0.0.0/16",
                            "ingress_security_rules.1.stateless": "false",
                            "ingress_security_rules.1.tcp_options.#": "0",
                            "ingress_security_rules.1.udp_options.#": "0",
                            "ingress_security_rules.2.icmp_options.#": "0",
                            "ingress_security_rules.2.protocol": "6",
                            "ingress_security_rules.2.source": "129.144.0.0/12",
                            "ingress_security_rules.2.stateless": "false",
                            "ingress_security_rules.2.tcp_options.#": "0",
                            "ingress_security_rules.2.udp_options.#": "0",
                            "ingress_security_rules.3.icmp_options.#": "0",
                            "ingress_security_rules.3.protocol": "6",
                            "ingress_security_rules.3.source": "129.213.0.0/16",
                            "ingress_security_rules.3.stateless": "false",
                            "ingress_security_rules.3.tcp_options.#": "0",
                            "ingress_security_rules.3.udp_options.#": "0",
                            "ingress_security_rules.4.icmp_options.#": "0",
                            "ingress_security_rules.4.protocol": "all",
                            "ingress_security_rules.4.source": "10.0.0.0/16",
                            "ingress_security_rules.4.stateless": "false",
                            "ingress_security_rules.4.tcp_options.#": "0",
                            "ingress_security_rules.4.udp_options.#": "0",
                            "ingress_security_rules.5.icmp_options.#": "0",
                            "ingress_security_rules.5.protocol": "6",
                            "ingress_security_rules.5.source": "0.0.0.0/0",
                            "ingress_security_rules.5.stateless": "false",
                            "ingress_security_rules.5.tcp_options.#": "1",
                            "ingress_security_rules.5.tcp_options.0.max": "22",
                            "ingress_security_rules.5.tcp_options.0.min": "22",
                            "ingress_security_rules.5.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.5.udp_options.#": "0",
                            "ingress_security_rules.6.icmp_options.#": "0",
                            "ingress_security_rules.6.protocol": "6",
                            "ingress_security_rules.6.source": "0.0.0.0/0",
                            "ingress_security_rules.6.stateless": "false",
                            "ingress_security_rules.6.tcp_options.#": "1",
                            "ingress_security_rules.6.tcp_options.0.max": "80",
                            "ingress_security_rules.6.tcp_options.0.min": "80",
                            "ingress_security_rules.6.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.6.udp_options.#": "0",
                            "ingress_security_rules.7.icmp_options.#": "0",
                            "ingress_security_rules.7.protocol": "6",
                            "ingress_security_rules.7.source": "0.0.0.0/0",
                            "ingress_security_rules.7.stateless": "false",
                            "ingress_security_rules.7.tcp_options.#": "1",
                            "ingress_security_rules.7.tcp_options.0.max": "443",
                            "ingress_security_rules.7.tcp_options.0.min": "443",
                            "ingress_security_rules.7.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.7.udp_options.#": "0",
                            "ingress_security_rules.8.icmp_options.#": "0",
                            "ingress_security_rules.8.protocol": "6",
                            "ingress_security_rules.8.source": "0.0.0.0/0",
                            "ingress_security_rules.8.stateless": "false",
                            "ingress_security_rules.8.tcp_options.#": "1",
                            "ingress_security_rules.8.tcp_options.0.max": "2380",
                            "ingress_security_rules.8.tcp_options.0.min": "2379",
                            "ingress_security_rules.8.tcp_options.0.source_port_range.#": "0",
                            "ingress_security_rules.8.udp_options.#": "0",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:11.762 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.NATSubnetAD1": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.NatSecurityList",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "cidr_block": "10.0.13.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "publicNATSubnetAD1",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaa2v4ptkvyswymgbjcgbdb6yn7dxlkcur45rlwztf4khxz2yiz4x3q",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.2471026238": "ocid1.securitylist.oc1.iad.aaaaaaaaockktlfg4bwymtpj3b6lh7diqsi4kdqdsz2dyt2ms3vlhjcockra",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:15.218 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.13.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.NATSubnetAD2": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.NatSecurityList",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaamezfmzw4xkoduqzuxrsfreouitkhsxnmo4uukd4btrnrwxht4nyq",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-2",
                            "cidr_block": "10.0.14.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "publicNATSubnetAD2",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaamezfmzw4xkoduqzuxrsfreouitkhsxnmo4uukd4btrnrwxht4nyq",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.2471026238": "ocid1.securitylist.oc1.iad.aaaaaaaaockktlfg4bwymtpj3b6lh7diqsi4kdqdsz2dyt2ms3vlhjcockra",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:14.927 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.14.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.NATSubnetAD3": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.NatSecurityList",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaak7bxex6ssockzoemup537dntkdllu44ltln224safckvdsnxrz6a",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-3",
                            "cidr_block": "10.0.15.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "publicNATSubnetAD3",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaak7bxex6ssockzoemup537dntkdllu44ltln224safckvdsnxrz6a",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.2471026238": "ocid1.securitylist.oc1.iad.aaaaaaaaockktlfg4bwymtpj3b6lh7diqsi4kdqdsz2dyt2ms3vlhjcockra",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:15.087 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.15.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.PublicSubnetAD1": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.PublicSecurityList",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaagzy4dlm25w6gn7z523ss56qvdk3cnpfsrcigk3curx33toaktvja",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "cidr_block": "10.0.10.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "publicSubnetAD1",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaagzy4dlm25w6gn7z523ss56qvdk3cnpfsrcigk3curx33toaktvja",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.514596769": "ocid1.securitylist.oc1.iad.aaaaaaaawbv3fdaczk43yakr57nxyflyvz5v2x6qhohkfkjcdlctab2zy2pa",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:13.77 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.10.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.PublicSubnetAD2": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.PublicSecurityList",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaadcgbuknfac25c6tf5ivuyylpixb7uamdpzjz5u3sc6nq6jklfq7a",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-2",
                            "cidr_block": "10.0.11.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "publicSubnetAD2",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaadcgbuknfac25c6tf5ivuyylpixb7uamdpzjz5u3sc6nq6jklfq7a",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.514596769": "ocid1.securitylist.oc1.iad.aaaaaaaawbv3fdaczk43yakr57nxyflyvz5v2x6qhohkfkjcdlctab2zy2pa",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:14.574 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.11.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.PublicSubnetAD3": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.PublicSecurityList",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaanlzfxpjupyuol5g6o6ee3weqsthblapdwcltykn572yaxsrxba3q",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-3",
                            "cidr_block": "10.0.12.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "publicSubnetAD3",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaanlzfxpjupyuol5g6o6ee3weqsthblapdwcltykn572yaxsrxba3q",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.514596769": "ocid1.securitylist.oc1.iad.aaaaaaaawbv3fdaczk43yakr57nxyflyvz5v2x6qhohkfkjcdlctab2zy2pa",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:14.691 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.12.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.etcdSubnetAD1": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.EtcdSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaaf7xofr4fl6ceqs2wukk4it6amuzljtnj44srqfif5p43oxnemyga",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "cidr_block": "10.0.20.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateETCDSubnetAD1",
                            "dns_label": "etcdsubnet1",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaaf7xofr4fl6ceqs2wukk4it6amuzljtnj44srqfif5p43oxnemyga",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.3423923779": "ocid1.securitylist.oc1.iad.aaaaaaaaa4p6phc3zxmxkdqwaqrwx75dtma5jpkpheo37sapv5ivlhm4tyoa",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "etcdsubnet1.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:09.154 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.20.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.etcdSubnetAD2": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.EtcdSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaaxiqvp52kdugxhyfv2svsbap34it4dymr2felbnjfi2lxjiwqvwnq",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-2",
                            "cidr_block": "10.0.21.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateETCDSubnetAD2",
                            "dns_label": "etcdsubnet2",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaaxiqvp52kdugxhyfv2svsbap34it4dymr2felbnjfi2lxjiwqvwnq",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.3423923779": "ocid1.securitylist.oc1.iad.aaaaaaaaa4p6phc3zxmxkdqwaqrwx75dtma5jpkpheo37sapv5ivlhm4tyoa",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "etcdsubnet2.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:08.54 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.21.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.etcdSubnetAD3": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.EtcdSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaap2rwkhbboizkwub3aialqrv3xnzw6s3vpjw7dfjjydbkzbckljca",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-3",
                            "cidr_block": "10.0.22.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateETCDSubnetAD3",
                            "dns_label": "etcdsubnet3",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaap2rwkhbboizkwub3aialqrv3xnzw6s3vpjw7dfjjydbkzbckljca",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.3423923779": "ocid1.securitylist.oc1.iad.aaaaaaaaa4p6phc3zxmxkdqwaqrwx75dtma5jpkpheo37sapv5ivlhm4tyoa",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "etcdsubnet3.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:08.874 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.22.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sCCMLBSubnetAD1": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SCCMLBSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaawlpvf7zgpwlu6hovzi5nbdinf4iinzsagb4rqdf6qr5l6a3t7uba",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "cidr_block": "10.0.50.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "PublicK8SCCMLBSubnetAD1",
                            "dns_label": "k8sccmlbad1",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaawlpvf7zgpwlu6hovzi5nbdinf4iinzsagb4rqdf6qr5l6a3t7uba",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.3204459418": "ocid1.securitylist.oc1.iad.aaaaaaaax34gq4i6roykhxocqbr5osjlfyhbznwprtisyk37qz6ztyrz65pq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8sccmlbad1.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:21:13.468 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.50.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sCCMLBSubnetAD2": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SCCMLBSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaa2ohaovg3thspzp2vjpwje6akrdmgxtj3k57bgsgcja63235la36a",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-2",
                            "cidr_block": "10.0.51.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "PublicK8SCCMLBSubnetAD2",
                            "dns_label": "k8sccmlbad2",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaa2ohaovg3thspzp2vjpwje6akrdmgxtj3k57bgsgcja63235la36a",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.3204459418": "ocid1.securitylist.oc1.iad.aaaaaaaax34gq4i6roykhxocqbr5osjlfyhbznwprtisyk37qz6ztyrz65pq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8sccmlbad2.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:21:15.386 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.51.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sCCMLBSubnetAD3": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SCCMLBSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaa6rg4zrgomrivnwdcfmx4audqr3lbdwvzzfvamqlz4v6cqkh4jeua",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-3",
                            "cidr_block": "10.0.52.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "PublicK8SCCMLBSubnetAD3",
                            "dns_label": "k8sccmlbad3",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaa6rg4zrgomrivnwdcfmx4audqr3lbdwvzzfvamqlz4v6cqkh4jeua",
                            "prohibit_public_ip_on_vnic": "false",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaarvbgphzmd4yoy3pj6luyvy2kuescxpnieqiefvkkpa5uq667mlda",
                            "security_list_ids.#": "1",
                            "security_list_ids.3204459418": "ocid1.securitylist.oc1.iad.aaaaaaaax34gq4i6roykhxocqbr5osjlfyhbznwprtisyk37qz6ztyrz65pq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8sccmlbad3.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:21:14.363 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.52.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sMasterSubnetAD1": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SMasterSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaa3mx26p2ylaqsw5no5qxnihqhxqdpqukkpt4msuevcpfguyat6d7a",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "cidr_block": "10.0.30.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateK8SMasterSubnetAD1",
                            "dns_label": "k8smasterad1",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaa3mx26p2ylaqsw5no5qxnihqhxqdpqukkpt4msuevcpfguyat6d7a",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.3290570641": "ocid1.securitylist.oc1.iad.aaaaaaaawt5inyhnosbf6oqsq5tjf7izyr7agdscf3uiaao2r6yol5zkp5gq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8smasterad1.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:09.07 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.30.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sMasterSubnetAD2": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SMasterSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaagyxrq2uygyhhyltjjc3ghljjrjq5sk5mpmevkfdjl5uuohnkjttq",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-2",
                            "cidr_block": "10.0.31.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateK8SMasterSubnetAD2",
                            "dns_label": "k8smasterad2",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaagyxrq2uygyhhyltjjc3ghljjrjq5sk5mpmevkfdjl5uuohnkjttq",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.3290570641": "ocid1.securitylist.oc1.iad.aaaaaaaawt5inyhnosbf6oqsq5tjf7izyr7agdscf3uiaao2r6yol5zkp5gq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8smasterad2.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:07.911 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.31.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sMasterSubnetAD3": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SMasterSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaaumqfgoz6o7s32wqvf5ddowxz5likw5xepxcvi7xcv554w575acpa",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-3",
                            "cidr_block": "10.0.32.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateK8SMasterSubnetAD3",
                            "dns_label": "k8smasterad3",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaaumqfgoz6o7s32wqvf5ddowxz5likw5xepxcvi7xcv554w575acpa",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.3290570641": "ocid1.securitylist.oc1.iad.aaaaaaaawt5inyhnosbf6oqsq5tjf7izyr7agdscf3uiaao2r6yol5zkp5gq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8smasterad3.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:07.703 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.32.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sWorkerSubnetAD1": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SWorkerSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaaefqwgcbfss43qxjvcrovz3a6zaqskdfyuif65b7eqpuz3omexuhq",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-1",
                            "cidr_block": "10.0.40.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateK8SWorkerSubnetAD1",
                            "dns_label": "k8sworkerad1",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaaefqwgcbfss43qxjvcrovz3a6zaqskdfyuif65b7eqpuz3omexuhq",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.1607518493": "ocid1.securitylist.oc1.iad.aaaaaaaapfu5z7jgx23a727aqqv6hohpebxccs4mmbpxlmwxnqkqfrg45igq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8sworkerad1.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:08.308 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.40.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sWorkerSubnetAD2": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SWorkerSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaabhkzbvfotkst2mbwxyloesuq6pcvmkext3tjddfjdm3coo2geikq",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-2",
                            "cidr_block": "10.0.41.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateK8SWorkerSubnetAD2",
                            "dns_label": "k8sworkerad2",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaabhkzbvfotkst2mbwxyloesuq6pcvmkext3tjddfjdm3coo2geikq",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.1607518493": "ocid1.securitylist.oc1.iad.aaaaaaaapfu5z7jgx23a727aqqv6hohpebxccs4mmbpxlmwxnqkqfrg45igq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8sworkerad2.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:08.124 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.41.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_subnet.k8sWorkerSubnetAD3": {
                    "type": "oci_core_subnet",
                    "depends_on": [
                        "data.oci_identity_availability_domains.ADs",
                        "oci_core_route_table.NATInstanceAD1RouteTable.*",
                        "oci_core_route_table.NATInstanceAD2RouteTable.*",
                        "oci_core_route_table.NATInstanceAD3RouteTable.*",
                        "oci_core_route_table.PublicRouteTable",
                        "oci_core_security_list.K8SWorkerSubnet",
                        "oci_core_virtual_network.CompleteVCN"
                    ],
                    "primary": {
                        "id": "ocid1.subnet.oc1.iad.aaaaaaaavop32xhqq7frm4ahwe7mwazf6soe3wtizx7wmvh4jqxfzjv7p6uq",
                        "attributes": {
                            "availability_domain": "AhKQ:US-ASHBURN-AD-3",
                            "cidr_block": "10.0.42.0/24",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "display_name": "privateK8SWorkerSubnetAD3",
                            "dns_label": "k8sworkerad3",
                            "id": "ocid1.subnet.oc1.iad.aaaaaaaavop32xhqq7frm4ahwe7mwazf6soe3wtizx7wmvh4jqxfzjv7p6uq",
                            "prohibit_public_ip_on_vnic": "true",
                            "route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaawygs325u2iyu7ls426rceb5iq7g62afkrjtizs7iej575vjwhaja",
                            "security_list_ids.#": "1",
                            "security_list_ids.1607518493": "ocid1.securitylist.oc1.iad.aaaaaaaapfu5z7jgx23a727aqqv6hohpebxccs4mmbpxlmwxnqkqfrg45igq",
                            "state": "AVAILABLE",
                            "subnet_domain_name": "k8sworkerad3.kubernetes.oraclevcn.com",
                            "time_created": "2019-02-08 02:23:07.461 +0000 UTC",
                            "vcn_id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "virtual_router_ip": "10.0.42.1",
                            "virtual_router_mac": "00:00:17:B2:5B:7E"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                },
                "oci_core_virtual_network.CompleteVCN": {
                    "type": "oci_core_virtual_network",
                    "depends_on": [],
                    "primary": {
                        "id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                        "attributes": {
                            "cidr_block": "10.0.0.0/16",
                            "compartment_id": "ocid1.compartment.oc1..aaaaaaaajdloco2usq6y24dudqirugj6ej44mpooogjes3penwtye4wp42uq",
                            "default_dhcp_options_id": "ocid1.dhcpoptions.oc1.iad.aaaaaaaabal7vktejf63j4no736beyrzgk5zhghem56ro6anmber4xvlzmkq",
                            "default_route_table_id": "ocid1.routetable.oc1.iad.aaaaaaaa5j4jxe2nyhilrqam52wvybsgmugqrt7ctmjks5pdxanyesbqezva",
                            "default_security_list_id": "ocid1.securitylist.oc1.iad.aaaaaaaapjpjz6ii4cdr2ua577x77yok3dbfolxmhqrllvwbk6vya7q5kriq",
                            "display_name": "kubernetes",
                            "dns_label": "kubernetes",
                            "id": "ocid1.vcn.oc1.iad.aaaaaaaawubwha2e25bbpbgkakt2swyeoaprabxarbg267dvqprb232jpxra",
                            "state": "AVAILABLE",
                            "time_created": "2019-02-08 02:21:10.602 +0000 UTC",
                            "vcn_domain_name": "kubernetes.oraclevcn.com"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000,
                                "delete": 300000000000,
                                "update": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.oci"
                }
            },
            "depends_on": []
        }
    ]
}
